This XML file does not appear to have any style information associated with it. The document tree is shown below.
<rss xmlns:dc="http://purl.org/dc/elements/1.1/" xmlns:content="http://purl.org/rss/1.0/modules/content/" xmlns:atom="http://www.w3.org/2005/Atom" xmlns:media="http://search.yahoo.com/mrss/" version="2.0">
<channel>
<title>
<![CDATA[ The Cloudflare Blog ]]>
</title>
<description>
<![CDATA[ Get the latest news on how products at Cloudflare are built, technologies used, and join the teams helping to build a better Internet. ]]>
</description>
<link>https://blog.cloudflare.com/</link>
<image>
<url>http://blog.cloudflare.com/favicon.png</url>
<title>The Cloudflare Blog</title>
<link>https://blog.cloudflare.com/</link>
</image>
<generator>Ghost 3.5</generator>
<lastBuildDate>Wed, 01 Mar 2023 20:29:51 GMT</lastBuildDate>
<atom:link href="https://blog.cloudflare.com/rss/" rel="self" type="application/rss+xml"/>
<ttl>60</ttl>
<item>
<title>
<![CDATA[ How Rust and Wasm power Cloudflare's 1.1.1.1 ]]>
</title>
<description>
<![CDATA[ Introducing a new DNS platform that powers 1.1.1.1 and various other products. ]]>
</description>
<link>https://blog.cloudflare.com/big-pineapple-intro/</link>
<guid isPermaLink="false">63f8bb7a917f76000a693027</guid>
<category>
<![CDATA[ DNS ]]>
</category>
<category>
<![CDATA[ Resolver ]]>
</category>
<category>
<![CDATA[ 1.1.1.1 ]]>
</category>
<dc:creator>
<![CDATA[ Anbang Wen ]]>
</dc:creator>
<pubDate>Tue, 28 Feb 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/BLOG-1649-header.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image1-11.png" class="kg-image" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/BLOG-1649-header.png" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"><p>On April 1, 2018, Cloudflare <a href="http://blog.cloudflare.com/dns-resolver-1-1-1-1/">announced</a> the 1.1.1.1 public DNS resolver. Over the years, we added the <a href="https://1.1.1.1/help">debug page</a> for troubleshooting, global <a href="https://1.1.1.1/purge-cache/">cache purge</a>, 0 TTL for zones on Cloudflare, <a href="http://blog.cloudflare.com/encrypting-dns-end-to-end/">Upstream TLS</a>, and <a href="http://blog.cloudflare.com/introducing-1-1-1-1-for-families/">1.1.1.1 for families</a> to the platform. In this post, we would like to share some behind the scenes details and changes.</p><p>When the project started, <a href="https://www.knot-resolver.cz/">Knot Resolver</a> was chosen as the DNS resolver. We started building a whole system on top of it, so that it could fit Cloudflare's use case. Having a battle tested DNS recursive resolver, as well as a DNSSEC validator, was fantastic because we could spend our energy elsewhere, instead of worrying about the DNS protocol implementation.</p><p>Knot Resolver is quite flexible in terms of its Lua-based plugin system. It allowed us to quickly extend the core functionality to support various product features, like DoH/DoT, logging, BPF-based attack mitigation, cache sharing, and iteration logic override. As the <a href="https://mobile.twitter.com/eastdakota/status/1103800276102729729">traffic grew</a>, we reached certain limitations.</p><h2 id="lessons-we-learned">Lessons we learned</h2><p>Before going any deeper, let’s first have a bird’s-eye view of a simplified Cloudflare data center setup, which could help us understand what we are going to talk about later. At Cloudflare, every server is identical: the software stack running on one server is exactly the same as on another server, only the configuration may be different. This setup greatly reduces the complexity of fleet maintenance.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/colo_kresd.png" class="kg-image" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"><figcaption>Figure 1 Data center layout</figcaption></figure><p>The resolver runs as a daemon process, kresd, and it doesn’t work alone. Requests, specifically DNS requests, are load-balanced to the servers inside a data center by <a href="http://blog.cloudflare.com/unimog-cloudflares-edge-load-balancer/">Unimog</a>. DoH requests are terminated at our TLS terminator. Configs and other small pieces of data can be delivered worldwide by <a href="http://blog.cloudflare.com/introducing-quicksilver-configuration-distribution-at-internet-scale/">Quicksilver</a> in seconds. With all the help, the resolver can concentrate on its own goal - resolving DNS queries, and not worrying about transport protocol details. Now let’s talk about 3 key areas we wanted to improve here - blocking I/O in plugins, a more efficient use of cache space, and plugin isolation.</p><h3 id="callbacks-blocking-the-event-loop">Callbacks blocking the event loop</h3><p>Knot Resolver has a very flexible plugin system for extending its core functionality. The plugins are called modules, and they are based on callbacks. At certain points during request processing, these callbacks will be invoked with current query context. This gives a module the ability to inspect, modify, and even produce requests / responses. By design, these callbacks are supposed to be simple, in order to avoid blocking the underlying event loop. This matters because the service is single threaded, and the event loop is in charge of serving many requests at the same time. So even just one request being held up in a callback means that no other concurrent requests can be progressed until the callback finishes.</p><p>The setup worked well enough for us until we needed to do blocking operations, for example, to pull data from Quicksilver before responding to the client.</p><h3 id="cache-efficiency">Cache efficiency</h3><p>As requests for a domain could land on any node inside a data center, it would be wasteful to repetitively resolve a query when another node already has the answer. By intuition, the latency could be improved if the cache could be shared among the servers, and so we created a cache module which multicasted the newly added cache entries. Nodes inside the same data center could then subscribe to the events and update their local cache.</p><p>The default cache implementation in Knot Resolver is <a href="https://www.symas.com/lmdb">LMDB</a>. It is fast and reliable for small to medium deployments. But in our case, cache eviction shortly became a problem. The cache itself doesn’t track for any TTL, popularity, etc. When it’s full, it just clears all the entries and starts over. Scenarios like zone enumeration could fill the cache with data that is unlikely to be retrieved later.</p><p>Furthermore, our multicast cache module made it worse by amplifying the less useful data to all the nodes, and led them to the cache high watermark at the same time. Then we saw a latency spike because all the nodes dropped the cache and started over around the same time.</p><h3 id="module-isolation">Module isolation</h3><p>With the list of Lua modules increasing, debugging issues became increasingly difficult. This is because a single Lua state is shared among all the modules, so one misbehaving module could affect another. For example, when something went wrong inside the Lua state, like having too many coroutines, or being out of memory, we got lucky if the program just crashed, but the resulting stack traces were hard to read. It is also difficult to forcibly tear down, or upgrade, a running module as it not only has state in the Lua runtime, but also FFI, so memory safety is not guaranteed.</p><h2 id="hello-bigpineapple">Hello BigPineapple</h2><p>We didn’t find any existing software that would meet our somewhat niche requirements, so eventually we started building something ourselves. The first attempt was to <a href="https://github.com/vavrusa/rust-kres">wrap Knot Resolver's core</a> with a thin service written in Rust (modified <a href="https://github.com/jedisct1/edgedns">edgedns</a>).</p><p>This proved to be difficult due to having to constantly convert between the storage, and C/FFI types, and some other quirks (for example, the ABI for looking up records from cache expects the returned records to be immutable until the next call, or the end of the read transaction). But we learned a lot from trying to implement this sort of split functionality where the host (the service) provides some resources to the guest (resolver core library), and how we would make that interface better.</p><p>In the later iterations, we replaced the entire recursive library with a new one based around an async runtime; and a redesigned module system was added to it, sneakily rewriting the service into Rust over time as we swapped out more and more components. That async runtime was <a href="https://tokio.rs/">tokio</a>, which offered a neat thread pool interface for running both non-blocking and blocking tasks, as well as a good ecosystem for working with other crates (Rust libraries).</p><p>After that, as the futures combinators became tedious, we started converting everything to async/await. This was before the async/await feature that landed in Rust 1.39, which led us to use nightly (Rust beta) for a while and had <a href="https://areweasyncyet.rs/">some hiccups</a>. When the async/await stabilized, it enabled us to write our request processing routine ergonomically, similar to Go.</p><p>All the tasks can be run concurrently, and certain I/O heavy ones can be broken down into smaller pieces, to benefit from a more granular scheduling. As the runtime executes tasks on a threadpool, instead of a single thread, it also benefits from work stealing. This avoids a problem we previously had, where a single request taking a lot of time to process, that blocks all the other requests on the event loop.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/blog_server.png" class="kg-image" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"><figcaption>Figure 2 Components overview</figcaption></figure><p>Finally, we forged a platform that we are happy with, and we call it <strong>BigPineapple</strong>. The figure above shows an overview of its main components and the data flow between them. Inside BigPineapple, the server module gets inbound requests from the client, validates and transforms them into unified frame streams, which can then be processed by the worker module. The worker module has a set of workers, whose task is to figure out the answer to the question in the request. Each worker interacts with the cache module to check if the answer is there and still valid, otherwise it drives the recursor module to recursively iterate the query. The recursor doesn’t do any I/O, when it needs anything, it delegates the sub-task to the conductor module. The conductor then uses outbound queries to get the information from upstream nameservers. Through the whole process, some modules can interact with the Sandbox module, to extend its functionality by running the plugins inside.</p><p>Let’s look at some of them in more detail, and see how they helped us overcome the problems we had before.</p><h3 id="updated-i-o-architecture">Updated I/O architecture</h3><p>A DNS resolver can be seen as an agent between a client and several authoritative nameservers: it receives requests from the client, recursively fetches data from the upstream nameservers, then composes the responses and sends them back to the client. So it has both inbound and outbound traffic, which are handled by the server and the conductor component respectively.</p><p>The server listens on a list of interfaces using different transport protocols. These are later abstracted into streams of “frames”. Each frame is a high level representation of a DNS message, with some extra metadata. Underneath, it can be a UDP packet, a segment of TCP stream, or the payload of a HTTP request, but they are all processed the same way. The frame is then converted into an asynchronous task, which in turn is picked up by a set of workers in charge of resolving these tasks. The finished tasks are converted back into responses, and sent back to the client.</p><p>This “frame” abstraction over the protocols and their encodings simplified the logic used to regulate the frame sources, such as enforcing fairness to prevent starving and controlling pacing to protect the server from being overwhelmed. One of the things we’ve learned with the previous implementations is that, for a service open to the public, a peak performance of the I/O matters less than the ability to pace clients fairly. This is mainly because the time and computational cost of each recursive request is vastly different (for example a cache hit from a cache miss), and it’s difficult to guess it beforehand. The cache misses in recursive service not only consume Cloudflare’s resources, but also the resources of the authoritative nameservers being queried, so we need to be mindful of that.</p><p>On the other side of the server is the conductor, which manages all the outbound connections. It helps to answer some questions before reaching out to the upstream: Which is the fastest nameserver to connect to in terms of latency? What to do if all the nameservers are not reachable? What protocol to use for the connection, and are there any <a href="https://engineering.fb.com/2018/12/21/security/dns-over-tls/">better options</a>? The conductor is able to make these decisions by tracking the upstream server’s metrics, such as RTT, QoS, etc. With that knowledge, it can also guess for things like upstream capacity, UDP packet loss, and take necessary actions, e.g. retry when it thinks the previous UDP packet didn’t reach the upstream.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/conductor-1-.png" class="kg-image" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"><figcaption>Figure 3 I/O conductor</figcaption></figure><p>Figure 3 shows a simplified data flow about the conductor. It is called by the exchanger mentioned above, with upstream requests as input. The requests will be deduplicated first: meaning in a small window, if a lot of requests come to the conductor and ask for the same question, only one of them will pass, the others are put into a waiting queue. This is common when a cache entry expires, and can reduce unnecessary network traffic. Then based on the request and upstream metrics, the connection instructor either picks an open connection if available, or generates a set of parameters. With these parameters, the I/O executor is able to connect to the upstream directly, or even take a route via another Cloudflare data center using our <a href="http://blog.cloudflare.com/argo/">Argo Smart Routing technology</a>!</p><h3 id="the-cache">The cache</h3><p>Caching in a recursive service is critical as a server can return a cached response in under one millisecond, while it will be hundreds of milliseconds to respond on a cache miss. As the memory is a finite resource (and also a shared resource in Cloudflare’s architecture), more efficient use of space for cache was one of the key areas we wanted to improve. The new cache is implemented with a cache replacement data structure (<a href="https://en.wikipedia.org/wiki/Adaptive_replacement_cache">ARC</a>), instead of a KV store. This makes good use of the space on a single node, as less popular entries are progressively evicted, and the data structure is resistant to scans.</p><p>Moreover, instead of duplicating the cache across the whole data center with multicast, as we did before, BigPineapple is aware of its peer nodes in the same data center, and relays queries from one node to another if it cannot find an entry in its own cache. This is done by consistent hashing the queries onto the healthy nodes in each data center. So, for example, queries for the same registered domain go through the same subset of nodes, which not only increases the cache hit ratio, but also helps the infrastructure cache, which stores information about performance and features of nameservers.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/colo_3_bp.png" class="kg-image" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"><figcaption>Figure 4 Updated data center layout</figcaption></figure><h3 id="async-recursive-library">Async recursive library</h3><p>The recursive library is the DNS brain of BigPineapple, as it knows how to find the answer to the question in the query. Starting from the root, it breaks down the client query into subqueries, and uses them to collect knowledge recursively from various authoritative nameservers on the internet. The product of this process is the answer. Thanks to the async/await it can be abstracted as a function like such:</p><!--kg-card-begin: markdown--><pre><code>async fn resolve(Request, Exchanger) → Result&lt;Response&gt;; </code></pre> <!--kg-card-end: markdown--><p>The function contains all the logic necessary to generate a response to a given request, but it doesn’t do any I/O on its own. Instead, we pass an Exchanger trait (Rust interface) that knows how to exchange DNS messages with upstream authoritative nameservers asynchronously. The exchanger is usually called at various await points - for example, when a recursion starts, one of the first things it does is that it looks up the closest cached delegation for the domain. If it doesn’t have the final delegation in cache, it needs to ask what nameservers are responsible for this domain and wait for the response, before it can proceed any further.</p><p>Thanks to this design, which decouples the “waiting for some responses” part from the recursive DNS logic, it is much easier to test by providing a mock implementation of the exchanger. In addition, it makes the recursive iteration code (and DNSSEC validation logic in particular) much more readable, as it’s written sequentially instead of being scattered across many callbacks.</p><p>Fun fact: writing a DNS recursive resolver from scratch is not fun at all!</p><p>Not only because of the complexity of DNSSEC validation, but also because of the necessary “workarounds” needed for various RFC incompatible servers, forwarders, firewalls, etc. So we ported <a href="https://github.com/CZ-NIC/deckard">deckard</a> into Rust to help test it. Additionally, when we started migrating over to this new async recursive library, we first ran it in “shadow” mode: processing real world query samples from the production service, and comparing differences. We’ve done this in the past on Cloudflare’s authoritative DNS service as well. It is slightly more difficult for a recursive service due to the fact that a recursive service has to look up all the data over the Internet, and authoritative nameservers often give different answers for the same query due to localization, load balancing and such, leading to many false positives.</p><p>In December 2019, we finally enabled the new service on a public test endpoint (see the <a href="https://community.cloudflare.com/t/help-us-test-a-new-version-of-1-1-1-1-public-dns-resolver/137078">announcement</a>) to iron out remaining issues before slowly migrating the production endpoints to the new service. Even after all that, we continued to find edge cases with the DNS recursion (and DNSSEC validation in particular), but fixing and reproducing these issues has become much easier due to the new architecture of the library.</p><h3 id="sandboxed-plugins">Sandboxed plugins</h3><p>Having the ability to extend the core DNS functionality on the fly is important for us, thus BigPineapple has its redesigned plugin system. Before, the Lua plugins run in the same memory space as the service itself, and are generally free to do what they want. This is convenient, as we can freely pass memory references between the service and modules using C/FFI. For example, to read a response directly from cache without having to copy to a buffer first. But it is also dangerous, as the module can read uninitialized memory, call a host ABI using a wrong function signature, block on a local socket, or do other undesirable things, in addition the service doesn’t have a way to restrict these behaviors.</p><p>So we looked at replacing the embedded Lua runtime with JavaScript, or native modules, but around the same time, embedded runtimes for WebAssembly (Wasm for short) started to appear. Two nice properties of WebAssembly programs are that it allows us to write them in the same language as the rest of the service, and that they run in an isolated memory space. So we started modeling the guest/host interface around the limitations of WebAssembly modules, to see how that would work.</p><p>BigPineapple’s Wasm runtime is currently powered by <a href="https://wasmer.io/">Wasmer</a>. We tried several runtimes over time like <a href="https://wasmtime.dev/">Wasmtime</a>, <a href="https://wavm.github.io/">WAVM</a> in the beginning, and found Wasmer was simpler to use in our case. The runtime allows each module to run in its own instance, with an isolated memory and a signal trap, which naturally solved the module isolation problem we described before. In addition to this, we can have multiple instances of the same module running at the same time. Being controlled carefully, the apps can be hot swapped from one instance to another without missing a single request! This is great because the apps can be upgraded on the fly without a server restart. Given that the Wasm programs are distributed via Quicksilver, BigPineapple’s functionality can be safely changed worldwide within a few seconds!</p><p>To better understand the WebAssembly sandbox, several terms need to be introduced first:</p><ul><li>Host: the program which runs the Wasm runtime. Similar to a kernel, it has full control through the runtime over the guest applications.</li><li>Guest application: the Wasm program inside the sandbox. Within a restricted environment, it can only access its own memory space, which is provided by the runtime, and call the imported Host calls. We call it an app for short.</li><li>Host call: the functions defined in the host that can be imported by the guest. Comparable to syscall, it’s the only way guest apps can access the resources outside the sandbox.</li><li>Guest runtime: a library for guest applications to easily interact with the host. It implements some common interfaces, so an app can just use async, socket, log and tracing without knowing the underlying details.</li></ul><p>Now it’s time to dive into the sandbox, so stay awhile and listen. First let’s start from the guest side, and see what a common app lifespan looks like. With the help of the guest runtime, guest apps can be written similar to regular programs. So like other executables, an app begins with a start function as an entrypoint, which is called by the host upon loading. It is also provided with arguments as from the command line. At this point, the instance normally does some initialization, and more importantly, registers callback functions for different query phases. This is because in a recursive resolver, a query has to go through several phases before it gathers enough information to produce a response, for example a cache lookup, or making subrequests to resolve a delegation chain for the domain, so being able to tie into these phases is necessary for the apps to be useful for different use cases. The start function can also run some background tasks to supplement the phase callbacks, and store global state. For example - report metrics, or pre-fetch shared data from external sources, etc. Again, just like how we write a normal program.</p><p>But where do the program arguments come from? How could a guest app send log and metrics? The answer is, external functions.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/sandbox-1-.png" class="kg-image" alt="How Rust and Wasm power Cloudflare's 1.1.1.1"><figcaption>Figure 5 Wasm based Sandbox</figcaption></figure><p>In figure 5, we can see a barrier in the middle, which is the sandbox boundary, that separates the guest from the host. The only way one side can reach out to the other, is via a set of functions exported by the peer beforehand. As in the picture, the “hostcalls” are exported by the host, imported and called by the guest; while the “trampoline” are guest functions that the host has knowledge of.</p><p>It is called <a href="https://en.wikipedia.org/wiki/Trampoline_(computing)">trampoline</a> because it is used to invoke a function or a closure inside a guest instance that’s not exported. The phase callbacks are one example of why we need a trampoline function: each callback returns a closure, and therefore can’t be exported on instantiation. So a guest app wants to register a callback, it calls a host call with the callback address “<code>hostcall_register_callback(pre_cache, #30987)</code>”, when the callback needs to be invoked, the host cannot just call that pointer as it’s pointing to the guest’s memory space. What it can do instead is, to leverage one of the aforementioned trampolines, and give it the address of the callback closure: “<code>trampoline_call(#30987)</code>”.</p><p><strong>Isolation overhead</strong><br>Like a coin that has two sides, the new sandbox does come with some additional overhead. The portability and isolation that WebAssembly offers bring extra cost. Here, we'll list two examples.</p><p>Firstly, guest apps are not allowed to read host memory. The way it works is the guest provides a memory region via a host call, then the host writes the data into the guest memory space. This introduces a memory copy that would not be needed if we were outside the sandbox. The bad news is, in our use case, the guest apps are supposed to do something on the query and/or the response, so they almost always need to read data from the host on every single request. The good news, on the other hand, is that during a request life cycle, the data won’t change. So we pre-allocate a bulk of memory in the guest memory space right after the guest app instantiates. The allocated memory is not going to be used, but instead serves to occupy a hole in the address space. Once the host gets the address details, it maps a shared memory region with the common data needed by the guest into the guest’s space. When the guest code starts to execute, it can just access the data in the shared memory overlay, and no copy is needed.</p><p>Another issue we ran into was when we wanted to add support for a modern protocol, <a href="http://blog.cloudflare.com/oblivious-dns/">oDoH</a>, into BigPineapple. The main job of it is to decrypt the client query, resolve it, then encrypt the answers before sending it back. By design, this doesn’t belong to core DNS, and should instead be extended with a Wasm app. However, the WebAssembly instruction set doesn’t provide some crypto primitives, such as AES and SHA-2, which prevents it from getting the benefit of host hardware. There is ongoing work to bring this functionality to Wasm with <a href="https://github.com/WebAssembly/wasi-crypto">WASI-crypto</a>. Until then, our solution for this is to simply delegate the <a href="http://blog.cloudflare.com/hybrid-public-key-encryption/">HPKE</a> to the host via host calls, and we already saw 4x performance improvements, compared to doing it inside Wasm.</p><p><strong>Async in Wasm</strong><br>Remember the problem we talked about before that the callbacks could block the event loop? Essentially, the problem is how to run the sandboxed code asynchronously. Because no matter how complex the request processing callback is, if it can yield, we can put an upper bound on how long it is allowed to block. Luckily, Rust’s async framework is both elegant and lightweight. It gives us the opportunity to use a set of guest calls to implement the “Future”s.</p><p>In Rust, a Future is a building block for asynchronous computations. From the user’s perspective, in order to make an asynchronous program, one has to take care of two things: implement a pollable function that drives the state transition, and place a waker as a callback to wake itself up, when the pollable function should be called again due to some external event (e.g. time passes, socket becomes readable, and so on). The former is to be able to progress the program gradually, e.g. read buffered data from I/O and return a new state indicating the status of the task: either finished, or yielded. The latter is useful in case of task yielding, as it will trigger the Future to be polled when the conditions that the task was waiting for are fulfilled, instead of busy looping until it’s complete.</p><p>Let’s see how this is implemented in our sandbox. For a scenario when the guest needs to do some I/O, it has to do so via the host calls, as it is inside a restricted environment. Assuming the host provides a set of simplified host calls which mirror the basic socket operations: open, read, write, and close, the guest can have its pseudo poller defined as below:</p><!--kg-card-begin: markdown--><pre><code>fn poll(&amp;mut self, wake: fn()) -&gt; Poll { match hostcall_socket_read(self.sock, self.buffer) { HostOk =&gt; Poll::Ready, HostEof =&gt; Poll::Pending, } } </code></pre> <!--kg-card-end: markdown--><p>Here the host call reads data from a socket into a buffer, depending on its return value, the function can move itself to one of the states we mentioned above: finished(Ready), or yielded(Pending). The magic happens inside the host call. Remember in figure 5, that it is the only way to access resources? The guest app doesn’t own the socket, but it can acquire a “<code>handle” via “hostcall_socket_open</code>”, which will in turn create a socket on the host side, and return a handle. The handle can be anything in theory, but in practice using integer socket handles map well to file descriptors on the host side, or indices in a vector or slab. By referencing the returned handle, the guest app is able to remotely control the real socket. As the host side is fully asynchronous, it can simply relay the socket state to the guest. If you noticed that the waker function isn’t used above, well done! That’s because when the host call is called, it not only starts opening a socket, but also registers the current waker to be called then the socket is opened (or fails to do so). So when the socket becomes ready, the host task will be woken up, it will find the corresponding guest task from its context, and wakes it up using the trampoline function as shown in figure 5. There are other cases where a guest task needs to wait for another guest task, an async mutex for example. The mechanism here is similar: using host calls to register wakers.</p><p>All of these complicated things are encapsulated in our guest async runtime, with easy to use API, so the guest apps get access to regular async functions without having to worry about the underlying details.</p><h2 id="-not-the-end">(Not) The End</h2><p>Hopefully, this blog post gave you a general idea of the innovative platform that powers 1.1.1.1. It is still evolving. As of today, several of our products, such as <a href="http://blog.cloudflare.com/introducing-1-1-1-1-for-families/">1.1.1.1 for Families</a>, <a href="http://blog.cloudflare.com/the-as112-project/">AS112</a>, and <a href="https://www.cloudflare.com/products/zero-trust/gateway/">Gateway DNS</a>, are supported by guest apps running on BigPineapple. We are looking forward to bringing new technologies into it. If you have any ideas, please let us know in the <a href="https://community.cloudflare.com/c/zero-trust/dns-1111/47">community</a> or via <a href="mailto:resolver@cloudflare.com">email</a>.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ ROFL with a LOL: rewriting an NGINX module in Rust ]]>
</title>
<description>
<![CDATA[ Engineers at Cloudflare have written a replacement in Rust for one of the oldest and least-well understood parts of the Cloudflare infrastructure, cf-html, which is an NGINX module. In doing so we learned a lot about how NGINX works, and paved the way to move away from NGINX entirely. ]]>
</description>
<link>https://blog.cloudflare.com/rust-nginx-module/</link>
<guid isPermaLink="false">63f7b0f8917f76000a692dca</guid>
<category>
<![CDATA[ Lol-html ]]>
</category>
<category>
<![CDATA[ ROFL ]]>
</category>
<category>
<![CDATA[ NGINX ]]>
</category>
<category>
<![CDATA[ OpenResty ]]>
</category>
<dc:creator>
<![CDATA[ Sam Howson ]]>
</dc:creator>
<pubDate>Fri, 24 Feb 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/ROFL-with-a-LOL--rewriting-an-NGINX-module-in-Rust-OG-1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/ROFL-with-a-LOL--rewriting-an-NGINX-module-in-Rust-OG.png" class="kg-image" alt="ROFL with a LOL: rewriting an NGINX module in Rust"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/ROFL-with-a-LOL--rewriting-an-NGINX-module-in-Rust-OG-1.png" alt="ROFL with a LOL: rewriting an NGINX module in Rust"><p>At Cloudflare, engineers spend a great deal of time refactoring or rewriting existing functionality. When your company doubles the amount of traffic it handles every year, what was once an elegant solution to a problem can quickly become outdated as the engineering constraints change. Not only that, but when you're averaging 40 million requests a second, issues that might affect 0.001% of requests flowing through our network are big incidents which may impact millions of users, and one-in-a-trillion events happen several times a day.</p><p>Recently, we've been working on a replacement to one of our oldest and least-well-known components called cf-html, which lives inside the core reverse web proxy of Cloudflare known as FL (Front Line). Cf-html is the framework in charge of parsing and rewriting HTML as it streams back through from the website origin to the website visitor. Since the early days of Cloudflare, we’ve offered features which will rewrite the response body of web requests for you on the fly. The first ever feature we wrote in this way was to replace email addresses with chunks of JavaScript, which would then load the email address when viewed in a web browser. Since bots are often unable to evaluate JavaScript, this helps to prevent scraping of email addresses from websites. You can see this in action if you view the source of this page and look for this email address: foo@example.com.</p><p>FL is where most of the application infrastructure logic for Cloudflare runs, and largely consists of code written in the Lua scripting language, which runs on top of NGINX as part of <a href="https://openresty.org/en/">OpenResty</a>. In order to interface with NGINX directly, some parts (like cf-html) are written in lower-level languages like C and C++. In the past, there were many such OpenResty services at Cloudflare, but these days FL is one of the few left, as we move other components to <a href="http://blog.cloudflare.com/introducing-cloudflare-workers/">Workers</a> or <a href="http://blog.cloudflare.com/how-we-built-pingora-the-proxy-that-connects-cloudflare-to-the-internet/">Rust-based proxies</a>. The platform that once was the best possible blend of developer ease and speed has more than started to show its age for us.</p><p>When discussing what happens to an HTTP request passing through our network and in particular FL, nearly all the attention is given to what happens up until the request reaches the customer's origin. That’s understandable as this is where most of the business logic happens: firewall rules, Workers, and routing decisions all happen on the request. But it's not the end of the story. From an engineering perspective, much of the more interesting work happens on the response, as we stream the HTML response back from the origin to the site visitor.</p><p>The logic to handle this is contained in a static NGINX module, and runs in the <a href="http://nginx.org/en/docs/dev/development_guide.html#http_response_body_filters">Response Body Filters</a>  phase in NGINX, as chunks of the HTTP response body are streamed through. Over time, more features were added, and the system became known as cf-html. cf-html uses a streaming HTML parser to match on specific HTML tags and content, called <a href="https://github.com/cloudflare/lazyhtml">Lazy HTML</a> or lhtml, with much of the logic for both it and the cf-html features written using the <a href="http://www.colm.net/open-source/ragel/">Ragel</a> state machine engine.</p><h3 id="memory-safety">Memory safety</h3><p>All the cf-html logic was written in C, and therefore was susceptible to memory corruption issues that plague many large C codebases. In 2017 this led to a security bug as the team was trying to replace part of cf-html. FL was reading arbitrary data from memory and appending it to response bodies. This could potentially include data from other requests passing through FL at the same time. This security event became known widely as<a href="https://en.wikipedia.org/wiki/Cloudbleed"> Cloudbleed</a>.</p><p>Since this episode, Cloudflare implemented a number of policies and safeguards to ensure something like that never happened again. While work has been carried out on cf-html over the years, there have been few new features implemented on the framework, and we’re now hyper-sensitive to crashes happening in FL (and, indeed, any other process running on our network), especially in parts that can reflect data back with a response.</p><p>Fast-forward to 2022 into 2023, and the FL Platform team have been getting more and more requests for a system they can easily use to look at and rewrite response body data. At the same time, another team has been working on a new response body parsing and rewriting framework for Workers called<a href="https://github.com/cloudflare/lol-html"> lol-html</a> or Low Output Latency HTML. Not only is lol-html faster and more efficient than Lazy HTML, but it’s also currently in full production use as part of the Worker interface, and written in Rust, which is much safer than C in terms of its handling of memory. It’s ideal, therefore, as a replacement for the ancient and creaking HTML parser we’ve been using in FL up until now.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image1-8.png" class="kg-image" alt="ROFL with a LOL: rewriting an NGINX module in Rust"></figure><p>So we started working on a new framework, written in Rust, that would incorporate lol-html and allow other teams to write response body parsing features without the threat of causing massive security issues. The new system is called ROFL or Response Overseer for FL, and it’s a brand-new NGINX module written completely in Rust. As of now, ROFL is running in production on millions of responses a second, with comparable performance to cf-html. In building ROFL, we’ve been able to deprecate one of the scariest bits of code in Cloudflare’s entire codebase, while providing teams at Cloudflare with a robust system they can use to write features which need to parse and rewrite response body data.</p><h3 id="writing-an-nginx-module-in-rust">Writing an NGINX module in Rust</h3><p>While writing the new module, we learned a lot about how NGINX works, and how we can get it to talk to Rust. NGINX doesn’t provide much documentation on writing modules written in languages other than C, and so there was some work which needed to be done to figure out how to write an NGINX module in our language of choice. When starting out, we made heavy use of parts of the code from the <a href="https://github.com/dcoles/nginx-rs">nginx-rs</a> project, particularly around the handling of buffers and memory pools. While writing a full NGINX module in Rust is a long process and beyond the scope of this blog post, there are a few key bits that make the whole thing possible, and that are worth talking about.</p><p>The first one of these is generating the Rust bindings so that NGINX can communicate with it. To do that, we used Rust’s library <a href="https://rust-lang.github.io/rust-bindgen/">Bindgen</a> to build the FFI bindings for us, based on the symbol definitions in NGINX’s header files. To add this to an existing Rust project, the first thing is to pull down a copy of NGINX and configure it. Ideally this would be done in a simple script or Makefile, but when done by hand it would look something like this:</p><!--kg-card-begin: markdown--><pre><code class="language-unset">$ git clone --depth=1 https://github.com/nginx/nginx.git $ cd nginx $ ./auto/configure --without-http_rewrite_module --without-http_gzip_module </code></pre> <!--kg-card-end: markdown--><p>With NGINX in the right state, we need to create a <code>build.rs</code> file in our Rust project to auto-generate the bindings at build-time of the module. We’ll now add the necessary arguments to the build, and use Bindgen to generate us the <code>bindings.rs</code> file. For the arguments, we just need to include all the directories that may contain header files for clang to do its thing. We can then feed them into Bindgen, along with some allowlist arguments, so it knows for what things it should generate the bindings, and which things it can ignore. Adding a little boilerplate code to the top, the whole file should look something like this:</p><!--kg-card-begin: markdown--><pre><code class="language-unset">use std::env; use std::path::PathBuf; fn main() { println!(&quot;cargo:rerun-if-changed=build.rs&quot;); let clang_args = [ &quot;-Inginx/objs/&quot;, &quot;-Inginx/src/core/&quot;, &quot;-Inginx/src/event/&quot;, &quot;-Inginx/src/event/modules/&quot;, &quot;-Inginx/src/os/unix/&quot;, &quot;-Inginx/src/http/&quot;, &quot;-Inginx/src/http/modules/&quot; ]; let bindings = bindgen::Builder::default() .header(&quot;wrapper.h&quot;) .layout_tests(false) .allowlist_type(&quot;ngx_.*&quot;) .allowlist_function(&quot;ngx_.*&quot;) .allowlist_var(&quot;NGX_.*|ngx_.*|nginx_.*&quot;) .parse_callbacks(Box::new(bindgen::CargoCallbacks)) .clang_args(clang_args) .generate() .expect(&quot;Unable to generate bindings&quot;); let out_path = PathBuf::from(env::var(&quot;OUT_DIR&quot;).unwrap()); bindings.write_to_file(out_path.join(&quot;bindings.rs&quot;)) .expect(&quot;Unable to write bindings.&quot;); } </code></pre> <!--kg-card-end: markdown--><p>Hopefully this is all fairly self-explanatory. Bindgen traverses the NGINX source and generates equivalent constructs in Rust in a file called <code>bindings.rs</code>, which we can import into our project. There’s just one more thing to add- Bindgen has trouble with a couple of symbols in NGINX, which we’ll need to fix in a file called <code>wrapper.h</code>. It should have the following contents:</p><!--kg-card-begin: markdown--><pre><code class="language-unset">#include &lt;ngx_http.h&gt; const char* NGX_RS_MODULE_SIGNATURE = NGX_MODULE_SIGNATURE; const size_t NGX_RS_HTTP_LOC_CONF_OFFSET = NGX_HTTP_LOC_CONF_OFFSET; </code></pre> <!--kg-card-end: markdown--><p>With this in place and <a href="https://crates.io/crates/bindgen">Bindgen</a> set in the <code>[build-dependencies]</code> section of the Cargo.toml file, we should be ready to build.</p><!--kg-card-begin: markdown--><pre><code class="language-unset">$ cargo build Compiling rust-nginx-module v0.1.0 (/Users/sam/cf-repos/rust-nginx-module) Finished dev [unoptimized + debuginfo] target(s) in 4.70s </code></pre> <!--kg-card-end: markdown--><p>With any luck, we should see a file called bindings.rs in the target/debug/build directory, which contains Rust definitions of all the NGINX symbols.</p><!--kg-card-begin: markdown--><pre><code class="language-unset">$ find target -name 'bindings.rs' target/debug/build/rust-nginx-module-c5504dc14560ecc1/out/bindings.rs $ head target/debug/build/rust-nginx-module-c5504dc14560ecc1/out/bindings.rs /* automatically generated by rust-bindgen 0.61.0 */ [...] </code></pre> <!--kg-card-end: markdown--><p>To be able to use them in the project, we can include them in a new file under the <code>src</code> directory which we’ll call <code>bindings.rs</code>.</p><!--kg-card-begin: markdown--><pre><code class="language-unset">$ cat &gt; src/bindings.rs include!(concat!(env!(&quot;OUT_DIR&quot;), &quot;/bindings.rs&quot;)); </code></pre> <!--kg-card-end: markdown--><p>With that set, we just need to add the usual imports to the top of the <code>lib.rs</code> file, and we can access NGINX constructs from Rust. Not only does this make bugs in the interface between NGINX and our Rust module much less likely than if these values were hand-coded, but it’s also a fantastic reference we can use to check the structure of things in NGINX when building modules in Rust, and it takes a lot of the leg-work out of setting everything up. It’s really a testament to the quality of a lot of Rust libraries such as Bindgen that something like this can be done with so little effort, in a robust way.</p><p>Once the Rust library has been built, the next step is to hook it into NGINX. Most NGINX modules are compiled statically. That is, the module is compiled as part of the compilation of NGINX as a whole. However, since NGINX 1.9.11, it has supported dynamic modules, which are compiled separately and then loaded using the <code>load_module</code> directive in the <code>nginx.conf</code> file. This is what we needed to use to build ROFL, so that the library could be compiled separately and loaded-in at the time NGINX starts up. Finding the right format so that the necessary symbols could be found from the documentation was tricky, though, and although it is possible to use a separate config file to set some of this metadata, it’s better if we can load it as part of the module, to keep things neat. Luckily, it doesn’t take much spelunking through the NGINX codebase to find where <code>dlopen</code> is called.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image2-3.png" class="kg-image" alt="ROFL with a LOL: rewriting an NGINX module in Rust"></figure><p>So after that it’s just a case of making sure the relevant symbols exist.</p><!--kg-card-begin: markdown--><pre><code class="language-unset">use std::os::raw::c_char; use std::ptr; #[no_mangle] pub static mut ngx_modules: [*const ngx_module_t; 2] = [ unsafe { rust_nginx_module as *const ngx_module_t }, ptr::null() ]; #[no_mangle] pub static mut ngx_module_type: [*const c_char; 2] = [ &quot;HTTP_FILTER\0&quot;.as_ptr() as *const c_char, ptr::null() ]; #[no_mangle] pub static mut ngx_module_names: [*const c_char; 2] = [ &quot;rust_nginx_module\0&quot;.as_ptr() as *const c_char, ptr::null() ]; </code></pre> <!--kg-card-end: markdown--><p>When writing an NGINX module, it’s crucial to get its order relative to the other modules correct. Dynamic modules get loaded as NGINX starts, which means they are (perhaps counterintuitively) the first to run on a response. Ensuring your module runs after gzip decompression by specifying its order relative to the gunzip module is essential, otherwise you can spend lots of time staring at streams of unprintable characters, wondering why you aren’t seeing the response you expected. Not fun. Fortunately this is also something that can be solved by looking at the NGINX source, and making sure the relevant entities exist in your module. Here’s an example of what you might set-</p><!--kg-card-begin: markdown--><pre><code class="language-unset">pub static mut ngx_module_order: [*const c_char; 3] = [ &quot;rust_nginx_module\0&quot;.as_ptr() as *const c_char, &quot;ngx_http_headers_more_filter_module\0&quot;.as_ptr() as *const c_char, ptr::null() ]; </code></pre> <!--kg-card-end: markdown--><p>We’re essentially saying we want our module <code>rust_nginx_module</code> to run just before the <code>ngx_http_headers_more_filter_module</code> module, which should allow it to run in the place we expect.</p><p>One of the quirks of NGINX and OpenResty is how it is really hostile to making calls to external services at the point that you’re dealing with the HTTP response. It’s something that isn’t provided as part of the OpenResty Lua framework, even though it would make working with the response phase of a request much easier. While we could do this anyway, that would mean having to fork NGINX and OpenResty, which would bring its own challenges. As a result, we’ve spent a lot of time over the years thinking about ways to pass state from the time when NGINX’s dealing with an HTTP request, over to the time when it’s streaming through the response, and much of our logic is built around this style of work.</p><p>For ROFL, that means in order to determine if we need to apply a certain feature for a response, we need to figure that out on the request, then pass that information over to the response so that we know which features to activate. To do that, we need to use one of the utilities that NGINX provides you with. With the help of the <code>bindings.rs</code> file generated earlier, we can take a look at the definition of the <code>ngx_http_request_s</code> struct, which contains all the state associated with a given request:</p><!--kg-card-begin: markdown--><pre><code class="language-unset">#[repr(C)] #[derive(Debug, Copy, Clone)] pub struct ngx_http_request_s { pub signature: u32, pub connection: *mut ngx_connection_t, pub ctx: *mut *mut ::std::os::raw::c_void, pub main_conf: *mut *mut ::std::os::raw::c_void, pub srv_conf: *mut *mut ::std::os::raw::c_void, pub loc_conf: *mut *mut ::std::os::raw::c_void, pub read_event_handler: ngx_http_event_handler_pt, pub write_event_handler: ngx_http_event_handler_pt, pub cache: *mut ngx_http_cache_t, pub upstream: *mut ngx_http_upstream_t, pub upstream_states: *mut ngx_array_t, pub pool: *mut ngx_pool_t, pub header_in: *mut ngx_buf_t, pub headers_in: ngx_http_headers_in_t, pub headers_out: ngx_http_headers_out_t, pub request_body: *mut ngx_http_request_body_t, [...] } </code></pre> <!--kg-card-end: markdown--><p>As we can see, there’s a member called <code>ctx</code>. As the<a href="http://nginx.org/en/docs/dev/development_guide.html#http_request"> NGINX Development Guide mentions</a>, it’s a place where you’re able to store any value associated with a request, which should live for as long as the request does. In OpenResty this is used heavily for the storing of state to do with a request over its lifetime in a Lua context. We can do the same thing for our module, so that settings initialised during the request phase are there when our HTML parsing and rewriting is run in the response phase. Here’s an example function which can be used to get the request <code>ctx</code>:</p><!--kg-card-begin: markdown--><pre><code>pub fn get_ctx(request: &amp;ngx_http_request_t) -&gt; Option&lt;&amp;mut Ctx&gt; { unsafe { match *request.ctx.add(ngx_http_rofl_module.ctx_index) { p if p.is_null() =&gt; None, p =&gt; Some(&amp;mut *(p as *mut Ctx)), } } } </code></pre> <!--kg-card-end: markdown--><p>Notice that <code>ctx</code> is at the offset of the <code>ctx_index</code> member of <code>ngx_http_rofl_module</code> - this is the structure of type <code>ngx_module_t</code> that’s part of the module definition needed to make an NGINX module. Once we have this, we can point it to a structure containing any setting we want. For example, here’s the actual function we use to enable the Email Obfuscation feature from Lua, via FFI to the Rust module using LuaJIT’s FFI tools:</p><!--kg-card-begin: markdown--><pre><code>#[no_mangle] pub extern &quot;C&quot; fn rofl_module_email_obfuscation_new( request: &amp;mut ngx_http_request_t, dry_run: bool, decode_script_url: *const u8, decode_script_url_len: usize, ) { let ctx = context::get_or_init_ctx(request); let decode_script_url = unsafe { std::str::from_utf8(std::slice::from_raw_parts(decode_script_url, decode_script_url_len)) .expect(&quot;invalid utf-8 string for decode script&quot;) }; ctx.register_module(EmailObfuscation::new(decode_script_url.to_owned()), dry_run); } </code></pre> <!--kg-card-end: markdown--><p>The function is called <code>get_or_init_ctx</code> here- it performs the same job as <code>get_ctx</code>, but also initialises the structure if it doesn’t exist yet. Once we’ve set whatever data we need in <code>ctx</code> during the request, we can then check what features need to be run in the response, without having to make any calls to external databases, which might slow us down.</p><p>One of the nice things about storing state on <code>ctx</code> in this way, and working with NGINX in general, is that it relies heavily on memory pools to store request content. This largely removes any need for the programmer to have to think about freeing memory after use- the pool is automatically allocated at the start of a request, and is automatically freed when the request is done. All that’s needed is to allocate the memory using NGINX’s built-in functions for<a href="https://www.nginx.com/resources/wiki/extending/api/alloc/#c.ngx_palloc"> allocating memory to the pool</a> and then<a href="http://www.nginx.com/resources/wiki/extending/api/alloc/#c.ngx_pool_cleanup_add"> registering a callback</a> that will be called to free everything. In Rust, that would look something like the following:</p><!--kg-card-begin: markdown--><pre><code>pub struct Pool&lt;'a&gt;(&amp;'a mut ngx_pool_t); impl&lt;'a&gt; Pool&lt;'a&gt; { /// Register a cleanup handler that will get called at the end of the request. fn add_cleanup&lt;T&gt;(&amp;mut self, value: *mut T) -&gt; Result&lt;(), ()&gt; { unsafe { let cln = ngx_pool_cleanup_add(self.0, 0); if cln.is_null() { return Err(()); } (*cln).handler = Some(cleanup_handler::&lt;T&gt;); (*cln).data = value as *mut c_void; Ok(()) } } /// Allocate memory for a given value. pub fn alloc&lt;T&gt;(&amp;mut self, value: T) -&gt; Option&lt;&amp;'a mut T&gt; { unsafe { let p = ngx_palloc(self.0, mem::size_of::&lt;T&gt;()) as *mut _ as *mut T; ptr::write(p, value); if let Err(_) = self.add_cleanup(p) { ptr::drop_in_place(p); return None; }; Some(&amp;mut *p) } } } unsafe extern &quot;C&quot; fn cleanup_handler&lt;T&gt;(data: *mut c_void) { ptr::drop_in_place(data as *mut T); } </code></pre> <!--kg-card-end: markdown--><p>This should allow us to allocate memory for whatever we want, safe in the knowledge that NGINX will handle it for us.</p><p>It is regrettable that we have to write a lot of <code>unsafe</code> blocks when dealing with NGINX’s interface in Rust. Although we’ve done a lot of work to minimise them where possible, unfortunately this is often the case with writing Rust code which has to manipulate C constructs through FFI. We have plans to do more work on this in the future, and remove as many lines as possible from <code>unsafe</code>.</p><h3 id="challenges-encountered">Challenges encountered</h3><p>The NGINX module system allows for a massive amount of flexibility in terms of the way the module itself works, which makes it very accommodating to specific use-cases, but that flexibility can also lead to problems. One that we ran into had to do with the way the response data is handled between Rust and FL. In NGINX, response bodies are chunked, and these chunks are then linked together into a list. Additionally, there may be more than one of these linked lists per response, if the response is large.</p><p>Efficiently handling these chunks means processing them and passing them on as quickly as possible. When writing a Rust module for manipulating responses, it’s tempting to implement a Rust-based view into these linked lists. However, if you do that, you must be sure to update both the Rust-based view and the underlying NGINX data structures when mutating them, otherwise this can lead to serious bugs where Rust becomes out of sync with NGINX. Here’s a small function from an early version of ROFL that caused headaches:</p><!--kg-card-begin: markdown--><pre><code>fn handle_chunk(&amp;mut self, chunk: &amp;[u8]) { let mut free_chain = self.chains.free.borrow_mut(); let mut out_chain = self.chains.out.borrow_mut(); let mut data = chunk; self.metrics.borrow_mut().bytes_out += data.len() as u64; while !data.is_empty() { let free_link = self .pool .get_free_chain_link(free_chain.head, self.tag, &amp;mut self.metrics.borrow_mut()) .expect(&quot;Could not get a free chain link.&quot;); let mut link_buf = unsafe { TemporaryBuffer::from_ngx_buf(&amp;mut *(*free_link).buf) }; data = link_buf.write_data(data).unwrap_or(b&quot;&quot;); out_chain.append(free_link); } } </code></pre> <!--kg-card-end: markdown--><p>What this code was supposed to do is take the output of lol-html’s HTMLRewriter, and write it to the output chain of buffers. Importantly, the output can be larger than a single buffer, so you need to take new buffers off the chain in a loop until you’ve written all the output to buffers. Within this logic, NGINX is supposed to take care of popping the buffer off the free chain and appending the new chunk to the output chain, which it does. However, if you’re only thinking in terms of the way NGINX handles its view of the linked list, you may not notice that Rust never changes which buffer its <code>free_chain.head</code> points to, causing the logic to loop forever and the NGINX worker process to lock-up completely. This sort of issue can take a long time to track down, especially since we couldn’t reproduce it on our personal machines until we understood it was related to the response body size.</p><p>Getting a coredump to perform some analysis with gdb was also hard because once we noticed it happening, it was already too late and the process memory had grown to the point the server was in danger of falling over, and the memory consumed was too large to be written to disk. Fortunately, this code never made it to production. As ever, while Rust’s compiler can help you to catch a lot of common mistakes, it can’t help as much if the data is being shared via FFI from another environment, even without much direct use of <code>unsafe</code>, so extra care must be taken in these cases, especially when NGINX allows the kind of flexibility that might lead to a whole machine being taken out of service.</p><p>Another major challenge we faced had to do with backpressure from incoming response body chunks. In essence, if ROFL increased the size of the response due to having to inject some large amount of code into the stream (such as replacing an email address with a large chunk of JavaScript), NGINX can feed the output from ROFL to the other downstream modules faster than they could push it along, potentially leading to data being dropped and HTTP response bodies being truncated if the <code>EAGAIN</code> error from the next module is left unhandled. This was another case where the issue was really hard to test, because most of the time the response would be flushed fast enough for backpressure never to be a problem. To handle this, we had to create a special chain to store these chunks called <code>saved_in</code>, which required a special method for appending to it.</p><!--kg-card-begin: markdown--><pre><code>#[derive(Debug)] pub struct Chains { /// This saves buffers from the `in` chain that were not processed for any reason (most likely /// backpressure for the next nginx module). saved_in: RefCell&lt;Chain&gt;, pub free: RefCell&lt;Chain&gt;, pub busy: RefCell&lt;Chain&gt;, pub out: RefCell&lt;Chain&gt;, [...] } </code></pre> <!--kg-card-end: markdown--><p>Effectively we’re ‘queueing’ the data for a short period of time so that we don’t overwhelm the other modules by feeding them data faster than they can handle it. The <a href="https://nginx.org/en/docs/dev/development_guide.html">NGINX Developer Guide</a> has a lot of great information, but many of its examples are trivial to the point where issues like this don’t come up. Things such as this are the result of working in a complex NGINX-based environment, and need to be discovered independently.</p><h3 id="a-future-without-nginx">A future without NGINX</h3><p>The obvious question a lot of people might ask is: why are we still using NGINX? As already mentioned, Cloudflare is well on its way to replacing components that either used to run NGINX/OpenResty proxies, or would have done without heavy investment in home-grown platforms. That said, some components are easier to replace than others and FL, being where most of the logic for Cloudflare’s application services runs, is definitely on the more challenging end of the spectrum.</p><p>Another motivating reason for doing this work is that whichever platform we eventually migrate to, we’ll need to run the features that make up cf-html, and in order to do that we’ll want to have a system that is less heavily integrated and dependent on NGINX. ROFL has been specifically designed with the intention of running it in multiple places, so it will be easy to move it to another Rust-based web proxy (or indeed our Workers platform) without too much trouble. That said it’s hard to imagine we’d be in the same place without a language like Rust, which offers speed at the same time as a high degree of safety, not to mention high-quality libraries like Bindgen and Serde. More broadly, the FL team are working to migrate other aspects of the platform over to Rust, and while cf-html and the features of which make it up are a key part of our infrastructure that needed work, there are many others.</p><p>Safety in programming languages is often seen as beneficial in terms of preventing bugs, but as a company we’ve found that it also allows you to do things which would be considered very hard, or otherwise impossible to do safely. Whether it be providing a <a href="https://developers.cloudflare.com/firewall/cf-firewall-rules/">Wireshark-like filter language for writing firewall rules</a>,<a href="https://workers.cloudflare.com/"> allowing millions of users to write arbitrary JavaScript code and run it directly on our platform</a> or rewriting HTML responses on the fly, having strict boundaries in place allows us to provide services we wouldn’t be able to otherwise, all while safe in the knowledge that the kind of memory-safety issues that used to plague the industry are increasingly a thing of the past.</p><p>If you enjoy rewriting code in Rust, solving challenging application infrastructure problems and want to help maintain the busiest web server in the world, we’re <a href="https://www.cloudflare.com/careers/jobs/">hiring</a>!</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ One year of war in Ukraine: Internet trends, attacks, and resilience ]]>
</title>
<description>
<![CDATA[ This blog post reports on Internet insights during an historical war in Europe that has been seen and shared online, and discusses how Ukraine's Internet remained resilient in spite of dozens of disruptions in three different stages of the conflict. ]]>
</description>
<link>https://blog.cloudflare.com/one-year-of-war-in-ukraine/</link>
<guid isPermaLink="false">63f77a8635b40c000afc5067</guid>
<category>
<![CDATA[ Cloudflare Radar ]]>
</category>
<category>
<![CDATA[ Ukraine ]]>
</category>
<category>
<![CDATA[ Outage ]]>
</category>
<category>
<![CDATA[ Project Galileo ]]>
</category>
<category>
<![CDATA[ Trends ]]>
</category>
<category>
<![CDATA[ Russia ]]>
</category>
<dc:creator>
<![CDATA[ João Tomé ]]>
</dc:creator>
<pubDate>Thu, 23 Feb 2023 15:58:55 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/image13-1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image13-2.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><!--kg-card-begin: markdown--><img src="http://blog.cloudflare.com/content/images/2023/02/image13-1.png" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"><p>The Internet has become a significant factor in geopolitical conflicts, such as the ongoing war in Ukraine. Tomorrow marks one year since the Russian invasion of that country. This post reports on Internet insights and discusses how Ukraine's Internet remained resilient in spite of dozens of disruptions in three different stages of the conflict.</p> <!--kg-card-end: markdown--><p>Key takeaways:</p><ul><li>Internet traffic shifts in Ukraine are clearly visible from east to west as Ukrainians fled the war, with country-wide traffic dropping as much as 33% after February 24, 2022.</li><li>Air strikes on energy infrastructure starting in October led to widespread Internet disruptions that continue in 2023.</li><li>Application-layer cyber attacks in Ukraine rose 1,300% in early March 2022 compared to pre-war levels.</li><li>Government administration, financial services, and the media saw the most attacks targeting Ukraine.</li><li>Traffic from a number of networks in Kherson was re-routed through Russia between June and October, subjecting traffic to Russia’s restrictions and limitations, including content filtering. Even after traffic ceased to reroute through Russia, those Ukrainian networks saw major outages through at least the end of the year, while two networks remain offline.</li><li>Through efforts on the ground to repair damaged fiber optics and restore electrical power, Ukraine’s networks have remained resilient from both an infrastructure and routing perspective. This is partly due to Ukraine’s widespread connectivity to networks outside the country and large number of IXPs.</li><li>Starlink traffic in Ukraine grew over 500% between mid-March and mid-May, and continued to grow from mid-May through mid-November, increasing nearly 300% over that six-month period. For the full period from mid-March (two weeks after it was made available) to mid-December, it was over a 1,600% increase, dropping a bit after that.</li></ul><h2 id="internet-changes-and-disruptions">Internet changes and disruptions</h2><h3 id="an-internet-shock-after-february-24-2022">An Internet shock after February 24, 2022</h3><p>In Ukraine, human Internet traffic dropped as much as 33% in the weeks following February 24. The following chart shows Cloudflare’s perspective on daily traffic (by number of requests).</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Internet traffic levels recovered over the next few months, including strong growth seen in September and October, when many Ukrainian refugees <a href="https://en.wikipedia.org/wiki/2022%E2%80%932023_Ukrainian_refugee_crisis">returned</a> to the country. That said, there were also country-wide outages, mostly after October, that are discussed below.</p><p>14% of total traffic <em>from</em> Ukraine (including traffic from Crimea and other occupied regions) was mitigated as potential attacks, while 10% of total traffic <em>to</em> Ukraine was mitigated as potential attacks in the last 12 months.</p><p>Before February 24, 2022, typical weekday Internet traffic in Ukraine initially peaked after lunch, around 15:00 local time, dropped between 17:00 and 18:00 (consistent with people leaving work), and reached the biggest peak of the day at around 21:00 (possibly after dinner for mobile and streaming use).</p><p>After the invasion started, we observed less variation during the day in a clear change in the usual pattern given the reported disruption and “<a href="https://www.france24.com/en/europe/20220226-exodus-from-ukraine-a-night-spent-with-civilians-fleeing-war-russia-s-invasion">exodus</a>” from the country​. During the first few days after the invasion began, peak traffic occurred around 19:00, at a time when nights for many in cities such as Kyiv were spent in improvised underground <a href="https://www.newyorker.com/magazine/2022/03/14/inside-kyivs-metro-a-citywide-bomb-shelter">bunkers</a>. By late March, the 21:00 peak had returned, but the early evening drop in traffic did not return until May.</p><p>When looking at Ukraine Internet requests by type of traffic<strong> </strong>in the chart below (from February 10, 2022, through February 2023), we observe that while traffic from both mobile and desktop devices dropped after the invasion, request volume from mobile devices has remained higher over the past year. Pre-war, mobile devices accounted for around 53% of traffic, and grew to around 60% during the first weeks of the invasion. By late April, it had returned to typical pre-war levels, falling back to around 54% of traffic. There’s also a noticeable December drop/outage that we’ll go over below.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--1-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h3 id="millions-moving-from-east-to-west-in-ukraine">Millions moving from east to west in Ukraine</h3><p>The invasion brought attacks and failing infrastructure across a number of cities, but the target in the early days wasn’t the country’s energy infrastructure, as it was in October 2022. In the first weeks of the war, <a href="http://blog.cloudflare.com/internet-traffic-patterns-in-ukraine-since-february-21-2022/">Internet traffic changes</a> were largely driven by people evacuating conflict zones with their families. Over <a href="https://en.wikipedia.org/wiki/2022%E2%80%932023_Ukrainian_refugee_crisis">eight million</a> Ukrainians left the country in the first three months, and many more relocated internally to safer cities, although many returned during the summer of 2022. The Internet played a critical role during this refugee crisis, supporting communications and access to real-time information that could save lives, as well as apps providing services, among others.</p><p>There was also an increase in traffic in the western part of Ukraine, in areas such as Lviv (further away from the conflict areas), and a decrease in the east, in areas like Kharkiv, where the Russian military was arriving and attacks were a constant threat. The figure below provides a view of how Internet traffic across Ukraine changed in the week after the war began (a darker pink means a drop in traffic — as much as 60% — while a darker green indicates an increase in Internet traffic — as much as 50%).</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled-1.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"><figcaption>Source: <a href="https://datawrapper.dwcdn.net/dsUSJ/2/">https://datawrapper.dwcdn.net/dsUSJ/2/</a></figcaption></figure><p>The biggest drops in Internet traffic observed in Ukraine in the first days of the war were in Kharkiv Oblast in the east, and Chernihiv in the north, both with a 60% decrease, followed by Kyiv Oblast, with traffic 40% lower on March 2, 2022, as compared with February 23.</p><p>In western Ukraine, traffic surged. The regions with the highest observed traffic growth included Rivne (50%), Volyn (30%), Lviv (28%), Chernivtsi (25%), and Zakarpattia (15%).</p><p>At the city level, analysis of Internet traffic in Ukraine gives us some insight into usage of the Internet and availability of Internet access in those first weeks, with noticeable outages in places where direct conflict was going on or that was already occupied by Russian soldiers.</p><p>North of Kyiv, the city of <strong>Chernihiv</strong> had a significant drop in traffic the first week of the war and residual traffic by mid-March, with traffic picking up only after the Russians retreated in early April.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/che-2023-02-16-at-14.04.32.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In the capital city of <strong>Kyiv</strong>, there is a clear disruption in Internet traffic right after the war started, possibly caused by people leaving, attacks and use of underground shelters.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--1-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Near Kyiv, we observed a clear outage in early March in <strong>Bucha</strong>. After April 1, when the Russians withdrew, Internet traffic started to come back a few weeks later.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled.jpg" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In <strong>Irpin</strong>, just outside Kyiv, close to the Hostomel airport and Bucha, a similar outage pattern to Bucha was observed. Traffic only began to come back more clearly in late May.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--2-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In the east, in the city of <strong>Kharkiv</strong>, traffic dropped 50% on March 3, with a similar scenario seen not far away in Sumy. The disruption was related to people leaving and also by power outages affecting some networks.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--3-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Other cities in the south of Ukraine, like Berdyansk, had outages. This graph shows Enerhodar, the small city where Europe’s largest nuclear plant, <a href="https://en.wikipedia.org/wiki/Zaporizhzhia_Nuclear_Power_Plant">Zaporizhzhya NPP</a>, is located, with residual traffic compared to before.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--4-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In the cities located in the south of Ukraine, there were clear Internet disruptions. The Russians laid <a href="https://en.wikipedia.org/wiki/Siege_of_Mariupol">siege</a> to Mariupol on February 24. Energy infrastructure strikes and shutdowns had an impact on local networks and Internet traffic, which fell to minimal levels by March 1. Estimates indicate that <a href="https://web.archive.org/web/20220418203018/https://www.cnbc.com/2022/04/17/russia-ukraine-live-updates.html">95%</a> of the buildings in the city were destroyed, and by mid-May, the city was fully under Russian control. While there was some increase in traffic by the end of April, it reached only ~22% of what it was before the war’s start.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--5-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>When looking at Ukrainian Internet Service Providers (ISPs) or the autonomous systems (<a href="https://www.cloudflare.com/learning/network-layer/what-is-an-autonomous-system/">ASNs</a>) they use, we observed more localized disruptions in certain regions during the first months of the war, but recovery was almost always swift. <a href="https://radar.cloudflare.com/as6849">AS6849 (Ukrtel)</a> experienced problems with very short-term outages in mid-March. <a href="https://radar.cloudflare.com/as13188">AS13188 (Triolan)</a>, which services Kyiv, Chernihiv, and Kharkiv, was another provider experiencing problems (they <a href="https://t.me/triolan_me/630">reported</a> a cyberattack on March 9), as could be observed in the next chart:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--6-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>We did not observe a clear national outage in Ukraine’s main ISP, <a href="https://radar.cloudflare.com/as15895">AS15895 (Kyivstar)</a> until the October-November attacks on energy infrastructure, which also shows some early resilience of Ukrainian networks.</p><h3 id="ukraine-s-counteroffensive-and-its-internet-impact">Ukraine’s counteroffensive and its Internet impact</h3><p>As Russian troops retreated from the northern front in Ukraine, they shifted their efforts to gain ground in the east (<a href="https://en.wikipedia.org/wiki/Battle_of_Donbas_(2022%E2%80%93present)">Battle of Donbas</a>) and south (occupation of the <a href="https://en.wikipedia.org/wiki/Russian_occupation_of_Kherson_Oblast">Kherson region</a>) after late April. This resulted in Internet disruptions and traffic <a href="http://blog.cloudflare.com/tracking-shifts-in-internet-connectivity-in-kherson-ukraine/">shifts</a>, which are discussed in more detail in a section below. However, Internet traffic in the Kherson region was intermittent and included outages after May, given the battle for Internet control. News reports in <a href="https://www.bloomberg.com/news/articles/2022-06-21/ukrainian-telecom-workers-damage-own-equipment-to-thwart-russia">June</a> revealed that ISP workers damaged their own equipment to thwart Russia’s efforts to control the Ukrainian Internet.</p><p>Before the September Ukrainian counteroffensive, another example of the war’s impact on a city’s Internet traffic occurred during the summer, when Russian troops seized Lysychansk in eastern Ukraine in early <a href="https://www.cnn.com/2022/07/03/europe/russia-ukraine-luhansk-lysychansk-intl/index.html">July</a> after what became known as the <a href="https://en.wikipedia.org/wiki/Battle_of_Lysychansk">Battle of Lysychansk</a>. Internet traffic in Lysychansk clearly decreased after the war started. That slide continues during the intense <a href="https://en.wikipedia.org/wiki/Battle_of_Lysychansk">fighting</a> that took place after April, which led to most of the city’s population <a href="https://news.yahoo.com/12-000-lysychansk-residents-remain-194356536.html?fr=sycsrp_catchall">leaving</a>. By May, traffic was almost residual (with a mid-May few days short term increase).</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Lysychansk.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In early September the Ukrainian <a href="https://en.wikipedia.org/wiki/2022_Kharkiv_counteroffensive">counteroffensive</a> took off in the east, although the media initially <a href="https://www.euronews.com/2022/08/29/ukraine-launches-counter-offensive-to-retake-kherson-say-authorities">reported</a> a south offensive in <a href="https://en.wikipedia.org/wiki/2022_Kherson_counteroffensive">Kherson Oblast</a> that was a “<a href="https://mwi.usma.edu/the-kherson-ruse-ukraine-and-the-art-of-military-deception/">deception</a>” move. The Kherson offensive only came to fruition in late October and early November. Ukraine was able to retake in September over 500 settlements and 12,000 square kilometers of territory in the Kharkiv region. At that time, there were Internet outages in several of those settlements.</p><p>In response to the successful Ukrainian counteroffensive, Russian airstrikes caused power outages and Internet disruptions in the region. That was the case in <a href="https://twitter.com/CloudflareRadar/status/1569055256889147394">Kharkiv</a> on September 11, 12, and 13. The figure below shows a 12-hour near-complete outage on September 11, followed by two other periods of drop in traffic.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0.jpg" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h3 id="when-nuclear-inspectors-arrive-so-do-internet-outages">When nuclear inspectors arrive, so do Internet outages</h3><p>In the Zaporizhzhia region, there were also outages. On September 1, 2022, the day the International Atomic Energy Agency (IAEA) inspectors <a href="https://www.cnn.com/2022/09/01/europe/ukraine-zaporizhzhia-iaea-inspectors-intl/index.html">arrived</a> at the Russian-controlled Zaporizhzhia nuclear power plant in Enerhodar, there were Internet outages in two local ASNs that service the area: <a href="https://radar.cloudflare.com/as199560">AS199560 (Engrup)</a> and <a href="https://radar.cloudflare.com/as197002">AS197002<strong> </strong>(OOO Tenor<strong>)</strong></a>. Those outages lasted until September 10, as shown in the charts below.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image5-4.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p></p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image2-10.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>More broadly, the city of Enerhodar, where the nuclear power plant is located, experienced a four-day outage after September 6.</p><h3 id="mid-september-traffic-drop-in-crimea">Mid-September traffic drop in Crimea</h3><p>In mid-September, following Ukraine’s counteroffensive, there were questions as to when Crimea might be targeted by Ukrainian forces, with <a href="https://twitter.com/KyivIndependent/status/1569659989417152515?s=20">news reports</a> indicating that there was an evacuation of the Russian population from Crimea around September 13. We saw a clear drop in traffic on that Tuesday, compared with the previous day, as seen in the map of Crimea below (red is decrease in traffic, green is increase).</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--8-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h3 id="october-brings-energy-infrastructure-attacks-and-country-wide-disruptions">October brings energy infrastructure attacks and country-wide disruptions</h3><p>As we have seen, the Russian air strikes targeting critical energy infrastructure began in September as a retaliation to Ukraine's counteroffensive. The following month, the <a href="https://en.wikipedia.org/wiki/Crimean_Bridge_explosion">Crimean Bridge explosion</a> on Saturday, October 8 (when a truck-borne bomb destroyed part of the bridge) led to more air strikes that affected networks and Internet traffic across Ukraine.</p><p>On Monday, October 10, Ukraine woke up to air strikes on energy infrastructure and experienced severe electricity and Internet outages. At 07:35 UTC, traffic in the country was 35% below its usual level compared with the previous week and only fully recovered more than 24 hours later. The impact was particularly significant in regions like Kharkiv, where traffic was down by around 80%, and Lviv, where it dropped by about 60%. The graph below shows how new air strikes in Lviv Oblast the following day affected Internet traffic.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--3-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>There were clear disruptions in Internet connectivity in several regions on October 17, but also on <a href="https://twitter.com/CloudflareRadar/status/1583102832810790920">October 20</a>, when the destruction of several power stations in Kyiv resulted in a 25% drop in Internet traffic from Kyiv City as compared to the two previous weeks. It lasted 12 hours, and was followed the next day by a shorter partial outage as seen in the graph below.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--4-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In late October, <a href="https://www.politico.eu/article/russia-strike-several-energy-power-station-ukraine-cause-outage-zelenskyy/">according</a> to Ukrainian officials, 30% of Ukraine’s power stations were destroyed. Self-imposed power limitations because of this destruction resulted in drops in Internet traffic observed in places like Kyiv and the surrounding region.</p><p>The start of a multi-week Internet disruption in Kherson Oblast can be seen in the graph below, showing ~70% lower traffic than in previous weeks. The disruption began on Saturday, October 22, when Ukrainians were gaining ground in the Kherson region.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--5-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Traffic began to return after Ukrainian forces <a href="https://en.wikipedia.org/wiki/2022_Kherson_counteroffensive">took Kherson city</a> on November 11, 2022. The graph below shows a week-over-week comparison for Kherson Oblast for the weeks of November 7, November 28, and December 19 for better visualization in the chart while showing the evolution through a seven-week period.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--6-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h3 id="ongoing-strikes-and-internet-disruptions">Ongoing strikes and Internet disruptions</h3><p>Throughout the rest of the year and into 2023, Ukraine has continued to face intermittent Internet disruptions. On <a href="https://twitter.com/CloudflareRadar/status/1595419978282733573">November 23</a>, 2022, the country experienced widespread power outages after Russian strikes, causing a nearly 50% decrease in Internet traffic in Ukraine. This disruption lasted for almost a day and a half, further emphasizing the ongoing impact of the conflict on Ukraine's infrastructure.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--5--1.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Although there was a recovery after that late November outage, only a few days later traffic seemed closer to normal levels. Below is a chart of the week-over-week evolution of Internet traffic in Ukraine at both a national and local level during that time:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--1-.jpg" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In Kyiv Oblast:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--7-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In the Odessa region:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--8-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>And Kharkiv (where a <a href="https://twitter.com/CloudflareRadar/status/1603750187058561024">December 16</a> outage is also clear — in the green line):</p><figure class="kg-card kg-image-card kg-width-wide"><img src="https://lh6.googleusercontent.com/M-2axCRAh672FEYZnaQYK7QR5xcNVGYUKmQBa3jSQaC6p08PlhumoaevZzzrcH3z3hhvirRz5jfPUSSFaqov2FT9eOOK3cEsdyluH_9l9OvfFsCriHKo8p6YfuwfBMAjFKZ_WZcd4EFnXiHKVUQ1KqM" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>On <a href="https://twitter.com/CloudflareRadar/status/1603750187058561024">December 16</a>, there was another country-level Internet disruption caused by air strikes targeting energy infrastructure. Traffic at a national level dropped as much as 13% compared with the previous week, but Ukrainian networks were even more affected. <a href="https://radar.cloudflare.com/as13188">AS13188 (Triolan)</a> had a 70% drop in traffic, and <a href="https://radar.cloudflare.com/as15895">AS15895 (Kyivstar)</a> a 40% drop, both shown in the figures below.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--7--1.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p></p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--8--1.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In January 2023, air strikes caused additional Internet disruptions. One such recent event was in <a href="https://twitter.com/CloudflareRadar/status/1618602213965692930">Odessa</a>, where traffic dropped as low as 54% compared with the previous week during an 18-hour disruption.</p><h2 id="a-cyber-war-with-global-impact">A cyber war with global impact</h2><h3 id="-shields-up-on-cyber-attacks">“Shields Up” on cyber attacks</h3><p>The <a href="https://www.usatoday.com/story/tech/2022/02/28/russia-cyber-attack-ukraine-invasion-protect-yourself/6976490001/">US government</a> and the <a href="https://edition.cnn.com/2022/02/24/tech/russia-ukraine-us-sanctions-cyberattacks/index.html">FBI</a> issued warnings in March to all citizens, businesses, and organizations in the country, as well as allies and partners, to be aware of the need to “enhance cybersecurity.” The US Cybersecurity and Infrastructure Security Agency (CISA) launched the <a href="https://www.cisa.gov/shields-up">Shields Up</a> initiative, noting that “Russia’s invasion of Ukraine could impact organizations both within and beyond the region.” The <a href="http://blog.cloudflare.com/shields-up-free-cloudflare-services-to-improve-your-cyber-readiness/#:~:text=National%20Cyber%20Security%20Center">UK</a> and <a href="https://www.meti.go.jp/press/2021/02/20220221003/20220221003.html">Japan</a>, among others, also issued warnings.</p><p>Below, we discuss Web Application Firewall (WAF) mitigations and DDoS attacks. A <a href="https://www.cloudflare.com/en-gb/learning/ddos/glossary/web-application-firewall-waf/">WAF</a> helps protect web applications by filtering and monitoring <a href="https://www.cloudflare.com/learning/ddos/glossary/hypertext-transfer-protocol-http/">HTTP</a> traffic between a web application and the Internet. A WAF is a protocol <a href="https://www.cloudflare.com/learning/ddos/what-is-layer-7/">layer 7</a> defense (in the <a href="https://www.cloudflare.com/learning/ddos/glossary/open-systems-interconnection-model-osi/">OSI model</a>), and is not designed to defend against all types of attacks. <a href="https://www.cloudflare.com/en-gb/learning/ddos/what-is-a-ddos-attack/">Distributed Denial of Service (DDoS)</a> attacks are cyber attacks that aim to take down Internet properties and make them unavailable for users.</p><h3 id="cyber-attacks-rose-1-300-in-ukraine-by-early-march">Cyber attacks rose 1,300% in Ukraine by early March</h3><p>The charts below are based on normalized data, and show threats mitigated by our <a href="https://www.cloudflare.com/waf/">WAF</a>.</p><p>Mitigated application-layer threats blocked by our WAF skyrocketed after the war started on February 24. Mitigated requests were 105% higher on Monday, February 28 than in the previous (pre-war) Monday, and peaked on March 8, reaching 1,300% higher than pre-war levels.</p><p>Between February 2022 and February 2023, an average of 10% of all traffic to Ukraine was mitigations of potential attacks.</p><p>The graph below shows the daily percentage of application layer traffic to Ukraine that Cloudflare mitigated as potential attacks. In early March, 30% of all traffic was mitigated. This fell in April, and remained low for several months, but it picked up in early September around the time of the Ukrainian counteroffensive in east and south Ukraine. The peak was reached on October 29 when DDoS attack traffic constituted 39% of total traffic to Cloudflare’s Ukrainian customer websites.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--9-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>This trend is more evident when looking at all traffic to sites on the “.ua” top-level domain (from Cloudflare’s perspective). The chart below shows that DDoS attack traffic accounted for over 80% of all traffic by early March 2022. The first clear spikes occurred on February 16 and 19, with around 25% of traffic mitigated. There was no moment of rest after the war started, except towards the end of November and December, but the attacks resumed just before Christmas. An average of 13% of all traffic to “.ua”, between February 2022 and February 2023 was mitigations of potential attacks. The following graph provides a comprehensive view of DDoS application layer attacks on “.ua” sites:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--10-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Moving on to types of mitigations of product groups that were used (related to “.ua” sites), as seen in the next chart, around 57% were done by the ruleset which automatically detects and mitigates HTTP DDoS attacks (DDoS Mitigation), 31% were being mitigated by firewall rules put in place (WAF), and 10% were blocking requests based on our IP threat reputation database (IP Reputation).</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--11-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>It’s important to note that <a href="https://www.cloudflare.com/en-gb/learning/ddos/glossary/web-application-firewall-waf/">WAF</a> rules in the graph above are also associated with custom firewall rules created by customers to provide a more tailored protection. “DDoS Mitigation” (application layer o the first graph shown in this section, which looked at mitigated attack traffic targeting Ukraine, we can also look at mitigated attack traffic originating in Ukraine. The graph below also shows that the share of mitigated traffic from Ukraine also increased considerably after the invasion started.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--12-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h3 id="top-attacked-industries-from-government-to-news-media">Top attacked industries: from government to news media</h3><p>The industries sectors that had a higher share of <a href="https://www.cloudflare.com/learning/ddos/glossary/web-application-firewall-waf/">WAF</a> mitigations were government administration, financial services, and the media, representing almost half of all WAF mitigations targeting Ukraine during 2022.</p><p>Looking at DDoS attacks, there was a surge in attacks on media and publishing companies during 2022 in Ukraine. Entities targeting Ukrainian companies appeared to be focused on information-related websites. The top five most attacked industries in the Ukraine in the first two quarters of 2022 were all in broadcasting, Internet, online media, and publishing, accounting for almost 80% of all DDoS attacks targeting Ukraine.</p><p>In a more focused look at the type of websites Cloudflare has protected throughout the war, the next two graphs provide a view of mitigated application layer attacks by the type of “.ua” sites we helped to protect. In the first days of the war, mitigation spikes were observed at a news service, a TV channel, a government website, and a bank.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--9-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In July, spikes in mitigations we observed across other types of “.ua” websites, including food delivery, e-commerce, auto parts, news, and government.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--10-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>More recently, in February 2023, the spikes in mitigations were somewhat similar to what we saw one year ago, including electronics, e-commerce, IT, and education websites.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--13-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h3 id="12-6-of-network-layer-traffic-was-ddos-activity-in-q1-2022">12.6% of network-layer traffic was DDoS activity in Q1 2022</h3><p>Network-layer (layer 3 and 4) traffic is harder to attribute to a specific domain or target because IP addresses are shared across different customers. Looking at network-level DDoS traffic hitting our Kyiv data center, we saw peaks of DDoS traffic higher than before the war in early March, but they were much higher in June and August.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--11-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In our Q1 2022 <a href="https://radar.cloudflare.com/reports/ddos-2022-q1">DDoS report</a>, we also noted that <a href="https://radar.cloudflare.com/reports/ddos-2022-q1">12.6% of Ukraine’s traffic was DDoS activity</a>, compared with 1% in the previous quarter, a 1,160% quarter-over-quarter increase.</p><p>Several of our quarterly <a href="http://blog.cloudflare.com/tag/ddos/">DDoS reports</a> from 2022 include attack trends related to the war in Ukraine, with quarter over quarter <a href="https://radar.cloudflare.com/reports?q=DDoS">interactive</a> comparisons.</p><h2 id="network-re-routing-in-kherson">Network re-routing in Kherson</h2><p>On February 24, 2022, Russian forces <a href="https://en.wikipedia.org/wiki/Southern_Ukraine_campaign">invaded</a> Ukraine's Kherson Oblast region. The city of Kherson was captured on March 2, as the first major city and only regional capital to be captured by Russian forces during the initial invasion. The <a href="https://en.wikipedia.org/wiki/Russian_occupation_of_Kherson_Oblast">Russian occupation of Kherson Oblast</a> continued until Ukrainian forces <a href="https://en.wikipedia.org/wiki/Liberation_of_Kherson">resumed control</a> on November 11, after launching a counteroffensive at the end of August.</p><p>On May 4, 2022, we published <a href="http://blog.cloudflare.com/tracking-shifts-in-internet-connectivity-in-kherson-ukraine/"><em>Tracking shifts in Internet connectivity in Kherson, Ukraine</em></a>, a blog post that explored a re-routing event that impacted <a href="https://radar.cloudflare.com/as47598">AS47598 (Khersontelecom)</a>, a telecommunications provider in Kherson Oblast. Below, we summarize this event, and explore similar activity across other providers in Kherson that has taken place since then.</p><p>On May 1, 2022, we observed a shift in routing for the <a href="https://bgpview.io/prefix/91.206.110.0/23">IPv4 prefix</a> announced by Ukrainian network <a href="https://radar.cloudflare.com/as47598">AS47598 (Khersontelecom)</a>. During April, it reached the Internet through several other Ukrainian network providers, including <a href="https://radar.cloudflare.com/as12883">AS12883 (Vega Telecom)</a> and <a href="https://radar.cloudflare.com/as3326">AS3326 (Datagroup)</a>. However, after the shift, its routing path now showed a Russian network, <a href="https://radar.cloudflare.com/as201776">AS201776 (Miranda-Media)</a>, as the sole upstream provider. With traffic from KhersonTelecom passing through a Russian network, it was subject to the restrictions and limitations imposed on any traffic transiting Russian networks, including content filtering.</p><p>The flow of traffic from Khersontelecom before and after May 1, with rerouting through Russian network provider Miranda-Media, is illustrated in the chart below. This particular re-routing event was short-lived, as a routing update for AS47598 on May 4 saw it return to reaching the Internet through other Ukrainian providers.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--14-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>As a basis for our analysis, we started with a list of 15 Autonomous System Numbers (ASNs) belonging to networks in Kherson Oblast. Using that list, we analyzed routing information collected by route-views2 over the past year, from February 1, 2022, to February 15, 2023. route-views2 is a BGP route collector run by the <a href="https://www.routeviews.org/routeviews/">University of Oregon Route Views Project</a>. Note that with respect to the discussions of ASNs in this and the following section, we are treating them equally, and have not specifically factored estimated user population into these analyses.</p><p>The figure below illustrates the result of this analysis, showing that re-routing of Kherson network providers (listed along the y-axis) through Russian upstream networks was fairly widespread, and for some networks, has continued into 2023. During the analysis time frame, there were three primary Russian networks that appeared as upstream providers: <a href="https://radar.cloudflare.com/as201776">AS201776 (Miranda-Media)</a>, <a href="https://radar.cloudflare.com/as52091">AS52091 (Level-MSK Ltd.)</a>, and <a href="https://radar.cloudflare.com/as8492">AS8492 (OBIT Ltd.)</a>.</p><p>Within the graph, black bars indicate periods when the ASN effectively disappeared from the Internet; white segments indicate the ASN was dependent on other Ukraine networks as immediate upstreams; and red indicates the presence of Russian networks in the set of upstream providers. The intensity of the red shading corresponds to the percentage of announced prefixes for which a Russian network provider is present in the routing path as observed from networks outside Ukraine. Bright red shading, equivalent to “1” in the legend, indicates the presence of a Russian provider in all routing paths for announced prefixes.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--12-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In the blog post linked above, we referenced an outage that began on April 30. This is clearly visible in the figure as a black bar that runs for several days across all the listed ASNs. In this instance, AS47598 (KhersonTelecom) recovered a day later, but was sending traffic through AS201776 (Miranda-Media), a Russian provider, as discussed above.</p><p>Another Ukrainian network, <a href="https://radar.cloudflare.com/as49168">AS49168 (Brok-X)</a>, recovered from the outage on May 2, and was also sending traffic through Miranda-Media. By May 4, most of the other Kherson networks recovered from the outage, and both AS47598 and AS49168 returned to using Ukrainian networks as immediate upstream providers. Routing remained “normal” until May 30. Then, a more widespread shift to routing traffic through Russian providers began, although it appears that this shift was preceded by a brief outage for a few networks. For the most part, this re-routing lasted through the summer and into October. Some networks saw a brief outage on October 17, but most stopped routing directly through Russia by October 22.</p><p>However, this shift away from Russia was followed by periods of extended outages. KhersonTelecom suffered such an outage, and has remained offline since October, except for the first week of November when all of its traffic routed through Russia. Many other networks rejoined the Internet in early December, relying mostly on other Ukrainian providers for Internet connectivity. However, since early December, <a href="https://radar.cloudflare.com/as204485">AS204485 (PE Berislav Cable Television)</a>, <a href="https://radar.cloudflare.com/as56359">AS56359 (CHP Melnikov Roman Sergeevich)</a>, and <a href="https://radar.cloudflare.com/as49465">AS49465 (Teleradiocompany RubinTelecom Ltd.)</a> have continued to use Miranda-Media as an upstream provider, in addition to experiencing several brief outages. In addition, over the last several months, <a href="https://radar.cloudflare.com/as25082">AS25082 (Viner Telecom)</a> has used both a Ukrainian network and Miranda-Media as upstream providers.</p><h2 id="internet-resilience-in-ukraine">Internet resilience in Ukraine</h2><p>In the context of the Internet, “<a href="https://csrc.nist.gov/glossary/term/network_resilience">resilience</a>” refers to the ability of a network to operate continuously in a manner that is highly resistant to disruption. This includes the ability of a network to: (1) operate in a degraded mode if damaged, (2) rapidly recover if failure does occur, and (3) scale to meet rapid or unpredictable demands. Throughout the Russia-Ukraine conflict, media coverage (<a href="https://www.vice.com/en/article/qjbapv/diy-volunteers-are-repairing-ukraines-destroyed-internet-infrastructure">VICE</a>, <a href="https://www.bloomberg.com/news/features/2022-11-17/ukraine-stays-online-during-war-thanks-to-repair-crews#xj4y7vzkg">Bloomberg</a>, <a href="https://www.washingtonpost.com/technology/2022/03/29/ukraine-internet-faq/">Washington Post</a>) has highlighted the work done in Ukraine to repair damaged fiber-optic cables and mobile network infrastructure to keep the country online. This work has been critically important to maintaining the resilience of Ukrainian Internet infrastructure.</p><p>According to <a href="https://www.peeringdb.com/advanced_search?country__in=UA&amp;reftag=ix">PeeringDB</a>, as of February 2023, there are 25 Internet Exchange Points (IXPs) in Ukraine and 50 interconnection facilities. (An IXP may span multiple physical facilities.) Within this set of IXPs, Autonomous Systems (ASes) belonging to international providers are currently present in over half of them. The number of facilities, IXPs, and international ASes present in Ukraine points to a resilient interconnection fabric, with multiple locations for both domestic and international providers to exchange traffic.</p><p>To better understand these international interconnections, we first analyze the connectivity of ASes in Ukraine, and we classify the links to domestic networks (links where both ASes are registered in Ukraine) and international networks (links between ASes in Ukraine and ASes outside Ukraine). To determine which ASes are domestic in Ukraine, we can use information from the extended delegation reports from the <a href="https://ftp.ripe.net/pub/stats/ripencc/2023/">Réseaux IP Européens Network Coordination Centre (RIPE NCC)</a>, the <a href="hDDoS protection) and “Access Rules” (rate limiting) are specifically used for DDoS protection.</p><p>In contrast tttps://www.nro.net/about/rirs/">Regional Internet Registry</a> that covers Ukraine. We also parsed collected BGP data to extract the AS-level links between Ukrainian ASes and ASes registered in a different country, and we consider these the international connectivity of the domestic ASes.</p><p>A <a href="https://www.economist.com/science-and-technology/2022/03/26/the-degrading-treatment-of-ukraines-internet">March 2022 article in The Economist</a> noted that <em>“For one thing, Ukraine boasts an unusually large number of internet-service providers—by one reckoning the country has the world’s fourth-least-concentrated Internet market. This means the network has few choke points, so is hard to disable.”</em> As of the writing of this blog post, there are 2,190 ASes registered in Ukraine (UA ASes), and 1,574 of those ASes appear in the BGP routing table as active. These counts support the article’s characterization, and below we discuss several additional observations that reinforce Ukraine’s Internet resilience.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Untitled--13-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>The figure above is a cumulative distribution function showing the fraction of domestic Ukrainian ASes that have direct connections to international networks. In February 2023, approximately 50% had more than one (100) international link, while approximately 10% had more than 10, and approximately 2% had 100 or more. Although these numbers have dropped slightly over the last year, they underscore the lack of centralized choke points in the Ukrainian Internet.</p><p>For the networks with international connectivity, we can also look at the distribution of “next-hop” countries – countries with which those international networks are associated. (Note that some networks may have a global footprint, and for these, the associated country is the one recorded in their autonomous system registration.) Comparing the choropleth maps below illustrates how this set of countries, and their fraction of international paths, have changed between February 2022 and February 2023. The data underlying these maps shows that international connectivity from Ukraine is distributed across 18 countries — unsurprisingly, mostly in Europe.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/UA-2022-fraction-of-next-hop-ases-by-country.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>In February 2022, these countries/locations accounted for 77% of Ukraine’s next-hop international paths. The top four all had 7.8% each. However, in February 2023, the top 10 next-hop countries/locations dropped slightly to 76% of international paths. While just a slight change from the previous year, the set of countries/locations and many of their respective fractions saw considerable change.</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-color:#ccc;border-spacing:0;} .tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333; font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333; font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-baqh{text-align:center;vertical-align:top} .tg .tg-xt05{background-color:#D9D9D9;text-align:left;vertical-align:top} .tg .tg-xqm4{background-color:#D9D9D9;font-weight:bold;text-align:left;vertical-align:top} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg" width="100%"> <thead> <tr> <th class="tg-xt05"></th> <th class="tg-xqm4" colspan="2"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">February 2022</span></th> <th class="tg-xqm4" colspan="2"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">February 2023</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">1</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Germany </span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.85%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Russia</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">11.62%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">2</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Netherlands</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.85%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Germany</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">11.43%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">3</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">United Kingdom</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.83%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Hong Kong</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">8.38%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">4</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Hong Kong</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.81%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Poland</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.93%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">5</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Sweden</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.77%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Italy</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.75%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">6</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Romania</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.72%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Turkey</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">6.86%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Russia</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.67%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Bulgaria</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">6.20%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">8</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Italy</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.64%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Netherlands</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">5.31%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">9</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Poland</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.60%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">United Kingdom</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">5.30%</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">10</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Hungary</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">7.54%</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Sweden</span></td> <td class="tg-baqh"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">5.26%</span></td> </tr> </tbody> </table><!--kg-card-end: html--><p>Russia’s share grew by 50% year to 11.6%, giving it the biggest share of next-hop ASes. Germany also grew to account for more than 11% of paths.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/UA-2023-fraction-of-next-hop-ases-by-country.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h2 id="satellite-internet-connectivity">Satellite Internet connectivity</h2><p>Cloudflare observed a rapid growth in Starlink’s ASN (<a href="https://radar.cloudflare.com/traffic/as14593?range=28d">AS14593</a>) traffic to Ukraine during 2022 and into 2023. Between mid-March and mid-May, Starlink’s traffic in the country grew over 530%, and continued to grow from mid-May up until mid-November, increasing nearly 300% over that six-month period — from mid-March to mid-December the growth percentage was over 1600%. After that, traffic stabilized and even dropped a bit during January 2023.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--15-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><p>Our data shows that between November and December 2022, Starlink represented between 0.22% and 0.3% of traffic from Ukraine, but that number is now lower than 0.2%.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/pasted-image-0--16-.png" class="kg-image" alt="One year of war in Ukraine: Internet trends, attacks, and resilience"></figure><h2 id="conclusion">Conclusion</h2><p>One year in, the war in Ukraine has taken an unimaginable humanitarian toll. The Internet in Ukraine has also become a battleground, suffering attacks, re-routing, and disruptions. But it has proven to be exceptionally resilient, recovering time and time again from each setback.</p><p>We know that the need for a secure and reliable Internet there is more critical than ever. At Cloudflare, we’re committed to continue providing tools that protect Internet services from cyber attack, improve security for those operating in the region, and share information about Internet connectivity and routing inside Ukraine.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ The Chief Zero Trust Officer: a new role for a new era of cybersecurity ]]>
</title>
<description>
<![CDATA[ Implementing Zero Trust can be challenging, and efforts may stall. The need for a Chief Zero Trust Officer (CZTO) is driven by the increasing importance of Zero Trust security in the face of escalating cyber attacks. ]]>
</description>
<link>https://blog.cloudflare.com/chief-zero-trust-officer/</link>
<guid isPermaLink="false">63e5631eea5b01000ae292fd</guid>
<category>
<![CDATA[ Cloudflare Zero Trust ]]>
</category>
<category>
<![CDATA[ API Security ]]>
</category>
<category>
<![CDATA[ SASE ]]>
</category>
<dc:creator>
<![CDATA[ John Engates ]]>
</dc:creator>
<pubDate>Tue, 21 Feb 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/Zero-Trust-Access-to-Kubernetes.png" medium="image"/>
<content:encoded>
<![CDATA[ <!--kg-card-begin: markdown--><img src="http://blog.cloudflare.com/content/images/2023/02/Zero-Trust-Access-to-Kubernetes.png" alt="The Chief Zero Trust Officer: a new role for a new era of cybersecurity"><p><small>This post is also available in <a href="http://blog.cloudflare.com/zh-cn/chief-zero-trust-officer-zh-cn/">简体中文</a>, <a href="http://blog.cloudflare.com/zh-tw/chief-zero-trust-officer-zh-tw/">繁體中文</a>, <a href="http://blog.cloudflare.com/ja-jp/chief-zero-trust-officer-ja-jp/">日本語</a>, <a href="http://blog.cloudflare.com/ko-kr/chief-zero-trust-officer-ko-kr/">한국어</a>, <a href="http://blog.cloudflare.com/fr-fr/chief-zero-trust-officer-fr-fr/">Français</a>, <a href="http://blog.cloudflare.com/de-de/chief-zero-trust-officer-de-de/">Deutsch</a> and <a href="http://blog.cloudflare.com/es-es/chief-zero-trust-officer-es-es/">Español</a>.</small></p> <!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/Zero-Trust-Access-to-Kubernetes-1.png" class="kg-image" alt="The Chief Zero Trust Officer: a new role for a new era of cybersecurity"></figure><h3 id="setting-the-stage-for-zero-trust"><strong>Setting the stage for Zero Trust</strong></h3><p>Over the last few years the topic of cyber security has moved from the IT department to the board room. The current climate of geopolitical and economic uncertainty has made the threat of cyber attacks all the more pressing, with businesses of all sizes and across all industries feeling the impact. From the potential for a crippling ransomware attack to a data breach that could compromise sensitive consumer information, the risks are real and potentially catastrophic. Organizations are recognizing the need for better resilience and preparation regarding cybersecurity. It is not enough to simply react to attacks as they happen; companies must proactively prepare for the inevitable in their approach to cybersecurity.<br><br>The security approach that has gained the most traction in recent years is the concept of Zero Trust. The basic principle behind Zero Trust is simple: don't trust anything; verify everything. The impetus for a modern Zero Trust architecture is that traditional perimeter-based (castle-and-moat) security models are no longer sufficient in today's digitally distributed landscape. Organizations must adopt a holistic approach to security based on verifying the identity and trustworthiness of all users, devices, and systems that access their networks and data. </p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image2-64.png" class="kg-image" alt="The Chief Zero Trust Officer: a new role for a new era of cybersecurity"></figure><p>Zero Trust has been on the radar of business leaders and board members for some time now. However, Zero Trust is no longer just a concept being discussed; it's now a mandate. With remote or hybrid work now the norm and cyber-attacks continuing to escalate, businesses realize they must take a fundamentally different approach to security. But as with any significant shift in strategy, implementation can be challenging, and efforts can sometimes stall. Although many firms have begun implementing Zero Trust methods and technologies, only some have fully implemented them throughout the organization. For many large companies, this is the current status of their Zero Trust initiatives - stuck in the implementation phase.</p><h3 id="a-new-leadership-role-emerges">A new leadership role emerges</h3><p>But what if there was a missing piece in the cybersecurity puzzle that could change everything? Enter the role of "Chief Zero Trust Officer" (CZTO) – a new position that we believe will become increasingly common in large organizations over the next year.</p><p>The idea of companies potentially creating the role of Chief Zero Trust Officer evolved from conversations last year between Cloudflare's Field CTO team members and US federal government agencies. A similar job function was first noted in the <a href="https://www.whitehouse.gov/wp-content/uploads/2022/01/M-22-09.pdf">White House memorandum</a> directing federal agencies to “move toward Zero Trust cybersecurity principles” and requiring agencies “designate and identify a Zero Trust strategy implementation lead for their organization” within 30 days. In government, a role like this is often called a "czar," but the title "chief" is more appropriate within a business.</p><p>Large organizations need strong leaders to efficiently get things done. Businesses assign the ultimate leadership responsibility to people with titles that begin with the word chief, such as Chief Executive Officer (CEO) or Chief Financial Officer (CFO). These positions exist to provide direction, set strategy, make critical decisions, and manage day-to-day operations and they are often accountable to the board for overall performance and success.</p><h3 id="why-a-c-level-for-zero-trust-and-why-now">Why a C-level for Zero Trust, and why now?</h3><p>An old saying goes, “when everyone is responsible, no one is responsible.” As we consider the challenges in implementing Zero Trust within an enterprise, it appears that a lack of clear leadership and accountability is a significant issue. The question remains, who *exactly* is responsible for driving the adoption and execution of Zero Trust within the organization?</p><p>Large enterprises need a single person responsible for driving the Zero Trust journey. This leader should be empowered with a clear mandate and have a singular focus: getting the enterprise to Zero Trust. This is where the idea of the Chief Zero Trust Officer was born. "Chief Zero Trust Officer" may seem like just a title, but it holds a lot of weight. It commands attention and can overcome many obstacles to Zero Trust.</p><h3 id="barriers-to-adoption"><strong>Barriers to adoption</strong></h3><p>Implementing Zero Trust can be hindered by various technological challenges. Understanding and implementing the complex architecture of some vendors can take time, demand extensive training, or require a professional services engagement to acquire the necessary expertise. Identifying and verifying users and devices in a Zero Trust environment can also be a challenge. It requires an accurate inventory of the organization's user base, groups they’re a part of, and their applications and devices.</p><p>On the organizational side, coordination between different teams is crucial for effectively implementing Zero Trust. Breaking down the silos between IT, cybersecurity, and networking groups, establishing clear communication channels, and regular meetings between team members can help achieve a cohesive security strategy. General resistance to change can also be a significant obstacle. Leaders should use techniques such as leading by example, transparent communication, and involving employees in the change process to mitigate it. Proactively addressing concerns, providing support, and creating employee training opportunities can also help ease the transition.</p><h3 id="responsibility-and-accountability-no-matter-what-you-call-it">Responsibility and accountability - no matter what you call it</h3><p>But why does an organization need a CZTO? Is another C-level role essential? Why not assign someone already managing security within the CISO organization? Of course, these are all valid questions. Think about it this way - companies should assign the title based on the level of strategic importance to the company. So, whether it's Chief Zero Trust Officer, Head of Zero Trust, VP of Zero Trust, or something else, the title must command attention and come with the power to break down silos and cut through bureaucracy. </p><p>New C-level titles aren’t without precedent. In recent years, we've seen the emergence of titles such as Chief Digital Transformation Officer, Chief eXperience Officer, Chief Customer Officer, and Chief Data Scientist. The Chief Zero Trust Officer title is likely not even a permanent role. What's crucial is that the person holding the role has the authority and vision to drive the Zero Trust initiative forward, with the support of company leadership and the board of directors.</p><h3 id="getting-to-zero-trust-in-2023">Getting to Zero Trust in 2023</h3><p>Getting to Zero Trust security is now a mandate for many companies, as the traditional perimeter-based security model is no longer enough to protect against today's sophisticated threats. To navigate the technical and organizational challenges that come with Zero Trust implementation, the leadership of a CZTO is crucial. The CZTO will lead the Zero Trust initiative, align teams and break down barriers to achieve a smooth rollout. The role of CZTO in the C-suite emphasizes the importance of Zero Trust in the company. It ensures that the Zero Trust initiative is given the necessary attention and resources to succeed. Organizations that appoint a CZTO now will be the ones that come out on top in the future.</p><h3 id="cloudflare-one-for-zero-trust">Cloudflare One for Zero Trust</h3><p>Cloudflare One is Cloudflare's Zero Trust platform that is easy to deploy and integrates seamlessly with existing tools and vendors. It is built on the principle of Zero Trust and provides organizations with a comprehensive security solution that works globally. Cloudflare One is delivered on Cloudflare's global network, which means that it works seamlessly across multiple geographies, countries, network providers, and devices. With Cloudflare's massive global presence, traffic is secured, routed, and filtered over an optimized backbone that uses real-time Internet intelligence to protect against the latest threats and route traffic around bad Internet weather and outages. Additionally, Cloudflare One integrates with best-of-breed identity management and endpoint device security solutions, creating a complete solution that encompasses the entire corporate network of today and tomorrow. If you’d like to know more, <a href="https://www.cloudflare.com/lp/cio-week-2023-cloudflare-one-contact-us/">let us know here, and we’ll reach out</a>.</p><p>Do you prefer to avoid talking to someone just yet? Nearly every feature in Cloudflare One is available at no cost for up to 50 users. Many of our largest enterprise customers start by exploring our Zero Trust products themselves on our free plan, and we invite you to do so by following <a href="https://dash.cloudflare.com/sign-up/teams">the link here</a>.</p><h3 id="working-with-another-zero-trust-vendor">Working with another Zero Trust vendor?</h3><p>Cloudflare’s security experts have built a vendor-neutral roadmap to provide a Zero Trust architecture and an example implementation timeline. The Zero Trust Roadmap<a href="https://zerotrustroadmap.org/"> https://zerotrustroadmap.org/</a> is an excellent resource for organizations that want to learn more about the benefits and best practices of implementing Zero Trust. And if you feel stuck on your current Zero Trust journey, have your chief Zero Trust officer give us a <a href="https://www.cloudflare.com/lp/cio-week-2023-cloudflare-one-contact-us/">call</a> at Cloudflare!</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ So long, and thanks for all the deployments: deprecating Wrangler v1 ]]>
</title>
<description>
<![CDATA[ Version 1 of Wrangler has served us well for years. But with a new major version to focus on, it’s time to say goodbye ]]>
</description>
<link>https://blog.cloudflare.com/deprecating-wrangler-v1/</link>
<guid isPermaLink="false">63e6a138ea5b01000ae293fb</guid>
<category>
<![CDATA[ Wrangler ]]>
</category>
<category>
<![CDATA[ Developers ]]>
</category>
<category>
<![CDATA[ Cloudflare Workers ]]>
</category>
<dc:creator>
<![CDATA[ Cass Fridkin ]]>
</dc:creator>
<pubDate>Thu, 16 Feb 2023 19:46:33 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/Developer-Challenges-1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/Developer-Challenges.png" class="kg-image" alt="So long, and thanks for all the deployments: deprecating Wrangler v1"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/Developer-Challenges-1.png" alt="So long, and thanks for all the deployments: deprecating Wrangler v1"><p><a href="https://workers.cloudflare.com/">Cloudflare Workers</a> allow developers to deploy code instantly across the globe. <a href="https://github.com/cloudflare/workers-sdk">Wrangler</a> is the CLI tool we build (and use!) to create, modify, and upload Workers. We recently <a href="http://blog.cloudflare.com/wrangler-v2-beta/">announced a new version of Wrangler</a> with <a href="http://blog.cloudflare.com/10-things-i-love-about-wrangler/">a bunch of new features</a> – including <a href="http://blog.cloudflare.com/10-things-i-love-about-wrangler/#4-local-mode">offline development</a>, <a href="http://blog.cloudflare.com/10-things-i-love-about-wrangler/#2-zero-config-startup">zero-config startup</a>, and <a href="http://blog.cloudflare.com/10-things-i-love-about-wrangler/#7-on-demand-developer-tools-for-debugging-">developer tools support</a>. Since then, we’ve been working hard to make the developer experience with version 2 as smooth and enjoyable as possible. We’re confident in what we’ve built and are now planning to officially deprecate version 1.</p><h3 id="what-s-happening">What’s happening?</h3><p>Version 1 of Wrangler (<a href="https://www.npmjs.com/package/@cloudflare/wrangler">@cloudflare/wrangler</a> on npm) is now deprecated, which means no new features or bug fixes will be published unless they’re critical. Beginning August 2023, no further updates will be provided and the <a href="https://github.com/cloudflare/wrangler-legacy">Wrangler v1 GitHub repo</a> will be archived. We strongly recommend you upgrade to version 2 (<a href="https://www.npmjs.com/package/wrangler">wrangler</a> on npm) to receive continued support. We have a <a href="https://developers.cloudflare.com/workers/wrangler-legacy/migration/">migration guide</a> to make this process easy!</p><h3 id="why">Why?</h3><p>Our goal is to make development on the Cloudflare platform as smooth and enjoyable as possible. Whether that means<a href="https://github.com/cloudflare/workers-sdk/pull/1735"> simplifying common workflows</a>, <a href="https://github.com/cloudflare/workers-sdk/pull/82">incorporating powerful tools into the Wrangler codebase</a>, or <a href="https://github.com/cloudflare/workers-sdk/pull/1350">opening up Wrangler for use as a library</a>, we want Wrangler to be a one-stop shop for developing on Cloudflare.</p><p>With that in mind, last year we set out to align our product with our goals. Wrangler was the primary way developers interacted with our platform, but the codebase was difficult to maintain and had spiraled in complexity. Weighing our options, we found that the best way forward was a total rewrite of Wrangler, culminating in the 2.0 release.</p><p>Typically, <a href="https://semver.org/#:~:text=Given%20a%20version,incompatible%20API%20changes">semver-major releases</a> (such as 1.x to 2.0) introduce breaking changes into a codebase – making it non-trivial to update to the latest version of software. While some breakage was inevitable with the release of a new major version of Wrangler, we aimed to ensure smooth upgrades. We <a href="https://github.com/cloudflare/workers-sdk/pull/733">provided detailed deprecation messages</a> and <a href="https://developers.cloudflare.com/workers/wrangler-legacy/migration/deprecations/">documented breaking changes</a> wherever they occurred. We carefully <a href="https://github.com/cloudflare/workers-sdk/issues/1519">monitored issue reports</a>, and responded with <a href="https://github.com/cloudflare/workers-sdk/pull/1595">updates to fix problems</a>. We monitored download statistics of both versions of wrangler, and celebrated internally when <a href="https://npmtrends.com/@cloudflare/wrangler-vs-wrangler">downloads for version 2 of Wrangler surpassed downloads for version 1 on npm</a>.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="https://lh6.googleusercontent.com/HMs_w-V8fT6F7MaZcOWZ0QxZcg1EBnM14PPt_svfEF-5ZKRwUxa5NBjYYNMdeZKht-vIMNzlUOi8ngNcKbLXc5oa8t2GiL8F3vASyuBJpzd0JvwLaqRXgyLwPClk34VN6mJIFxZOBfzjohufwN6FVbY" class="kg-image" alt="So long, and thanks for all the deployments: deprecating Wrangler v1"><figcaption>Download statistics for @cloudflare/wrangler (version 1, in blue) and wrangler (version 2, in orange). Source: <a href="https://npmtrends.com/@cloudflare/wrangler-vs-wrangler">https://npmtrends.com/@cloudflare/wrangler-vs-wrangler</a></figcaption></figure><h3 id="what-do-i-need-to-do">What do I need to do?</h3><p>For most of our users, deprecation of version 1 will be invisible – they’re already on version 2! If you’re still on version 1, please upgrade – we have a <a href="https://developers.cloudflare.com/workers/wrangler/migration/migrating-from-wrangler-1/">migration guide</a> that details everything you need to do to update to the latest and greatest version. If you encounter any bugs, unexpected behavior, or anything blocking you from upgrading, <a href="https://github.com/cloudflare/workers-sdk/issues/new/choose">file an issue</a>! If you’re not using Wrangler, <a href="https://developers.cloudflare.com/workers/get-started/guide/">give it a shot</a>! We’re really proud of what we’ve built, and we want your feedback on how we can continue to make it even better.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ A look at Internet traffic trends during Super Bowl LVII ]]>
</title>
<description>
<![CDATA[ We look at who the biggest winners were among Super Bowl advertisers, and examine traffic trends for food delivery services, social media, and sports and betting sites. We also review city and state-level traffic trends, as well as related email threat volume in the weeks ahead of the game ]]>
</description>
<link>https://blog.cloudflare.com/super-bowl-lvii/</link>
<guid isPermaLink="false">63ea93c9ea5b01000ae29461</guid>
<category>
<![CDATA[ Cloudflare Radar ]]>
</category>
<category>
<![CDATA[ Trends ]]>
</category>
<category>
<![CDATA[ Super Bowl ]]>
</category>
<category>
<![CDATA[ Advertising ]]>
</category>
<category>
<![CDATA[ Internet Traffic ]]>
</category>
<dc:creator>
<![CDATA[ David Belson ]]>
</dc:creator>
<pubDate>Mon, 13 Feb 2023 22:23:55 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/image20-1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image20.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/image20-1.png" alt="A look at Internet traffic trends during Super Bowl LVII"><p>The Super Bowl has been happening since the end of the 1966 season, the same year that the <a href="https://en.wikipedia.org/wiki/ARPANET">ARPANET</a> project, which gave birth to the Internet, was initiated. Around <a href="https://www.pewresearch.org/internet/2015/06/26/americans-internet-access-2000-2015/">20 years</a> ago, 50% of the US population were Internet users, and that number is now around<a href="https://wearesocial.com/us/blog/2022/02/digital-2022-in-the-us/"> 92%</a>. So, it's no surprise that interest in an event like Super Bowl LVII resulted in a noticeable dip in Internet traffic in the United States at the time of the game's kickoff, dropping to around <a href="https://radar.cloudflare.com/traffic/us">5% lower</a> than the previous Sunday. During the game, Rihanna's halftime show also caused a significant drop in Internet traffic across most states, with Pennsylvania and New York feeling the biggest impact, but messaging and video platforms saw a surge of traffic right after her show ended.</p><p>In this blog post, we will dive into who the biggest winners were among Super Bowl advertisers, as well as examine how traffic to food delivery services, social media and sports and betting websites changed during the game. In addition, we look at traffic trends seen at city and state levels during the game, as well as email threat volume across related categories in the weeks ahead of the game.</p><p><a href="https://radar.cloudflare.com/">Cloudflare Radar</a> uses a variety of sources to provide aggregate information about Internet traffic and attack trends. In this blog post, as we did <a href="http://blog.cloudflare.com/who-won-super-bowl-lvi-a-look-at-internet-traffic-during-the-big-game/">last year</a> and the <a href="http://blog.cloudflare.com/who-won-super-bowl-lv/">year before</a>, we use DNS name resolution data from our <a href="https://one.one.one.one">1.1.1.1 resolver</a> to estimate traffic to websites. We can’t see who visited the websites mentioned, or what anyone did on the websites, but DNS can give us an estimate of the interest generated by the ads or across a set of sites in the categories listed above.</p><h2 id="ads-are-urls-no-longer-cool">Ads: are URLs no longer cool?</h2><p>In contrast to Super Bowl commercials of the past 25 years, many of this year’s advertisements didn’t include a URL, possibly suggesting strong confidence by brands in their search engine results placement, or an assumption that the viewer would engage with the brand through an app on their phone, rather than a website. To that end, several ads did include an app store-related call to action, encouraging the viewer to download the associated mobile app. And possibly in an effort to capitalize on the success of Coinbase’s QR code commercial during Super Bowl LVI, a number of brands, including Toyota, Michelob Ultra, and Mr. Peanut included QR codes as a way for viewers to get additional information or see more.</p><p>As we did last year, we again tracked DNS request traffic to our <a href="https://one.one.one.one/">1.1.1.1</a> resolver in United States data centers for domains associated with the advertised products or brands. Traffic growth is plotted against a baseline calculated as the mean request volume for the associated domains between 1200-1500 EST on Sunday, February 12 (Super Bowl Sunday.) Although over 50 brands advertised during the game, the brands highlighted below were chosen because their advertisements drove some of the largest percentage traffic spikes, as well as one interesting tale.</p><h3 id="bluemoon">BlueMoon</h3><p>Although the commercial initially seemed to be for sibling beer brands Coors Light and Miller Lite, there was a twist at the end, This twist was only fitting, as the ad was actually for Blue Moon, which is often served with a twist of orange on the rim of the glass. Although beer ads don’t usually drive significant traffic spikes, this one did, reaching 76,400% above baseline for Blue Moon’s site. Coors Light saw a 275% bump in DNS traffic coincident with the ad, while Miller Lite grew 120%. However, traffic for Coors and Miller was fairly volatile at other times during the game.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image10.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h3 id="limitbreak">LimitBreak</h3><p>Although last year’s advertisements included a number of cryptocurrency-related brands, they were all but absent from this year’s slate of ads. The closest we got during this year’s game was a commercial from LimitBreak, which describes itself as “bringing the free-to-play gaming experience to Web3 and beyond”, in which it promoted a giveaway of thousands of its Dragon series NFTs. This ad featured a QR code and a URL, and given the nearly 54,000% increase in DNS traffic observed, both were effective means of driving traffic to the LimitBreak website.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image2-2.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h3 id="temu">Temu</h3><p>Upstart mobile shopping app Temu purchased multiple Super Bowl ad slots to promote its “shop like a billionaire” campaign, urging viewers to download its mobile app. As seen in the graph below, these advertisements drove spikes in traffic, and continued engagement, each time they ran. The first airing at 19:16 EST drove a 222% spike over baseline in DNS traffic. However, the second airing at 21:12 EST apparently resulted in significantly more interest, driving a 475% traffic increase. A third airing at 22:20 EST reached 169% over baseline, with another one just after that reaching over 200%.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image3-2.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h3 id="dunkin-">Dunkin’</h3><p>In early January, Boston-area media blew up with the news that local celebrity Ben Affleck was <a href="https://www.boston.com/culture/celebs/2023/01/10/ben-affleck-dunkin-donuts-commercial-medford/">spotted working the drive-through window</a> at one of the coffee chain’s Medford locations, raising some speculation that he was filming a Super Bowl commercial. That speculation turned out to be true, as the commercial aired at 18:53 EST. But the commercial had a side effect: DNS traffic for dunkin.com, associated with DunkinWorks (a small personal coaching and training business), spiked 8,000% when the commercial aired, as shown in the graph below. (It isn’t clear what drove the later three spikes for dunkin.com, as the advertisement didn’t air again nationally during the remainder of the game.) We can only hope that the dunkin.com system administrators were fueled with plenty of coffee and donuts as they dealt with the rapid growth in traffic.<br></p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image6.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h2 id="site-categories-touchdowns-bring-attention">Site categories: touchdowns bring attention</h2><p>As we saw <a href="http://blog.cloudflare.com/who-won-super-bowl-lvi-a-look-at-internet-traffic-during-the-big-game/">last year</a>, there are two factors that bring a surge of traffic to the websites of Super Bowl participants: touchdowns and winning. However, nothing is more impactful than the sweet taste of victory. Both the Kansas City Chiefs' and Philadelphia Eagles' websites experienced a surge in DNS traffic just before the game started, as compared to a baseline calculated as the mean request volume for the associated domains between 12:00-15:00 EST on Sunday, February 12 (Super Bowl Sunday.). The Eagles website had its peak just around the time of the kickoff, with 828% growth over baseline, and continued to grow more rapidly than traffic to the Chiefs' website until 20:55 EST, when traffic to chiefs.com began to pull ahead.</p><p>What happened at that time? That was the moment of the Chiefs' third touchdown of the game, when DNS traffic to the team’s website had its first peak of the evening, at 514% above baseline. There was a clear spike during another Chiefs touchdown at 21:42 EST, at 454% above baseline, but that was nothing compared to the end of the game, when the Kansas City Chiefs were once again, after their 2019 victory, the winners. At 22:15 EST, when the game ended, DNS traffic to the Chiefs' website was 871% higher, and peaked 10 minutes later at 890%, as compared to the baseline. At this same time, DNS traffic for the Eagles' website dropped significantly. <a href="http://blog.cloudflare.com/who-won-super-bowl-lvi-a-look-at-internet-traffic-during-the-big-game/">As we saw last year as well</a>, winning the Super Bowl clearly drives increased traffic to the victor’s website.<br></p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image16.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Sports websites trends also followed the in-game events. There was a clear spike to approximately 90% above baseline when the game started at 18:30 EST, with further growth to 120% over baseline at 19:00 EST during the Kansas City Chiefs' first touchdown. There were also clear spikes at 21:30 and 21:40 EST coinciding with the two more Chiefs touchdowns. The Super Bowl peak for these websites was reached during the final break at 22:00 EST, reaching 145% above baseline, just before the Chiefs' game-winning field goal. After a brief drop as the game ended, there was an additional spike to 134%.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image4-1.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h2 id="rihanna-s-impact-on-messaging-and-social-media-sites">Rihanna’s impact on messaging and social media sites</h2><p>What happened following Rihanna's performance during the Super Bowl halftime show? As the game resumed, we saw a clear increase in traffic for messaging websites, with a first peak right after the end of the show at around 20:45 EST, 22% over baseline. The biggest peak, however, was when the game ended. At 22:15 EST, DNS traffic for messaging sites was 30% higher than the earlier baseline.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image15.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Rihanna's announcement of her second pregnancy, which made <a href="https://www.nytimes.com/2023/02/13/style/rihanna-pregnancy-fashion-super-bowl.html">news</a> after her performance, also impacted traffic to social media platforms. After a small increase when halftime started, there was a clear drop during Rihanna's show, followed by a jump from 6% below baseline back to 0% right after the show. An additional 3% of traffic growth was reached during the final break at 22:00 EST, just before the Kansas City Chiefs' winning field goal. After a brief drop, traffic reached 2% above baseline as the game ended.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image1-5.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h2 id="is-halftime-also-a-time-for-rewatching-ads">Is halftime also a time for rewatching ads?</h2><p>The arrival of halftime at 20:21 EST also brought a surge in DNS traffic for video platforms. The first peak was reached at 18:00 EST, before the game started, at 12% above baseline. The peak during halftime was reached at 20:25 EST with 13% growth above baseline, suggesting that viewers may have been looking at that time to Super Bowl related videos or just using the time to browse those platforms.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image21.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Food delivery websites saw flat to lower DNS traffic just before the game as compared to the earlier baseline, suggesting that food orders were placed/scheduled earlier in the afternoon, hours before the game. At kickoff, traffic was 19% below baseline, but there was a clear spike at the time of the first break and right after the first Kansas City touchdown at 18:55 EST. After falling again during the game, there was a small increase in traffic observed just after the game ended.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image24.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>What about betting sites? They <a href="https://www.cnn.com/2023/02/12/investing/sports-betting-super-bowl/index.html">expected</a> a big day during the Super Bowl, given that more states have recently legalized gambling on sports. The peak was reached at 19:00 EST, as DNS traffic reached 295% over baseline, when the Chiefs had their first touchdown, The first Eagles touchdown, minutes before, resulted in a 233% spike. The lowest traffic for betting sites during the Super Bowl was during the halftime show. In the second half of the game, two other clear spikes in traffic are visible. The first was at 20:55 EST at 167% above baseline when the Chiefs pulled ahead with a touchdown, and then a jump to 278% over baseline when the game ended.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image8.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><!--kg-card-begin: markdown--><h2 id="rihannarunsthistowncity">Rihanna runs this <s>town</s> city</h2> <!--kg-card-end: markdown--><p>While the so-called NFL cities across the country are loyal to their local teams, looking at traffic trends across cities from both conferences makes it clear that fans everywhere find joy, not division, in the unknown pleasures of a good halftime show. The drop visible in both graphs below between 20:30-20:50 EST coincides with Rihanna’s return to live performance, as she <a href="https://www.sportingnews.com/us/nfl/news/super-bowl-halftime-show-2023-live-reviews-rihanna/fb1rlfiaxisnyxhjbljknftj">last performed live</a> in January 2018. Based on the observed drop in traffic, viewers apparently turned away from their computers and devices, giving their attention to Rihanna, or at least stopped their general Internet surfing during the halftime show. As the graphs show, traffic recovered as soon as halftime was over.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image11.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image5-2.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Zooming in to individual cities, we examined the traffic patterns observed in both Philadelphia and Kansas City. While both teams have fans across the country, we can use their home cities as a proxy. In this case, we compared normalized Internet traffic levels between 17:00-22:30 EST on Super Bowl Sunday (February 12) with the same time frame on the prior Sunday (February 5).</p><p>In Kansas City last Sunday, traffic volumes remained fairly consistent across the surveyed time period. However, on Super Bowl Sunday, traffic levels were initially similar, but by the start of the game were 84% lower than the same time the previous week. Slight drops in traffic are visible coincident with Chiefs touchdowns, but don’t stand out from the overall noisiness of the graph. The graph reached its nadir at 22:13 EST when the Chiefs broke the tie and kicked the game-winning field goal, with the significant drop in traffic likely due to an increased shift in focus towards the outcome of the game, even by those that hadn’t previously been paying close attention.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image7-2.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>As the graph below shows, last Sunday saw Internet traffic in Philadelphia gradually decline as the evening wore on. On Super Bowl Sunday, traffic started out slightly lower than the week prior, and also diverged as game time approached, reaching nearly 50% lower at kickoff. As the Eagles took an early lead, their first touchdown resulted in a noticeable drop in traffic from Philadelphia, seen at 18:52 EST, less than 10 minutes after the start of the game. Visible drops in traffic are also coincident with the Eagles’ other three touchdowns, although they don’t stand out against the volatility of the graph. Traffic began to drop towards the end of the game, as the tie score added tension, and reached its lowest point when it became clear that the Eagles were not going to emerge victorious in Super Bowl LVII.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image23.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h2 id="state-level-traffic-trends-the-winning-impact">State-level traffut to examine Internet traffic trends in the Super Bowl states. Arizona, which hosted the big game at State Farm Stadium in Glendale, saw a drop in state-level traffic starting around 13:00 EST. At the time of the kickoff, traffic was 25% lower than the previous Sunday, but the biggest impact was during the wildly popular halftime show by Rihanna. At 20:30 EST, traffic was 29% lower than the same time on the previous Sunday. After the game ended, traffic levels returned to normal around 23:30 EST.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image17.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>In Pennsylvania, home of the Philadelphia Eagles, traffic began to dip after 15:00 EST and reached its first low point around kickoff, when it was 28% lower than the previous Sunday. Just like in Arizona, the biggest difference was during Rihanna's halftime show, when it was a whopping 33% lower than usual. However, just a few minutes after the game ended at 22:30 EST, traffic returned to normal.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image12.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>What about the winning team's state of Missouri? There, traffic started to decrease only after 17:00 EST and was actually higher than the previous Sunday before that point. With the kickoff came a clear drop, resulting in 28% less traffic than the previous Sunday at the same time. Traffic increased a bit heading towards halftime, but dropped again during Rihanna's show, when it was 30% lower than usual. The biggest drop in traffic, not surprisingly, was during the exciting moment of the Kansas City Chiefs' winning field goal. At 22:15 EST, traffic was 33% lower than the previous Sunday. However, after 22:50 EST, Internet traffic in Missouri was back on the fast track, with traffic increasing to levels higher than the previous Sunday. </p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image18.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Rihanna’s halftime performance had a clear impact on Internet traffic at a state level, which dropped across all states with NFL teams at the time of her show. Below we take a closer look at the most populous states, among which Pennsylvania, New York and Arizona were winners, with the largest traffic declines. The impacts in Pennsylvania and Arizona are shown above, and the graph below shows the traffic trends seen in New York.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image19.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>California, Texas, Florida, and New York all had their fair share of Internet traffic dropping before and throughout the game, but it was during the halftime show when things really got interesting. At the time of Rihanna’s performance, Internet traffic in California was 24% lower than the previous Sunday, while in Texas it was 21% below a week earlier, and Florida also saw a 21% drop. Meanwhile, New York had a clear 30% decrease in traffic during the show and, as shown above, Pennsylvania took the cake with a 33% drop. Illinois, Ohio, Georgia, North Carolina, and Michigan were close behind with 23%, 27%, 22%, 25%, and 22% drops respectively. </p><p>This seems to be a clear indication that the Super Bowl in general, but also the much-anticipated halftime shows, and the winning celebrations, all have a massive impact on the Internet, causing a noticeable dip in Internet traffic, especially in the state of the winning team.</p><h2 id="do-email-spammers-and-scammers-take-advantage-of-the-big-game-">Do email spammers and scammers take advantage of “The Big Game”?</h2><p>Spammers and scammers will frequently try to take advantage of the popularity of major events when running their campaigns, hoping the tie-in will entice the user to open the message and click on a malicious link, or visit a malicious website where they give up a password or credit card number. <a href="https://www.cloudflare.com/products/zero-trust/email-security/">Cloudflare Area 1 Email Security</a> analyzed the subject lines of email messages processed by the service in the weeks leading up to the Super Bowl to identify malicious, suspicious, and spam messages across four topic areas: Super Bowl/football, sports gambling, sports media/websites, and food delivery. </p><p>As the “regular” season NFL games wrapped up, Super Bowl and football themed email thevious week. These campaigns quickly ended in the week before the big game, though, as Super Bowl and football themed suspicious, malicious, and spam email volume dropped by nearly 90%.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/SB1.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Overall, the number of sports gambling themed subject lines remained fairly low over the survey period. This is somewhat surprising, given that an increasing number of US states have recently legalized betting on sporting events. Interestingly, the trend was highest at the beginning of the year, although that first week was too late to capture potential interest in college football “bowl” games. However, the weeks ahead of the NFL conference championship games (January 23-29) and the Super Bowl (February 6-12) saw message volume increase to levels nearly 2.5x higher than previous weeks.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/SB2.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>Sports media and website themed suspicious, malicious, and spam email messages apparently don’t draw the clicks, because the volume of such messages seen by Cloudflare Area 1 has remained extremely low since the start of the year, but peaked during the week of January 23-29. And although lower in volume, the observed trends were similar to those seen for sports gambling, with peaks during the same weeks.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/SB3.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><p>For many people, the Super Bowl is less about the football game than it is about the commercials and the food, and the growth of food delivery services over the last few years have made it easier to ensure that the snacks and libations never run out during the game. Scammers and spammers have apparently learned to take advantage of this hunger, as food delivery themed email messages saw the highest counts across the four categories reviewed here. Peak message counts were seen the weeks of January 2-8 and January 30-February 5. Message volume the weeks following these peaks fell by over 50% in both cases.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/SB4.png" class="kg-image" alt="A look at Internet traffic trends during Super Bowl LVII"></figure><h2 id="conclusion">Conclusion</h2><p>As we have seen time and again, advertising during the Super Bowl can drive significant traffic spikes, and apparently this holds true even if a URL isn’t included as a call to action within the commercial. In addition, the trends observed during the game remain a clear reminder that human behavior drives Internet traffic, especially when the halftime show features a popular singer that last performed live five years ago.</p><p>Visit <a href="https://radar.cloudflare.com/">Cloudflare Radar</a> for up to date Internet traffic and attack trends, and follow the Cloudflare Radar <a href="https://twitter.com/CloudflareRadar">Twitter</a> and <a href="https://cloudflare.social/@radar">Mastodon</a> accounts for regular insights on Internet events.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Cloudflare mitigates record-breaking 71 million request-per-second DDoS attack ]]>
</title>
<description>
<![CDATA[ This was a weekend of record-breaking DDoS attacks. Over the weekend, Cloudflare detected and mitigated dozens of hyper-volumetric DDoS attacks. The majority of attacks peaked in the ballpark of 50-70 million requests per second (rps) with the largest exceeding 71 million rps ]]>
</description>
<link>https://blog.cloudflare.com/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack/</link>
<guid isPermaLink="false">63ea8013ea5b01000ae2942c</guid>
<category>
<![CDATA[ Attacks ]]>
</category>
<category>
<![CDATA[ Trends ]]>
</category>
<category>
<![CDATA[ Speed & Reliability ]]>
</category>
<category>
<![CDATA[ Security ]]>
</category>
<category>
<![CDATA[ DDoS ]]>
</category>
<category>
<![CDATA[ Botnet ]]>
</category>
<dc:creator>
<![CDATA[ Omer Yoachimik ]]>
</dc:creator>
<pubDate>Mon, 13 Feb 2023 18:37:51 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/DDoS-protection.png" medium="image"/>
<content:encoded>
<![CDATA[ <!--kg-card-begin: markdown--><img src="http://blog.cloudflare.com/content/images/2023/02/DDoS-protection.png" alt="Cloudflare mitigates record-breaking 71 million request-per-second DDoS attack"><p><small>This post is also available in <a href="http://blog.cloudflare.com/zh-cn/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-zh-cn/">简体中文</a>, <a href="http://blog.cloudflare.com/zh-tw/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-zh-tw/">繁體中文</a>, <a href="http://blog.cloudflare.com/ja-jp/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-ja-jp/">日本語</a>, <a href="http://blog.cloudflare.com/ko-kr/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-ko-kr/">한국어</a>, <a href="http://blog.cloudflare.com/es-es/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-es-es/">Español</a>, <a href="http://blog.cloudflare.com/de-de/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-de-de/">Deutsch</a> and <a href="http://blog.cloudflare.com/fr-fr/cloudflare-mitigates-record-breaking-71-million-request-per-second-ddos-attack-fr-fr/">Français</a>.</small></p> <!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/DDoS-protection-1.png" class="kg-image" alt="Cloudflare mitigates record-breaking 71 million request-per-second DDoS attack"></figure><p>This was a weekend of record-breaking <a href="https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/">DDoS attacks</a>. Over the weekend, Cloudflare detected and mitigated dozens of <em>hyper-volumetric</em> DDoS attacks. The majority of attacks peaked in the ballpark of 50-70 million requests per second (rps) with the largest exceeding 71 million rps. This is the largest reported HTTP DDoS attack on record, more than 54% higher than the previous reported record of 46M rps in June 2022.</p><p>The attacks were HTTP/2-based and targeted websites protected by Cloudflare. They originated from over 30,000 IP addresses. Some of the attacked websites included a popular gaming provider, cryptocurrency companies, hosting providers, and cloud computing platforms. The attacks originated from numerous cloud providers, and we have been working with them to crack down on the botnet.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/1711-1.png" class="kg-image" alt="Cloudflare mitigates record-breaking 71 million request-per-second DDoS attack"><figcaption>Record breaking attack: DDoS attack exceeding 71 million requests per second</figcaption></figure><p>Over the past year, we’ve seen more attacks originate from cloud computing providers. For this reason, we will be providing service providers that own their own autonomous system a <a href="http://blog.cloudflare.com/botnet-threat-feed-for-isp/">free Botnet threat feed</a>. The feed will provide service providers threat intelligence about their own IP space; attacks originating from within their autonomous system. Service providers that operate their own IP space can now <a href="https://www.cloudflare.com/lp/botnet-threat-feed/">sign up</a> to the early access waiting list.</p><h3 id="is-this-related-to-the-super-bowl-or-killnet">Is this related to the Super Bowl or Killnet?</h3><p>No. This campaign of attacks arrives less than two weeks after the <a href="http://blog.cloudflare.com/uptick-in-healthcare-organizations-experiencing-targeted-ddos-attacks/">Killnet DDoS campaign that targeted healthcare websites</a>. Based on the methods and targets, we do not believe that these recent attacks are related to the healthcare campaign. Furthermore, yesterday was the US Super Bowl, and we also do not believe that this attack campaign is related to the game event.</p><h3 id="what-are-ddos-attacks">What are DDoS attacks?</h3><p><a href="https://www.cloudflare.com/learning/ddos/what-is-a-ddos-attack/">Distributed Denial of Service attacks</a> are cyber attacks that aim to take down Internet properties and make them unavailable for users. These types of cyberattacks can be very efficient against unprotected websites and they can be very inexpensive for the attackers to execute. </p><p>An HTTP DDoS attack usually involves a <a href="https://www.cloudflare.com/learning/ddos/http-flood-ddos-attack/">flood of HTTP requests</a> towards the target website. The attacker’s objective is to bombard the website with more requests than it can handle. Given a sufficiently high amount of requests, the website’s server will not be able to process all of the attack requests along with the <em>legitimate </em>user requests. Users will experience this as website-load delays, timeouts, and eventually not being able to connect to their desired websites at all. </p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/1711-2.png" class="kg-image" alt="Cloudflare mitigates record-breaking 71 million request-per-second DDoS attack"><figcaption>Illustration of a DDoS attack</figcaption></figure><p>To make attacks larger and more complicated, attackers usually leverage a network of bots — a <em><a href="https://www.cloudflare.com/learning/ddos/what-is-a-ddos-botnet/">botnet</a></em>. The attacker will orchestrate the botnet to bombard the victim’s websites with HTTP requests. A sufficiently large and powerful botnet can generate very large attacks as we’ve seen in this case.</p><p>However, building and operating botnets requires a lot of investment and expertise. What is the average Joe to do? Well, an average Joe that wants to launch a DDoS attack against a website doesn’t need to start from scratch. They can hire one of numerous DDoS-as-a-Service platforms for as little as $30 per month. The more you pay, the larger and longer of an attack you’re going to get.</p><h3 id="why-ddos-attacks">Why DDoS attacks?</h3><p>Over the years, it has become easier, cheaper, and more accessible for attackers and attackers-for-hire to launch DDoS attacks. But as easy as it has become for the attackers, we want to make sure that it is even easier - and free - for defenders of organizations of all sizes to protect themselves against DDoS attacks of all types. </p><p>Unlike <a href="https://www.cloudflare.com/learning/security/ransomware/what-is-ransomware/">Ransomware</a> attacks, <a href="https://www.cloudflare.com/learning/ddos/ransom-ddos-attack/">Ransom DDoS attacks</a> don’t require an actual system intrusion or a foothold within the targeted network. Usually Ransomware attacks start once an employee naively clicks an email link that installs and propagates the malware. There’s no need for that with DDoS attacks. They are more like a hit-and-run attack. All a DDoS attacker needs to know is the website’s address and/or IP address.</p><h3 id="is-there-an-increase-in-ddos-attacks">Is there an increase in DDoS attacks?</h3><p>Yes. The size, sophistication, and frequency of attacks has been increasing over the past months. In our latest <a href="http://blog.cloudflare.com/ddos-threat-report-2022-q4/">DDoS threat report</a>, we saw that the amount of HTTP DDoS attacks increased by 79% year-over-year. Furthermore, the amount of volumetric attacks exceeding 100 Gbps grew by 67% quarter-over-quarter (QoQ), and the number of attacks lasting more than three hours increased by 87% QoQ.</p><p>But it doesn’t end there. The audacity of attackers has been increasing as well. In our latest DDoS threat report, we saw that <a href="https://www.cloudflare.com/learning/ddos/ransom-ddos-attack/">Ransom DDoS attacks</a> steadily increased throughout the year. They peaked in November 2022 where one out of every four surveyed customers reported being subject to Ransom DDoS attacks or threats.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/02/1711-3.png" class="kg-image" alt="Cloudflare mitigates record-breaking 71 million request-per-second DDoS attack"><figcaption>Distribution of Ransom DDoS attacks by month</figcaption></figure><h3 id="should-i-be-worried-about-ddos-attacks">Should I be worried about DDoS attacks?</h3><p>Yes. If your website, server, or networks are not protected against volumetric DDoS attacks using a cloud service that provides automatic detection and mitigation, we really recommend that you consider it. </p><p>Cloudflare customers shouldn’t be worried, but should be aware and prepared. Below is a list of recommended steps to ensure your security posture is optimized.</p><h3 id="what-steps-should-i-take-to-defend-against-ddos-attacks">What steps should I take to defend against DDoS attacks?</h3><p>Cloudflare’s systems have been automatically detecting and <a href="https://www.cloudflare.com/learning/ddos/ddos-mitigation/ ">mitigating</a> these DDoS attacks. </p><p>Cloudflare offers many features and capabilities that you may already have access to but may not be using. So as extra precaution, we recommend taking advantage of these capabilities to improve and optimize your security posture:</p><ol><li>Ensure all <a href="https://developers.cloudflare.com/ddos-protection/managed-rulesets/">DDoS Managed Rules</a> are set to default settings (High sensitivity level and mitigation actions) for optimal DDoS activation.</li><li>Cloudflare Enterprise customers that are subscribed to the Advanced DDoS Protection service should consider enabling <a href="https://developers.cloudflare.com/ddos-protection/managed-rulesets/adaptive-protection/">Adaptive DDoS Protection</a>, which mitigates attacks more intelligently based on your unique traffic patterns.</li><li>Deploy <a href="https://developers.cloudflare.com/firewall/cf-firewall-rules/">firewall rules</a> and <a href="https://developers.cloudflare.com/waf/rate-limiting-rules/">rate limiting rules</a> to enforce a combined positive and negative security model. Reduce the traffic allowed to your website based on your known usage.</li><li>Ensure your origin is not exposed to the public Internet (i.e., <a href="https://developers.cloudflare.com/fundamentals/get-started/setup/allow-cloudflare-ip-addresses/">only enable access to Cloudflare IP addresses</a>). As an extra security precaution, we recommend contacting your hosting provider and requesting new origin server IPs if they have been targeted directly in the past.</li><li>Customers with access to <a href="https://developers.cloudflare.com/fundamentals/global-configurations/lists/ip-lists/#managed-ip-lists">Managed IP Lists</a> should consider leveraging those lists in firewall rules. Customers with <a href="https://developers.cloudflare.com/bots/get-started/bm-subscription/">Bot Management</a> should consider leveraging the bot scores within the firewall rules.</li><li>Enable <a href="https://developers.cloudflare.com/cache/">caching</a> as much as possible to reduce the strain on your origin servers, and when using <a href="https://workers.cloudflare.com/">Workers</a>, avoid overwhelming your origin server with more subrequests than necessary.</li><li>Enable <a href="https://developers.cloudflare.com/ddos-protection/reference/alerts/">DDoS alerting</a> to improve your response time.</li></ol><h3 id="preparing-for-the-next-ddos-wave">Preparing for the next DDoS wave</h3><p>Defending against DDoS attacks is critical for organizations of all sizes. While attacks may be initiated by humans, they are executed by bots — and to play to win, you must fight bots with bots. Detection and mitigation must be automated as much as possible, because relying solely on humans to mitigate in real time puts defenders at a disadvantage. Cloudflare’s automated systems constantly detect and mitigate DDoS attacks for our customers, so they don’t have to. This automated approach, combined with our wide breadth of security capabilities, lets customers tailor the protection to their needs.</p><p>We've been providing <a href="http://blog.cloudflare.com/unmetered-mitigation/">unmetered and unlimited DDoS protection</a> for free to all of our customers since 2017, when we pioneered the concept. Cloudflare's mission is to help build a better Internet. A better Internet is one that is more secure, faster, and reliable for everyone - even in the face of DDoS attacks.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Welcome to Wildebeest: the Fediverse on Cloudflare ]]>
</title>
<description>
<![CDATA[ Today we're announcing Wildebeest, an open-source, easy-to-deploy ActivityPub and Mastodon-compatible server built entirely on top of Cloudflare's Supercloud. ]]>
</description>
<link>https://blog.cloudflare.com/welcome-to-wildebeest-the-fediverse-on-cloudflare/</link>
<guid isPermaLink="false">63e3ec0aea5b01000ae290cd</guid>
<category>
<![CDATA[ Wildebeest ]]>
</category>
<category>
<![CDATA[ Cloudflare Pages ]]>
</category>
<category>
<![CDATA[ D1 ]]>
</category>
<category>
<![CDATA[ Cloudflare Workers ]]>
</category>
<category>
<![CDATA[ Cloudflare Zero Trust ]]>
</category>
<dc:creator>
<![CDATA[ Celso Martinho ]]>
</dc:creator>
<pubDate>Wed, 08 Feb 2023 19:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/Wildebeest-1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/Wildebeest.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/Wildebeest-1.png" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"><p><a href="https://en.wikipedia.org/wiki/Fediverse">The Fediverse</a> has been a hot topic of discussion lately, with thousands, if not <a href="https://bitcoinhackers.org/@mastodonusercount">millions</a>, of new users creating accounts on platforms like <a href="https://joinmastodon.org/">Mastodon</a> to either move entirely to "the other side" or experiment and learn about this new social network.</p><p>Today we're introducing <a href="https://github.com/cloudflare/wildebeest">Wildebeest</a>, an open-source, easy-to-deploy ActivityPub and Mastodon-compatible server built entirely on top of Cloudflare's Supercloud. If you want to run your own spot in the Fediverse you can now do it entirely on Cloudflare.</p><h2 id="the-fediverse-built-on-cloudflare">The Fediverse, built on Cloudflare</h2><p>Today you're left with two options if you want to join the Mastodon federated network: either you join one of the <a href="https://joinmastodon.org/servers">existing servers</a> (servers are also called communities, and each one has its own infrastructure and rules), or you can run your self-hosted server.</p><p>There are a few reasons why you'd want to run your own server:</p><ul><li>You want to create a new community and attract other users over a common theme and usage rules.</li><li>You don't want to have to trust third-party servers or abide by their policies and want your server, under your domain, for your personal account.</li><li>You want complete control over your data, personal information, and content and visibility over what happens with your instance.</li></ul><p>The Mastodon gGmbH non-profit organization provides a server implementation using Ruby, Node.js, PostgreSQL and Redis. Running the <a href="https://github.com/mastodon/mastodon">official server</a> can be challenging, though. You need to own or rent a server or VPS somewhere; you have to install and configure the software, set up the database and public-facing web server, and configure and protect your network against attacks or abuse. And then you have to maintain all of that and deal with constant updates. It's a lot of scripting and technical work before you can get it up and running; definitely not something for the less technical enthusiasts. </p><p>Wildebeest serves two purposes: you can quickly deploy your Mastodon-compatible server on top of Cloudflare and connect it to the Fediverse in minutes, and you don't need to worry about maintaining or protecting it from abuse or attacks; Cloudflare will do it for you automatically.</p><p>Wildebeest is not a managed service. It's your instance, data, and code running in our cloud under your Cloudflare account. Furthermore, it's <a href="https://github.com/cloudflare/wildebeest">open-sourced</a>, which means it keeps evolving with more features, and anyone can <a href="https://github.com/cloudflare/wildebeest/pulls">extend</a> and improve it.</p><p>Here's what we support today:</p><ul><li><a href="https://www.w3.org/TR/activitypub/">ActivityPub</a>, <a href="https://www.rfc-editor.org/rfc/rfc7033">WebFinger</a>, <a href="https://github.com/cloudflare/wildebeest/tree/main/functions/nodeinfo">NodeInfo</a>, <a href="https://datatracker.ietf.org/doc/html/rfc8030">WebPush</a> and <a href="https://docs.joinmastodon.org/api/">Mastodon-compatible</a> APIs. Wildebeest can connect to or receive connections from other Fediverse servers.</li><li>Compatible with the most popular Mastodon <a href="https://github.com/nolanlawson/pinafore">web</a> (like <a href="https://github.com/nolanlawson/pinafore">Pinafore</a>), desktop, and <a href="https://joinmastodon.org/apps">mobile clients</a>. We also provide a simple read-only web interface to explore the timelines and user profiles.</li><li>You can publish, edit, boost, or delete posts, sorry, toots. We support text, images, and (soon) video.</li><li>Anyone can follow you; you can follow anyone.</li><li>You can search for content.</li><li>You can register one or multiple accounts under your instance. Authentication can be email-based on or using any Cloudflare Access compatible IdP, like GitHub or Google.</li><li>You can edit your profile information, avatar, and header image.</li></ul><h2 id="how-we-built-it">How we built it</h2><p>Our implementation is built entirely on top of our <a href="https://www.cloudflare.com/en-gb/cloudflare-product-portfolio/">products</a> and <a href="https://developers.cloudflare.com/">APIs</a>. Building Wildebeest was another excellent opportunity to showcase our technology stack's power and versatility and prove how anyone can also use Cloudflare to build larger applications that involve multiple systems and complex requirements.</p><p>Here's a birds-eye diagram of Wildebeest's architecture:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/Screenshot-2023-02-08-at-10.58.01-AM.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>Let's get into the details and get technical now.</p><h3 id="cloudflare-pages">Cloudflare Pages</h3><p>At the core, Wildebeest is a <a href="https://pages.cloudflare.com/">Cloudflare Pages</a> project running its code using <a href="https://developers.cloudflare.com/pages/platform/functions/">Pages Functions</a>. Cloudflare Pages provides an excellent foundation for building and deploying your application and serving your bundled assets, Functions gives you full access to the Workers ecosystem, where you can run any code.</p><p>Functions has a built-in <a href="https://developers.cloudflare.com/pages/platform/functions/routing/">file-based router</a>. The <a href="https://github.com/cloudflare/wildebeest/tree/main/functions">/functions</a> directory structure, which is uploaded by Wildebeest’s continuous deployment builds, defines your application routes and what files and code will process each HTTP endpoint request. This routing technique is similar to what other frameworks like Next.js <a href="https://nextjs.org/docs/routing/introduction">use</a>.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/2b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>For example, Mastodon’s <a href="https://docs.joinmastodon.org/methods/timelines/#public">/api/v1/timelines/public</a> API endpoint is handled by <a href="https://github.com/cloudflare/wildebeest/blob/main/functions/api/v1/timelines/public.ts">/functions/api/v1/timelines/public.ts</a> with the onRequest method. </p><pre><code class="language-js">export onRequest = async ({ request, env }) =&gt; { const { searchParams } = new URL(request.url) const domain = new URL(request.url).hostname ... return handleRequest(domain, env.DATABASE, {}) } export async function handleRequest( … ): Promise&lt;Response&gt; { … } </code></pre><p>Unit testing these endpoints becomes easier too, since we only have to call the handleRequest() function from the testing framework. Check one of our <a href="https://jestjs.io/">Jest</a> tests, <a href="https://github.com/cloudflare/wildebeest/blob/main/backend/test/mastodon.spec.ts">mastodon.spec.ts</a>:</p><pre><code class="language-js">import * as v1_instance from 'wildebeest/functions/api/v1/instance' describe('Mastodon APIs', () =&gt; { describe('instance', () =&gt; { test('return the instance infos v1', async () =&gt; { const res = await v1_instance.handleRequest(domain, env) assert.equal(res.status, 200) assertCORS(res) const data = await res.json&lt;Data&gt;() assert.equal(data.rules.length, 0) assert(data.version.includes('Wildebeest')) }) }) }) </code></pre><p>As with any other regular Worker, Functions also lets you set up <a href="https://developers.cloudflare.com/pages/platform/functions/bindings/">bindings</a> to interact with other Cloudflare products and features like <a href="https://developers.cloudflare.com/workers/runtime-apis/kv/">KV</a>, <a href="https://developers.cloudflare.com/r2/data-access/workers-api/workers-api-reference/">R2</a>, <a href="https://developers.cloudflare.com/d1/">D1</a>, <a href="https://developers.cloudflare.com/workers/runtime-apis/durable-objects/">Durable Objects</a>, and more. The list keeps growing.</p><p>We use Functions to implement a large portion of the official <a href="https://docs.joinmastodon.org/api/">Mastodon API</a> specification, making Wildebeest compatible with the existing ecosystem of other servers and client applications, and also to run our own read-only web frontend under the same project codebase.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/3b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>Wildebeest’s web frontend uses <a href="https://qwik.builder.io/">Qwik</a>, a general-purpose web framework that is optimized for speed, uses modern concepts like the JSX JavaScript syntax extension and supports server-side-rendering (SSR) and static site generation (SSG).</p><p>Qwik provides a <a href="https://qwik.builder.io/integrations/deployments/cloudflare-pages/">Cloudflare Pages Adaptor</a> out of the box, so we use that (check our <a href="https://developers.cloudflare.com/pages/framework-guides/deploy-a-qwik-site/">framework guide</a> to know more about how to deploy a Qwik site on Cloudflare Pages). For styling we use the <a href="https://tailwindcss.com/">Tailwind CSS</a> framework, which Qwik supports natively.</p><p>Our frontend website code and static assets can be found under the <a href="https://github.com/cloudflare/wildebeest/tree/main/frontend">/frontend</a> directory. The application is handled by the <a href="https://github.com/cloudflare/wildebeest/blob/main/functions/%5B%5Bpath%5D%5D.ts">/functions/[[path]].js</a> dynamic route, which basically catches all the non-API requests, and then <a href="https://github.com/cloudflare/wildebeest/blob/main/frontend/src/entry.cloudflare-pages.tsx">invokes</a> Qwik’s own internal router, <a href="https://qwik.builder.io/qwikcity/routing/overview/">Qwik City</a>, which takes over everything else after that.</p><p>The power and versatility of Pages and Functions routes make it possible to run both the backend APIs and a server-side-rendered dynamic client, effectively a full-stack app, under the same project.</p><p>Let's dig even deeper now, and understand how the server interacts with the other components in our architecture.</p><h3 id="d1">D1</h3><p>Wildebeest uses <a href="https://developers.cloudflare.com/d1/">D1</a>, Cloudflare’s first SQL database for the Workers platform built on top of SQLite, now open to everyone in <a href="http://blog.cloudflare.com/d1-open-alpha/">alpha</a>, to store and query data. Here’s our schema:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/4b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>The schema will probably change in the future, as we add more features. That’s fine, D1 supports <a href="https://developers.cloudflare.com/d1/platform/migrations/">migrations</a> which are great when you need to update your database schema without losing your data. With each new Wildebeest version, we can create a <a href="https://github.com/cloudflare/wildebeest/blob/main/migrations/0001_add-unique-following.sql">new migration</a> file if it requires database schema changes.</p><pre><code class="language-SQL">-- Migration number: 0001 2023-01-16T13:09:04.033Z CREATE UNIQUE INDEX unique_actor_following ON actor_following (actor_id, target_actor_id); </code></pre><p>D1 exposes a powerful <a href="https://developers.cloudflare.com/d1/platform/client-api/">client API</a> that developers can use to manipulate and query data from Worker scripts, or in our case, Pages Functions.</p><p>Here’s a simplified example of how we interact with D1 when you start following someone on the Fediverse:</p><pre><code class="language-js">export async function addFollowing(db, actor, target, targetAcct): Promise&lt;UUID&gt; { const query = `INSERT OR IGNORE INTO actor_following (id, actor_id, target_actor_id, state, target_actor_acct) VALUES (?, ?, ?, ?, ?)` const out = await db .prepare(query) .bind(id, actor.id.toString(), target.id.toString(), STATE_PENDING, targetAcct) .run() return id } </code></pre><p>Cloudflare’s culture of dogfooding and building on top of our own products means that we sometimes experience their shortcomings before our users. We did face a few challenges using D1, which is built on SQLite, to store our data. Here are two examples. </p><p><a href="https://www.w3.org/TR/activitypub/">ActivityPub</a> uses <a href="https://www.rfc-editor.org/rfc/rfc4122.txt">UUIDs</a> to identify objects and reference them in URIs extensively. These objects need to be stored in the database. Other databases like PostgreSQL provide built-in functions to <a href="https://www.postgresql.org/docs/current/functions-uuid.html">generate unique identifiers</a>. SQLite and D1 don't have that, yet, it’s in our roadmap.</p><p>Worry not though, the Workers runtime supports <a href="https://developers.cloudflare.com/workers/runtime-apis/web-crypto/">Web Crypto</a>, so we use crypto.randomUUID() to get our unique identifiers. Check the <a href="https://github.com/cloudflare/wildebeest/blob/main/backend/src/activitypub/actors/inbox.ts">/backend/src/activitypub/actors/inbox.ts</a>:</p><pre><code class="language-js">export async function addObjectInInbox(db, actor, obj) { const id = crypto.randomUUID() const out = await db .prepare('INSERT INTO inbox_objects(id, actor_id, object_id) VALUES(?, ?, ?)') .bind(id, actor.id.toString(), obj.id.toString()) .run() }</code></pre><p>Problem solved.</p><p>The other example is that we need to store dates with sub-second resolution. Again, databases like PostgreSQL have that:</p><pre><code class="language-bash">psql&gt; select now(); 2023-02-01 11:45:17.425563+00</code></pre><p>However SQLite falls short with:</p><pre><code class="language-bash">sqlite&gt; select datetime(); 2023-02-01 11:44:02</code></pre><p>We worked around this problem with a small hack using <a href="https://www.sqlite.org/lang_datefunc.html">strftime()</a>:</p><pre><code class="language-bash">sqlite&gt; select strftime('%Y-%m-%d %H:%M:%f', 'NOW'); 2023-02-01 11:49:35.624</code></pre><p>See our <a href="https://github.com/cloudflare/wildebeest/blob/main/migrations/0000_initial.sql">initial SQL schema</a>, look for the <em>cdate</em> defaults.</p><h3 id="images">Images</h3><p>Mastodon content has a lot of rich media. We don't need to reinvent the wheel and build an image pipeline; Cloudflare Images <a href="https://developers.cloudflare.com/images/">provides APIs</a> to upload, transform, and serve optimized images from our global CDN, so it's the perfect fit for Wildebeest's requirements.</p><p>Things like posting content images, the profile avatar, or headers, all use the Images APIs. See <a href="https://github.com/cloudflare/wildebeest/blob/main/backend/src/media/image.ts">/backend/src/media/image.ts</a> to understand how we interface with Images.</p><pre><code class="language-js">async function upload(file: File, config: Config): Promise&lt;UploadResult&gt; { const formData = new FormData() const url = `https://api.cloudflare.com/client/v4/accounts/${config.accountId}/images/v1` formData.set('file', file) const res = await fetch(url, { method: 'POST', body: formData, headers: { authorization: 'Bearer ' + config.apiToken, }, }) const data = await res.json() return data.result }</code></pre><p>If you're curious about Images for your next project, here's a tutorial on <a href="https://developers.cloudflare.com/images/cloudflare-images/tutorials/integrate-cloudflare-images/">how to integrate Cloudflare Images</a> on your website.</p><p>Cloudflare Images is also available from the dashboard. You can use it to browse or manage your catalog quickly. </p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/5b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><h3 id="queues">Queues</h3><p>The <a href="https://www.w3.org/TR/activitypub/">ActivityPub</a> protocol is chatty by design. Depending on the size of your social graph, there might be a lot of back-and-forth HTTP traffic. We can’t have the clients blocked waiting for hundreds of Fediverse message deliveries every time someone posts something.</p><p>We needed a way to work asynchronously and launch background jobs to offload data processing away from the main app and keep the clients snappy. The official Mastodon server has a similar strategy using <a href="https://docs.joinmastodon.org/admin/scaling/#sidekiq">Sidekiq</a> to do background processing.</p><p>Fortunately, we don't need to worry about any of this complexity either. <a href="https://developers.cloudflare.com/queues/">Cloudflare Queues</a> allows developers to send and receive messages with guaranteed delivery, and offload work from your Workers' requests, effectively providing you with asynchronous batch job capabilities.</p><p>To put it simply, you have a queue topic identifier, which is basically a buffered list that scales automatically, then you have one or more producers that, well, produce structured messages, JSON objects in our case, and put them in the queue (you define their schema), and finally you have one or more consumers that subscribes that queue, receive its messages and process them, at their own speed.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/6b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>Here’s the <a href="https://developers.cloudflare.com/queues/learning/how-queues-works/">How Queues works</a> page for more information.</p><p>In our case, the main application produces queue jobs whenever any incoming API call requires long, expensive operations. For example, when someone posts, sorry, <em>toots</em> something, we need to broadcast that to their followers' inboxes, potentially triggering many requests to remote servers. <a href="https://github.com/cloudflare/wildebeest/blob/main/backend/src/activitypub/deliver.ts">Here we are</a> queueing a job for that, thus freeing the APIs to keep responding:</p><pre><code class="language-js">export async function deliverFollowers( db: D1Database, from: Actor, activity: Activity, queue: Queue ) { const followers = await getFollowers(db, from) const messages = followers.map((id) =&gt; { const body = { activity: JSON.parse(JSON.stringify(activity)), actorId: from.id.toString(), toActorId: id, } return { body } }) await queue.sendBatch(messages) }</code></pre><p>Similarly, we don't want to stop the main APIs when remote servers deliver messages to our instance inboxes. Here's Wildebeest creating asynchronous jobs when it <a href="https://github.com/cloudflare/wildebeest/blob/main/functions/ap/users/%5Bid%5D/inbox.ts">receives messages</a> in the inbox:</p><pre><code class="language-js">export async function handleRequest( domain: string, db: D1Database, id: string, activity: Activity, queue: Queue, ): Promise&lt;Response&gt; { const handle = parseHandle(id) const actorId = actorURL(domain, handle.localPart) const actor = await actors.getPersonById(db, actorId) // creates job await queue.send({ type: MessageType.Inbox, actorId: actor.id.toString(), activity, }) // frees the API return new Response('', { status: 200 }) }</code></pre><p>And the final piece of the puzzle, our <a href="https://github.com/cloudflare/wildebeest/tree/main/consumer">queue consumer</a> runs in a separate Worker, independently from the Pages project. The consumer listens for new messages and processes them sequentially, at its rhythm, freeing everyone else from blocking. When things get busy, the queue grows its buffer. Still, things keep running, and the jobs will eventually get dispatched, freeing the main APIs for the critical stuff: responding to remote servers and clients as quickly as possible.</p><pre><code class="language-js">export default { async queue(batch, env, ctx) { for (const message of batch.messages) { … switch (message.body.type) { case MessageType.Inbox: { await handleInboxMessage(...) break } case MessageType.Deliver: { await handleDeliverMessage(...) break } } } }, }</code></pre><p>If you want to get your hands dirty with Queues, here’s a simple example on <a href="https://developers.cloudflare.com/queues/examples/send-errors-to-r2/">Using Queues to store data in R2</a>.</p><h3 id="caching-and-durable-objects">Caching and Durable Objects</h3><p>Caching repetitive operations is yet another strategy for improving performance in complex applications that require data processing. A famous Netscape developer, Phil Karlton, once said: "There are only two hard things in Computer Science: <strong>cache invalidation</strong> and naming things."</p><p>Cloudflare obviously knows a lot about caching since <a href="https://developers.cloudflare.com/cache/">it's a core feature</a> of our global CDN. We also provide <a href="https://developers.cloudflare.com/workers/learning/how-kv-works/">Workers KV</a> to our customers, a global, low-latency, key-value data store that anyone can use to cache data objects in our data centers and build fast websites and applications.</p><p>However, KV achieves its performance by being eventually consistent. While this is fine for many applications and use cases, it's not ideal for others.</p><p>The ActivityPub protocol is highly transactional and can't afford eventual consistency. Here's an example: generating complete timelines is expensive, so we cache that operation. However, when you post something, we need to invalidate that cache before we reply to the client. Otherwise, the new post won't be in the timeline and the client can fail with an error because it doesn’t see it. This actually happened to us with one of the most popular clients.</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/7b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>We needed to get clever. The team discussed a few options. Fortunately, our API catalog has plenty of options. Meet <a href="https://developers.cloudflare.com/workers/learning/using-durable-objects/">Durable Objects</a>.</p><p>Durable Objects are single-instance Workers that provide a transactional storage API. They're ideal when you need central coordination, strong consistency, and state persistence. You can use Durable Objects in cases like handling the state of <a href="https://developers.cloudflare.com/workers/learning/using-websockets/#durable-objects-and-websocket-state">multiple WebSocket</a> connections, coordinating and routing messages in a <a href="https://github.com/cloudflare/workers-chat-demo">chatroom</a>, or even <a href="http://blog.cloudflare.com/doom-multiplayer-workers/">running a multiplayer game like Doom</a>.</p><p>You know where this is going now. Yes, we implemented our key-value caching subsystem for Wildebeest <a href="https://github.com/cloudflare/wildebeest/tree/main/do">on top of a Durable Object</a>. By taking advantage of the DO's native transactional storage API, we can have strong guarantees that whenever we create or change a key, the next read will always return the latest version.</p><p>The idea is so simple and effective that it took us literally a <a href="https://github.com/cloudflare/wildebeest/blob/main/do/src/index.ts">few lines of code</a> to implement a key-value cache with two primitives: HTTP PUT and GET.</p><pre><code class="language-js">export class WildebeestCache { async fetch(request: Request) { if (request.method === 'GET') { const { pathname } = new URL(request.url) const key = pathname.slice(1) const value = await this.storage.get(key) return new Response(JSON.stringify(value)) } if (request.method === 'PUT') { const { key, value } = await request.json() await this.storage.put(key, value) return new Response('', { status: 201 }) } } } </code></pre><p>Strong consistency it is. Let's move to user registration and authentication now.</p><h3 id="zero-trust-access">Zero Trust Access</h3><p>The official Mastodon server <a href="https://docs.joinmastodon.org/user/signup/">handlreat volume remained relatively low. However, campaigns clearly picked up between January 23-29 as the message coues user registrations</a>, typically using email, before you can choose your local username and start using the service. Handling user registration and authentication can be daunting and time-consuming if we were to build it from scratch though. </p><p>Furthermore, people don't want to create new credentials for every new service they want to use and instead want more convenient OAuth-like authorization and authentication methods so that they can reuse their existing Apple, Google, or GitHub accounts.</p><p>We wanted to simplify things using Cloudflare’s built-in features. Needless to say, we have a product that handles user onboarding, authentication, and <a href="https://developers.cloudflare.com/cloudflare-one/policies/access/policy-management/">access policies</a> to any application behind Cloudflare; it's called <a href="https://developers.cloudflare.com/cloudflare-one/">Zero Trust</a>. So we put Wildebeest behind it.</p><p>Zero Trust Access can either do one-time PIN (<a href="https://en.wikipedia.org/wiki/One-time_password">OTP</a>) authentication using email or single-sign-on (SSO) with many identity providers (examples: Google, Facebook, GitHub, LinkedIn), including any generic one supporting <a href="https://developers.cloudflare.com/cloudflare-one/identity/idp-integration/generic-saml/">SAML 2.0</a>.</p><p>When you start using Wildebeest with a client, you don't need to register at all. Instead, you go straight to log in, which will redirect you to the Access page and handle the authentication according to the policy that you, the owner of your instance, configured.</p><p>The policy defines who can authenticate, and how.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/8b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>When authenticated, Access will redirect you back to Wildebeest. The first time this happens, we will detect that we don't have information about the user and ask for your Username and Display Name. This will be asked only once and is what will be to create your public Mastodon profile.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/9b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>Technically, Wildebeest implements the <a href="https://docs.joinmastodon.org/spec/oauth/#implementation">OAuth 2 specification</a>. Zero Trust protects the <a href="https://github.com/cloudflare/wildebeest/blob/main/functions/oauth/authorize.ts">/oauth/authorize</a> endpoint and issues a valid <a href="https://developers.cloudflare.com/cloudflare-one/identity/authorization-cookie/validating-json/">JWT token</a> in the request headers when the user is authenticated. Wildebeest then reads and verifies the JWT and returns an authorization code in the URL redirect.</p><p>Once the client has an authorization code, it can use the <a href="https://github.com/cloudflare/wildebeest/blob/main/functnt grew sevenfold. However, campaigns kicked into high gear once the Chiefs and Eagles were headed to the Super Bowl, as the number of identified messages between January 30 and February 5 was nearly six times higher than the pric trends: the winning impact</h2><p>In addition to looking at traffic impacts at a city level, we can also zoom oions/oauth/token.ts">/oauth/token</a> endpoint to obtain an API access token. Subsequent API calls inject a bearer token in the Authorization header:</p><p><code>Authorization: Bearer access_token</code></p><h3 id="deployment-and-continuous-integration">Deployment and Continuous Integration</h3><p>We didn't want to run a managed service for Mastodon as it would somewhat diminish the concepts of federation and data ownership. Also, we recognize that ActivityPub and Mastodon are emerging, fast-paced technologies that will evolve quickly and in ways that are difficult to predict just yet.</p><p>For these reasons, we thought the best way to help the ecosystem right now would be to provide an open-source software package that anyone could use, customize, improve, and deploy on top of our cloud. Cloudflare will obviously keep improving Wildebeest and support the community, but we want to give our Fediverse maintainers complete control and ownership of their instances and data.</p><p>The remaining question was, how do we distribute the Wildebeest bundle and make it easy to deploy into someone's account when it requires configuring so many Cloudflare features, and how do we facilitate updating the software over time?</p><p>The solution ended up being a clever mix of using GitHub with <a href="https://github.com/features/actions">GitHub Actions</a>, <a href="https://developers.cloudflare.com/workers/platform/deploy-button/">Deploy with Workers</a>, and <a href="https://github.com/cloudflare/terraform-provider-cloudflare">Terraform</a>. </p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/Screenshot-2023-02-08-at-11.13.05-AM-1.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>The Deploy with Workers button is a specially crafted link that auto-generates a workflow page where the user gets asked some questions, and Cloudflare handles authorizing GitHub to deploy to Workers, automatically forks the Wildebeest repository into the user's account, and then configures and deploys the project using a <a href="https://github.com/marketplace/actions/deploy-to-cloudflare-workers-with-wrangler">GitHub Actions</a> workflow.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/10b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>A GitHub Actions <a href="https://docs.github.com/en/actions/using-workflows/about-workflows">workflow</a> is a YAML file that declares what to do in every step. Here’s the <a href="https://github.com/cloudflare/wildebeest/blob/main/.github/workflows/deploy.yml">Wildebeest workflow</a> (simplified):</p><pre><code class="language-YAML">name: Deploy on: push: branches: - main repository_dispatch: jobs: deploy: runs-on: ubuntu-latest timeout-minutes: 60 steps: - name: Ensure CF_DEPLOY_DOMAIN and CF_ZONE_ID are defined ... - name: Create D1 database uses: cloudflare/wrangler-action@2.0.0 with: command: d1 create wildebeest-${{ env.OWNER_LOWER }} ... - name: retrieve Zero Trust organization ... - name: retrieve Terraform state KV namespace ... - name: download VAPID keys ... - name: Publish DO - name: Configure run: terraform plan &amp;&amp; terraform apply -auto-approve - name: Create Queue ... - name: Publish consumer ... - name: Publish uses: cloudflare/wrangler-action@2.0.0 with: command: pages publish --project-name=wildebeest-${{ env.OWNER_LOWER }} .</code></pre><h4 id="updating-wildebeest">Updating Wildebeest</h4><p>This workflow runs automatically every time the main branch changes, so updating the Wildebeest is as easy as synchronizing the upstream official repository with the fork. You don't even need to use git commands for that; GitHub provides a convenient Sync button in the UI that you can simply click. </p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/11b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>What's more? Updates are incremental and non-destructive. When the GitHub Actions workflow redeploys Wildebeest, we only make the necessary changes to your configuration and nothing else. You don't lose your data; we don't need to delete your existing configurations. Here’s how we achieved this:</p><p>We use <a href="https://registry.terraform.io/providers/cloudflare/cloudflare/latest/docs">Terraform</a>, a declarative configuration language and tool that interacts with our APIs and can query and configure your Cloudflare features. Here's the trick, whenever we apply a new configuration, we keep a copy of the Terraform state for Wildebeest in a <a href="https://developers.cloudflare.com/workers/learning/how-kv-works/">Cloudflare KV</a> key. When a new deployment is triggered, we get that state from the KV copy, calculate the differences, then change only what's necessary.</p><p>Data loss is not a problem either because, as you read above, D1 supports <a href="https://developers.cloudflare.com/d1/platform/migrations/">migrations</a>. If we need to add a new column to a table or a new table, we don't need to destroy the database and create it again; we just apply the necessary SQL to that change.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/12b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><h3 id="protection-optimization-and-observability-naturally">Protection, optimization and observability, naturally</h3><p>Once Wildebeest is up and running, you can protect it from bad traffic and malicious actors. Cloudflare offers you <a href="https://www.cloudflare.com/en-gb/ddos/">DDoS</a>, <a href="https://www.cloudflare.com/en-gb/waf/">WAF</a>, and <a href="https://www.cloudflare.com/en-gb/products/bot-management/">Bot Management</a> protection out of the box at a click's distance.</p><p>Likewise, you'll get instant network and content delivery optimizations from our products and <a href="https://www.cloudflare.com/en-gb/analytics/">analytics</a> on how your Wildebeest instance is performing and being used.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/13b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><h3 id="activitypub-webfinger-nodeinfo-and-mastodon-apis">ActivityPub, WebFinger, NodeInfo and Mastodon APIs</h3><p>Mastodon popularized the Fediverse concept, but many of the underlying technologies used have been around for quite a while. This is one of those rare moments when everything finally comes together to create a working platform that answers an actual use case for Internet users. Let's quickly go through the protocols that Wildebeest had to implement:</p><h4 id="activitypub">ActivityPub</h4><p><a href="https://www.w3.org/TR/activitypub/">ActivityPub</a> is a decentralized social networking protocol and has been around as a W3C recommendation since at least 2018. It defines client APIs for creating and manipulating content and server-to-server APIs for content exchange and notifications, also known as federation. ActivityPub uses <a href="https://www.w3.org/TR/activitystreams-core/">ActivityStreams</a>, an even older W3C protocol, for its vocabulary. </p><p>The concepts of <a href="https://www.w3.org/TR/activitypub/#actors">Actors</a> (profiles), messages or <a href="https://www.w3.org/TR/activitypub/#obj">Objects</a> (the toots), <a href="https://www.w3.org/TR/activitypub/#inbox">inbox</a> (where you receive toots from people you follow), and <a href="https://www.w3.org/TR/activitypub/#outbox">outbox</a> (where you send your toots to the people you follow), to name a few of many other actions and activities, are all defined on the ActivityPub specification.</p><p>Here’s our folder with the <a href="https://github.com/cloudflare/wildebeest/tree/main/backend/src/activitypub">ActivityPub implementation</a>.</p><pre><code class="language-js">import type { APObject } from 'wildebeest/backend/src/activitypub/objects' import type { Actor } from 'wildebeest/backend/src/activitypub/actors' export async function addObjectInInbox(db, actor, obj) { const id = crypto.randomUUID() const out = await db .prepare('INSERT INTO inbox_objects(id, actor_id, object_id) VALUES(?, ?, ?)') .bind(id, actor.id.toString(), obj.id.toString()) .run() } </code></pre><h4 id="webfinger">WebFinger</h4><p>WebFinger is a simple HTTP protocol used to discover information about any entity, like a profile, a server, or a specific feature. It resolves URIs to resource objects.</p><p>Mastodon uses <a href="https://www.rfc-editor.org/rfc/rfc7033">WebFinger</a> lookups to discover information about remote users. For example, say you want to interact with @user@example.com. Your local server would <a href="https://github.com/cloudflare/wildebeest/blob/main/backend/src/webfinger/index.ts">request</a> https://example.com/.well-known/webfinger?resource=acct:user@example.com (using the <a href="https://www.rfc-editor.org/rfc/rfc7565">acct scheme</a>) and get something like this:</p><pre><code class="language-json">{ "subject": "acct:user@example.com", "aliases": [ "https://example.com/ap/users/user" ], "links": [ { "rel": "self", "type": "application/activity+json", "href": "https://example.com/ap/users/user" } ] } </code></pre><p>Now we know how to interact with <code>@user@example.com</code>, using the <code>https://example.com/ap/users/user endpoint</code>.</p><p>Here’s our WebFinger <a href="https://github.com/cloudflare/wildebeest/blob/main/functions/.well-known/webfinger.ts">response</a>:</p><pre><code class="language-js">export async function handleRequest(request, db): Promise&lt;Response&gt; { … const jsonLink = /* … link to actor */ const res: WebFingerResponse = { subject: `acct:...`, aliases: [jsonLink], links: [ { rel: 'self', type: 'application/activity+json', href: jsonLink, }, ], } return new Response(JSON.stringify(res), { headers }) }</code></pre><h4 id="mastodon-api">Mastodon API</h4><p>Finally, things like setting your server information, profile information, generating timelines, notifications, and searches, are all Mastodon-specific APIs. The Mastodon open-source project defines a catalog of REST APIs, and you can find all the documentation for them on <a href="https://docs.joinmastodon.org/api/">their website</a>.</p><p>Our Mastodon API implementation can be found <a href="https://github.com/cloudflare/wildebeest/tree/main/functions/api">here</a> (REST endpoints) and <a href="https://github.com/cloudflare/wildebeest/tree/main/backend/src/mastodon">here</a> (backend primitives). Here’s an example of Mastodon’s server information <a href="https://docs.joinmastodon.org/methods/instance/#v2">/api/v2/instance</a> implemented by <a href="https://github.com/cloudflare/wildebeest/blob/main/functions/api/v2/instance.ts">Wildebeest</a>:</p><pre><code class="language-js">export async function handleRequest(domain, db, env) { const res: InstanceConfigV2 = { domain, title: env.INSTANCE_TITLE, version: getVersion(), source_url: 'https://github.com/cloudflare/wildebeest', description: env.INSTANCE_DESCR, thumbnail: { url: DEFAULT_THUMBNAIL, }, languages: ['en'], registrations: { enabled: false, }, contact: { email: env.ADMIN_EMAIL, }, rules: [], } return new Response(JSON.stringify(res), { headers }) }</code></pre><p>Wildebeest also implements <a href="https://github.com/cloudflare/wildebeest/tree/main/backend/src/webpush">WebPush</a> for client notifications and <a href="https://github.com/cloudflare/wildebeest/tree/main/functions/nodeinfo">NodeInfo</a> for server information.</p><p>Other Mastodon-compatible servers had to implement all these protocols <a href="https://pleroma.social/">too</a>; Wildebeest is one of them. The community is very active in discussing future enhancements; we will keep improving our compatibility and adding support to more features over time, ensuring that Wildebeest plays well with the Fediverse ecosystem of servers and clients emerging.</p><h3 id="get-started-now">Get started now</h3><p>Enough about technology; let's get you into the Fediverse. We tried to detail all the steps to deploy your server. To start using Wildebeest, head to the public GitHub repository and check our <a href="https://github.com/cloudflare/wildebeest/blob/main/README.md">Get Started tutorial</a>.</p><p>Most of Wildebeest's dependencies offer a generous free plan that allows you to try them for personal or hobby projects that aren't business-critical, however you will need to subscribe an <a href="https://www.cloudflare.com/en-gb/products/cloudflare-images/">Images</a> plan (the lowest tier should be enough for most needs) and, depending on your server load, <a href="https://developers.cloudflare.com/workers/platform/limits/#unbound-usage-model">Workers Unbound</a> (again, the minimum cost should be plenty for most use cases).</p><p>Following our dogfooding mantra, Cloudflare is also officially joining the Fediverse today. You can start following our Mastodon accounts and get the same experience of having regular updates from Cloudflare as you get from us on other social platforms, using your favorite Mastodon apps. These accounts are entirely running on top of a Wildebeest server:</p><ul><li><a href="https://cloudflare.social/@cloudflare">@cloudflare@cloudflare.social</a> - Our main account</li><li><a href="https://cloudflare.social/@radar">@radar@cloudflare.social</a> - Cloudflare Radar</li></ul><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/14b.png" class="kg-image" alt="Welcome to Wildebeest: the Fediverse on Cloudflare"></figure><p>Wildebeest is compatible with most client apps; we are confirmed to work with the official Mastodon <a href="https://play.google.com/store/apps/details?id=org.joinmastodon.android">Android</a> and <a href="https://apps.apple.com/us/app/mastodon-for-iphone/id1571998974">iOS</a> apps, <a href="https://pinafore.social/">Pinafore</a>, <a href="https://mastodon.social/@JPEGuin/109315609418460036">Mammoth</a>, and <a href="https://tooot.app/">tooot</a>, and looking into others like <a href="https://tapbots.com/ivory/">Ivory</a>. If your favorite isn’t working, please submit an <a href="https://github.com/cloudflare/wildebeest/issues">issue here</a>, we’ll do our best to help support it.</p><h3 id="final-words">Final words</h3><p>Wildebeest was built entirely on top of our <a href="http://blog.cloudflare.com/welcome-to-the-supercloud-and-developer-week-2022/">Supercloud</a> stack. It was one of the most complete and complex projects we have created that uses various Cloudflare products and features.</p><p>We hope this write-up inspires you to not only try deploying Wildebeest and joining the Fediverse, but also building your next application, however demanding it is, on top of Cloudflare.</p><p>Wildebeest is a minimally viable Mastodon-compatible server right now, but we will keep improving it with more features and supporting it over time; after all, we're using it for our official accounts. It is also open-sourced, meaning you are more than welcome to contribute with pull requests or feedback.</p><p>In the meantime, we opened a <a href="https://discord.com/channels/595317990191398933/1064925651464896552">Wildebeest room</a> on our <a href="https://discord.gg/cloudflaredev">Developers Discord Server</a> and are keeping an eye open on the GitHub repo <a href="https://github.com/cloudflare/wildebeest/issues">issues</a> tab. Feel free to engage with us; the team is eager to know how you use Wildebeest and answer your questions.</p><p><em>PS: The code snippets in this blog were simplified to benefit readability and space (the TypeScript types and error handling code were removed, for example). Please refer to the GitHub repo links for the complete versions.</em></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ How Cloudflare erroneously throttled a customer’s web traffic ]]>
</title>
<description>
<![CDATA[ Today’s post is a little different. It’s about a single customer’s website not working correctly because of incorrect action taken by Cloudflare. ]]>
</description>
<link>https://blog.cloudflare.com/how-cloudflare-erroneously-throttled-a-customers-web-traffic/</link>
<guid isPermaLink="false">63e28aefea5b01000ae29064</guid>
<category>
<![CDATA[ Customers ]]>
</category>
<category>
<![CDATA[ Transparency ]]>
</category>
<dc:creator>
<![CDATA[ Jeremy Hartman ]]>
</dc:creator>
<pubDate>Tue, 07 Feb 2023 18:20:49 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/BLOG-1707-header.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/BLOG-1707-header-1.png" class="kg-image" alt="How Cloudflare erroneously throttled a customer’s web traffic"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/BLOG-1707-header.png" alt="How Cloudflare erroneously throttled a customer’s web traffic"><p>Over the years when Cloudflare has had an <a href="http://blog.cloudflare.com/tag/outage/">outage</a> that affected our customers we have very quickly blogged about what happened, why, and what we are doing to address the causes of the outage. Today’s post is a little different. It’s about a single customer’s website <a href="https://news.ycombinator.com/item?id=34639212">not working correctly</a> because of incorrect action taken by Cloudflare.</p><p>Although the customer was not in any way banned from Cloudflare, or lost access to their account, their website didn’t work. And it didn’t work because Cloudflare applied a bandwidth throttle between us and their origin server. The effect was that the website was unusable.</p><p>Because of this unusual throttle there was some internal confusion for our customer support team about what had happened. They, incorrectly, believed that the customer had been limited because of a breach of section 2.8 of our <a href="https://www.cloudflare.com/terms/">Self-Serve Subscription Agreement</a> which prohibits use of our self-service CDN to serve excessive non-HTML content, such as images and video, without a paid plan that includes those services (this is, for example, designed to prevent someone building an image-hosting service on Cloudflare and consuming a huge amount of bandwidth; for that sort of use case we have paid <a href="https://www.cloudflare.com/products/cloudflare-images/">image</a> and <a href="https://www.cloudflare.com/products/cloudflare-stream/">video</a> plans).</p><p>However, this customer wasn’t breaking section 2.8, and they were both a paying customer and a paying customer of Cloudflare Workers through which the throttled traffic was passing. This throttle should not have happened. In addition, there is and was no need for the customer to upgrade to some other plan level.</p><p>This incident has set off a number of workstreams inside Cloudflare to ensure better communication between teams, prevent such an incident happening, and to ensure that communications between Cloudflare and our customers are much clearer.</p><p>Before we explain our own mistake and how it came to be, we’d like to apologize to the customer. We realize the serious impact this had, and how we fell short of expectations. In this blog post, we want to explain what happened, and more importantly what we’re going to change to make sure it does not happen again.</p><h3 id="background">Background</h3><p>On February 2, an on-call network engineer received an alert for a congesting interface with Equinix IX in our Ashburn data center. While this is not an unusual alert, this one stood out for two reasons. First, it was the second day in a row that it happened, and second, the congestion was due to a sudden and extreme spike of traffic.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image2-1.png" class="kg-image" alt="How Cloudflare erroneously throttled a customer’s web traffic"></figure><p>The engineer in charge identified the customer’s domain, tardis.dev, as being responsible for this sudden spike of traffic between Cloudflare and their origin network, a storage provider. Because this congestion happens on a physical interface connected to external peers, there was an immediate impact to many of our customers and peers. A port congestion like this one typically incurs packet loss, slow throughput and higher than usual latency. While we have automatic mitigation in place for congesting interfaces, in this case the mitigation was unable to resolve the impact completely.</p><p>The traffic from this customer went suddenly from an average of 1,500 requests per second, and a 0.5 MB payload per request, to 3,000 requests per second (2x) and more than 12 MB payload per request (25x).</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image1-4.png" class="kg-image" alt="How Cloudflare erroneously throttled a customer’s web traffic"></figure><p>The congestion happened between Cloudflare and the origin network. Caching did not happen because the requests were all unique URLs going to the origin, and therefore we had no ability to serve from cache.</p><p><strong>A Cloudflare engineer decided to apply a throttling mechanism to prevent the zone from pulling so much traffic from their origin. Let's be very clear on this action: Cloudflare does not have an established process to throttle customers that consume large amounts of bandwidth, and does not intend to have one. This remediation was a mistake, it was not sanctioned, and we deeply regret it.</strong></p><p>We lifted the throttle through internal escalation 12 hours and 53 minutes after having set it up.</p><h3 id="what-s-next">What's next</h3><p>To make sure a similar incident does not happen, we are establishing clear rules to mitigate issues like this one. Any action taken against a customer domain, paying or not, will require multiple levels of approval and clear communication to the customer. Our tooling will be improved to reflect this. We have many ways of traffic shaping in situations where a huge spike of traffic affects a link and could have applied a different mitigation in this instance.</p><p>We are in the process of rewriting our terms of service to better reflect the type of services that our customers deliver on our platform today. We are also committed to explaining to our users in plain language what is permitted under self-service plans. As a developer-first company with transparency as one of its core principles, we know we can do better here. We will follow up with a blog post dedicated to these changes later.</p><p>Once again, we apologize to the customer for this action and for the confusion it created for other Cloudflare customers.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust ]]>
</title>
<description>
<![CDATA[ Administrators can now use Gateway traffic egress policies to determine which egress IPs are used when. ]]>
</description>
<link>https://blog.cloudflare.com/gateway-egress-policies/</link>
<guid isPermaLink="false">63c803de22d7b2000b3cb2ba</guid>
<category>
<![CDATA[ Cloudflare One ]]>
</category>
<category>
<![CDATA[ Zero Trust ]]>
</category>
<category>
<![CDATA[ Cloudflare Gateway ]]>
</category>
<dc:creator>
<![CDATA[ Ankur Aggarwal ]]>
</dc:creator>
<pubDate>Fri, 03 Feb 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/image5.png" medium="image"/>
<content:encoded>
<![CDATA[ <!--kg-card-begin: markdown--><img src="http://blog.cloudflare.com/content/images/2023/02/image5.png" alt="Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust"><p><small>This post is also available in <a href="http://blog.cloudflare.com/zh-cn/gateway-egress-policies-zh-cn/">简体中文</a>, <a href="http://blog.cloudflare.com/zh-tw/gateway-egress-policies-zh-tw/">繁體中文</a>, <a href="http://blog.cloudflare.com/ja-jp/gateway-egress-policies-ja-jp/">日本語</a>, <a href="http://blog.cloudflare.com/ko-kr/gateway-egress-policies-ko-kr/">한국어</a>, <a href="http://blog.cloudflare.com/de-de/gateway-egress-policies-de-de/">Deutsch</a>, <a href="http://blog.cloudflare.com/fr-fr/gateway-egress-policies-fr-fr/">Français</a>, <a href="http://blog.cloudflare.com/es-es/gateway-egress-policies-es-es/">Español</a> and <a href="http://blog.cloudflare.com/pt-br/gateway-egress-policies-pt-br/">Português</a>.</small></p> <!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image5-1.png" class="kg-image" alt="Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust"></figure><p>Before identity-driven Zero Trust rules, some SaaS applications on the public Internet relied on the IP address of a connecting user as a security model. Users would connect from known office locations, with fixed IP address ranges, and the SaaS application would check their address in addition to their login credentials.</p><p>Many systems still offer that second factor method. Customers of Cloudflare One can use a dedicated egress IP for this purpose as part of their journey to a <a href="https://www.cloudflare.com/learning/security/glossary/what-is-zero-trust/">Zero Trust model</a>. Unlike other solutions, customers using this option do not need to deploy any infrastructure of their own. However, not all traffic needs to use those dedicated egress IPs.</p><p>Today, we are announcing policies that give administrators control over when Cloudflare uses their dedicated egress IPs. Specifically, administrators can use a rule builder in the Cloudflare dashboard to determine which egress IP is used and when, based on attributes like identity, application, IP address, and geolocation. This capability is available to any enterprise-contracted customer that adds on dedicated egress IPs to their Zero Trust subscription.</p><h3 id="why-did-we-build-this">Why did we build this?</h3><p>In today’s hybrid work environment, organizations aspire for more consistent security and IT experiences to manage their employees’ traffic egressing from offices, data centers, and roaming users. To deliver a more streamlined experience, many organizations are adopting modern, cloud-delivered proxy services like <a href="https://www.cloudflare.com/learning/access-management/what-is-a-secure-web-gateway/">secure web gateways</a> (SWGs) and deprecating their complex mix of on-premise appliances.</p><p>One traditional convenience of these legacy tools has been the ability to create allowlist policies based on static source IPs. When users were primarily in one place, verifying traffic based on egress location was easy and reliable enough. Many organizations want or are required to maintain this method of traffic validation even as their users have moved beyond being in one place.</p><p>So far, Cloudflare has supported these organizations by providing dedicated egress IPs as an add-on to our proxy <a href="https://www.cloudflare.com/products/zero-trust/">Zero Trust services</a>. Unlike the default egress IPs, these dedicated egress IPs are not shared amongst any other Gateway accounts and are only used to egress proxied traffic for the designated account.</p><p>As <a href="http://blog.cloudflare.com/gateway-dedicated-egress-policies/">discussed in a previous blog post</a>, customers are already using Cloudflare’s dedicated egress IPs to deprecate their VPN use by using them to identify their users proxied traffic or to add these to allow lists on third party providers. These organizations benefit from the simplicity of still using fixed, known IPs, and their traffic avoids the bottlenecks and backhauling of traditional on-premise appliances.</p><h3 id="when-to-use-egress-policies">When to use egress policies</h3><p>The Gateway Egress policy builder empowers administrators with enhanced flexibility and specificity to egress traffic based on the user’s identity, device posture, source/destination IP address, and more.</p><p>Traffic egressing from specific geolocations to provide geo-specific experiences (e.g. language format, regional page differences) for select user groups is a common use case. For example, Cloudflare is currently working with the marketing department of a global media conglomerate. Their designers and web experts based in India often need to verify the layout of advertisements and websites that are running in different countries.</p><p>However, those websites restrict or change access based on the geolocation of the source IP address of the user. This required the team to use an additional VPN service for just this purpose. With egress policies, administrators can create a rule to match the domain IP address or destination country IP geolocation and marketing employees to egress traffic from a dedicated egress IP geo-located to the country where they need to verify the domain. This allows their security team to rest easy as they no longer have to maintain this hole in their perimeter defense, another VPN service just for marketing, and can enforce all of their other filtering capabilities to this traffic.</p><p>Another example use case is allowlisting access to applications or services maintained by a third party. While security administrators can control how their teams access their resources and even apply filtering to their traffic they often can’t change the security controls enforced by third parties. For example, while working with a large credit processor they used a third party service to verify the riskiness of transactions routed through their Zero Trust network. This third party required them to allowlist their source IPs.</p><p>To meet this goal, this customer could have just used dedicated egress IPs and called it a day, but this means that all of their traffic is now being routed through the data center with their dedicated egress IPs. So if a user wanted to browse any other sites they would receive a subpar experience since their traffic may not be taking the most efficient path to the upstream. But now with egress policies this customer can now only apply this dedicated egress IP to this third party provider traffic and let all other user traffic egress via the default Gateway egress IPs.</p><h3 id="building-egress-policies">Building egress policies</h3><p>To demonstrate how easy it is for an administrator to configure a policy let’s walk through the last scenario. My organization uses a third-party service and in addition to a username/password login they require us to use a static source IP or network range to access their domain.</p><p>To set this up, I just have to navigate to Egress Policies under Gateway on the Zero Trust dashboard. Once there I can hit ‘Create egress policy’:</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image3-1.png" class="kg-image" alt="Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust"></figure><p>For my organization most of my users accessing this third-party service are located in Portugal so I’ll use my dedicated egress IPs that are assigned to Montijo, Portugal. The users will access example.com hosted on 203.0.113.10 so I’ll use the destination IP selector to match all traffic to this site; policy configuration below:</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image2.png" class="kg-image" alt="Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust"></figure><p>Once my policy is created, I’ll add in one more as a catch-all for my organization to make sure they don’t use any dedicated egress IPs for destinations not associated with this third-party service. This is key to add in because it makes sure my users receive the most performant network experience while still maintaining their privacy by egress via our shared Enterprise pool of IPs; policy configuration below:</p><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image4.png" class="kg-image" alt="Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust"></figure><p>Taking a look at the egress policy list we can see both policies are enabled and now when my users try to access example.com they will be using either the primary or secondary dedicated IPv4 or the IPv6 range as the egress IP. And for all other traffic, the default Cloudflare egress IPs will be used.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image1-3.png" class="kg-image" alt="Manage and control the use of dedicated egress IPs with Cloudflare Zero Trust"></figure><h3 id="next-steps">Next steps</h3><p>We recognize that as organizations migrate away from on-premise appliances, they want continued simplicity and control as they proxy more traffic through their cloud security stack. With Gateway egress policies administrators will now be able to control traffic flows for their increasingly distributed workforces.</p><p>If you are interested in building policies around Cloudflare’s dedicated egress IPs, you can add them onto a <a href="https://www.cloudflare.com/lp/cio-week-2023-cloudflare-one-contact-us/">Cloudflare Zero Trust Enterprise plan</a> or contact your account manager.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Get notified about the most relevant events with Advanced HTTP Alerts ]]>
</title>
<description>
<![CDATA[ Today we’re adding more flexibility to HTTP alerting, enabling customers to customize the types of activity they’re alerted on and how those alerts are organized. ]]>
</description>
<link>https://blog.cloudflare.com/custom-alert-features-anomaly-detection/</link>
<guid isPermaLink="false">63b7f1c04b4c48000adffe72</guid>
<category>
<![CDATA[ Advanced HTTP Alerts ]]>
</category>
<category>
<![CDATA[ Product News ]]>
</category>
<dc:creator>
<![CDATA[ Justin Raczak ]]>
</dc:creator>
<pubDate>Fri, 03 Feb 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/01/image1-5.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/01/image1-6.png" class="kg-image" alt="Get notified about the most relevant events with Advanced HTTP Alerts"></figure><img src="http://blog.cloudflare.com/content/images/2023/01/image1-5.png" alt="Get notified about the most relevant events with Advanced HTTP Alerts"><p>Today we’re excited to be announcing more flexibility to HTTP alerting, enabling customers to customize the types of activity they’re alerted on and how those alerts are organized.</p><p>Prior to today, HTTP alerts at Cloudflare have been very generic. You could choose which Internet properties you wanted and what sensitivity you wanted to be alerted on, but you couldn’t choose anything else. You couldn’t, for example, exclude  the IP addresses you use to test things. You couldn’t choose to monitor only a specific path. You couldn’t choose which HTTP statuses you wanted to be alerted on. You couldn’t even choose to monitor your entire account instead of specific zones.</p><p>Our customers leverage the Cloudflare network for a myriad of use cases ranging from decreasing bandwidth costs and accelerating asset delivery with <a href="https://www.cloudflare.com/cdn-free/">Cloudflare CDN</a> to protecting their applications against <a href="https://www.cloudflare.com/learning/bots/brute-force-attack/">brute force attacks</a> with <a href="https://www.cloudflare.com/products/bot-management/">Cloudflare Bot Management</a>. Whether the reasons for routing traffic through the Cloudflare network are simple or complex, one powerful capability that comes for free is observability.</p><p>With traffic flowing through the network, we can monitor and alert customers about anomalous events such as spikes in origin error rates, enabling them to investigate further and mitigate any issues as necessary. But to date, our HTTP alerting capabilities have been too simple, offering only a narrow set of options for filtering alongside predefined service level objective (SLO) targets. By exposing more of the metadata already available with each request as filtering options, customers can create more sophisticated monitoring schemes to answer important questions about their traffic.</p><p>Which HTTP errors are crossing my SLO threshold? Is the sudden spike in traffic caused by my own internal testing? These questions and more can be answered with the new advanced HTTP alerts.</p><p>Alerts can be filtered and organized based on the values of the following properties: origin response status codes, edge response status codes, alert sensitivity/SLO, client IPv4/IPv6 addresses, and specific zones.</p><p>The new notifications are available to all Enterprise customers today and can be created and managed by anyone with account-level privileges.</p><h3 id="how-to-get-started">How to get started</h3><p>To get started setting up an advanced HTTP alert, navigate to your account’s <a href="https://dash.cloudflare.com/?to=/:account/notifications/create">notification management</a> and select the <em>Advanced HTTP Alert </em>type.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/01/unnamed.png" class="kg-image" alt="Get notified about the most relevant events with Advanced HTTP Alerts"></figure><p>Next, name your new notification and select how you want notifications to be delivered and to whom.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/01/unnamed--1-.png" class="kg-image" alt="Get notified about the most relevant events with Advanced HTTP Alerts"></figure><p>Lastly, select the domains for which this notification should be sent and configure the desired filters, groupings, and SLO.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/01/unnamed--2-.png" class="kg-image" alt="Get notified about the most relevant events with Advanced HTTP Alerts"></figure><p>Monitoring and alerting are critical practices in effectively managing an application or website, and today we’re excited to make it easier to do with Cloudflare.</p><p>If you’re not already an Enterprise customer and would like to take advantage of the new advanced HTTP alerts, <a href="https://www.cloudflare.com/enterprise-dashboard-contact-us/">get in touch</a>.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Cloudflare's handling of a bug in interpreting IPv4-mapped IPv6 addresses ]]>
</title>
<description>
<![CDATA[ Recently, a vulnerability was reported to our bug bounty about a bug in the way some of our code interprets IPv4 addresses mapped into IPv6 addresses. Read about how Cloudflare addressed this vulnerability and what will prevent similar exploits in the future. ]]>
</description>
<link>https://blog.cloudflare.com/cloudflare-handling-bug-interpreting-ipv4-mapped-ipv6-addresses/</link>
<guid isPermaLink="false">63da6a6f97f204000a5e80fe</guid>
<category>
<![CDATA[ Security ]]>
</category>
<category>
<![CDATA[ Bug Bounty ]]>
</category>
<category>
<![CDATA[ IPv6 ]]>
</category>
<dc:creator>
<![CDATA[ Lucas Ferreira ]]>
</dc:creator>
<pubDate>Thu, 02 Feb 2023 13:32:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/image1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/image1-1.png" class="kg-image" alt="Cloudflare's handling of a bug in interpreting IPv4-mapped IPv6 addresses"></figure><img src="http://blog.cloudflare.com/content/images/2023/02/image1.png" alt="Cloudflare's handling of a bug in interpreting IPv4-mapped IPv6 addresses"><p>In November 2022, our <a href="https://www.cloudflare.com/disclosure/">bug bounty program</a> received a critical and very interesting report. The report stated that certain types of DNS records could be used to bypass some of our network policies and connect to ports on the loopback address (e.g. 127.0.0.1) of our servers. This post will explain how we dealt with the report, how we fixed the bug, and the outcome of our internal investigation to see if the vulnerability had been previously exploited.</p><p><a href="https://datatracker.ietf.org/doc/html/rfc4291#section-2-5-5">RFC 4291</a> defines ways to embed an IPv4 address into IPv6 addresses. One of the methods defined in the RFC is to use IPv4-mapped IPv6 addresses, that have the following format:</p><!--kg-card-begin: markdown--><pre><code> | 80 bits | 16 | 32 bits | +--------------------------------------+--------------------------+ |0000..............................0000|FFFF| IPv4 address | +--------------------------------------+----+---------------------+ </code></pre> <!--kg-card-end: markdown--><p>In IPv6 notation, the corresponding mapping for <code>127.0.0.1</code> is <code>::ffff:127.0.0.1</code> (<a href="https://datatracker.ietf.org/doc/html/rfc4038">RFC 4038</a>)</p><p>The researcher was able to use DNS entries based on mapped addresses to bypass some of our controls and access ports on the loopback address or non-routable IPs.</p><p>This vulnerability was reported on November 27 to our bug bounty program. Our Security Incident Response Team (SIRT) was contacted, and incident response activities began shortly after the report was filed. A hotpatch was deployed three hours later to prevent exploitation of the bug.</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-color:#ccc;border-spacing:0;} .tg td{background-color:#fff;border-color:#ccc;border-style:solid;border-width:1px;color:#333; font-family:Arial, sans-serif;font-size:14px;overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{background-color:#f0f0f0;border-color:#ccc;border-style:solid;border-width:1px;color:#333; font-family:Arial, sans-serif;font-size:14px;font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-1wig{font-weight:bold;text-align:left;vertical-align:top} .tg .tg-citn{background-color:#FFF;color:#333;text-align:left;vertical-align:top} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg"> <thead> <tr> <th class="tg-1wig"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Date</span></th> <th class="tg-1wig"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Time (UTC)</span></th> <th class="tg-1wig"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Activity</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">27 November 2022</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">20:42</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Initial report to Cloudflare's bug bounty program</span></td> </tr> <tr> <td class="tg-0lax"></td> <td class="tg-citn"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#333;background-color:#FFF">21:04</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">SIRT oncall is paged</span></td> </tr> <tr> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">21:15</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">SIRT manager on call starts working on the report</span></td> </tr> <tr> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">21:22</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Incident declared and team is assembled and debugging starts</span></td> </tr> <tr> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">23:20</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">A hotfix is ready and deployment starts</span></td> </tr> <tr> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">23:47</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Team confirms that the hotfix is deployed and working</span></td> </tr> <tr> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">23:58</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Team investigates if other products are affected. Load Balancers and Spectrum are potential targets. Both products are found to be unaffected by the vulnerability.</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">28 November 2022</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">21:14</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">A permanent fix is ready</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">29 November 2022</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">21:34</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Permanent fix is merged</span></td> </tr> </tbody> </table><!--kg-card-end: html--><h3 id="blocking-exploitation">Blocking exploitation</h3><p>Immediately after the vulnerability was reported to our Bug Bounty program, the team began working to understand the issue and find ways to quickly block potential exploitation. It was determined that the fastest way to prevent exploitation would be to block the creation of the DNS records required to execute the attack.</p><p>The team then began to implement a patch to prevent the creation of DNS records that include IPv6 addresses that map loopback or RFC 1918 (internal) IPv4 addresses. The fix was fully deployed and confirmed three hours after the report was filed. We later realized that this change was insufficient because records hosted on external DNS servers could also be used in this attack.</p><h3 id="the-exploit">The exploit</h3><p>The exploit provided consisted of the following: a DNS entry, and a Cloudflare Worker. The DNS entry was an <code>AAAA</code> record pointing to <code>::ffff:127.0.0.1: </code></p><p><code>exploit.example.com</code> <code>AAAA</code> <code>::ffff:127.0.0.1</code></p><p>The worker included the following code:</p><!--kg-card-begin: markdown--><pre><code class="language-json">export default { async fetch(request) { const requestJson = await request.json() return fetch(requestJson.url, requestJson) } } </code></pre> <!--kg-card-end: markdown--><p>The Worker was given a custom URL such as <code>proxy.example.com</code>.</p><p>With that setup, it was possible to make the worker attempt connections on the loopback interface of the server where it was running. The call would look like this:</p><!--kg-card-begin: markdown--><pre><code>curl https://proxy.example.com/json -d '{&quot;url&quot;:&quot;http://exploit.example.com:80/url_path&quot;}' </code></pre> <!--kg-card-end: markdown--><p>The attack could then be scripted to attempt to connect to multiple ports on the server.</p><p>It was also found that a similar setup could be used with other IPv4 addresses to attempt connections into internal services. In this case, the DNS entry would look like:</p><!--kg-card-begin: markdown--><pre><code>exploit.example.com AAAA ::ffff:10.0.0.1 </code></pre> <!--kg-card-end: markdown--><p>This exploit would allow an attacker to connect to services running on the loopback interface of the server. If the attacker was able to bypass the security and authentication mechanisms of a service, it could impact the confidentiality and integrity of data. For services running on other servers, the attacker could also use the worker to attempt connections and map services available over the network. As in most networks, Cloudflare's network policies and ACLs must allow a few ports to be accessible. These ports would be accessible by an attacker using this exploit.</p><h3 id="investigation">Investigation</h3><p>We started an investigation to understand the root cause of the problem and created a proof-of-concept that allowed the team to debug the issue. At the same time, we started a parallel investigation to determine if the issue had been previously exploited.</p><p>It all happened when two bugs collided.</p><p>The first bug happened in our internal DNS system which is responsible for mapping hostnames to IP addresses of our customers’ origin servers (the DNS system). When the DNS system tried to answer a query for the DNS record from exploit.example.com, it serialized the IP as a string. The <a href="https://pkg.go.dev/net#IP.String">Golang net library</a> used for DNS automatically converted the IP <code>::ffff:10.0.0.1</code> to string “10.0.0.1”. However, the DNS system still treated it as an IPv6 address. So a query response <code>{ipv6: “10.0.0.1”}</code> was returned.</p><p>The second bug was in our internal HTTP system (the proxy) which is responsible for forwarding HTTP traffic to customer’s origin servers. The bug happened in how the proxy validates this DNS response, <code>{ipv6: “10.0.0.1”}</code>. The proxy has two deny lists of IPs that are not allowed to be used, one for IPv4 and one for IPv6. These lists contain localhost IPs and private IPs. The bug was that the proxy system compared the address 10.0.0.1 against the IPv6 deny list because the address was in the “ipv6” section. Naturally the address didn’t match any entry in the deny list. So the address was allowed to be used as an origin IP address.</p><p>The second investigation team searched through the logs and found no evidence of previous exploitation of this vulnerability. The team also checked Cloudflare DNS for entries using IPv4-mapped IPv6 addresses and determined that all the existing entries had been used for testing purposes. As of now, there are no signs that this vulnerability could have been previously used against Cloudflare systems.</p><h3 id="remediating-the-vulnerability">Remediating the vulnerability</h3><p>To address this issue we implemented a fix in the proxy service to correctly use the deny list of the parsed address, not the deny list of the IP family the DNS API response claimed to be, to validate the IP address. We confirmed both in our test and production environments that the fix did prevent the issue from happening again.</p><p>Beyond maintaining a <a href="https://www.cloudflare.com/disclosure/">bug bounty program</a>, we regularly perform internal security reviews and hire third-party firms to audit the software we develop. But it is through our bug bounty program that we receive some of the most interesting and creative reports. Each report has helped us improve the security of our services. We invite those that find a security issue in any of Cloudflare’s services to report it to us through <a href="https://hackerone.com/cloudflare">HackerOne</a>.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Uptick in healthcare organizations experiencing targeted DDoS attacks ]]>
</title>
<description>
<![CDATA[ Over the past few days, Cloudflare, as well as other sources, have observed healthcare organizations targeted by a pro-Russian hacktivist group claiming to be Killnet. ]]>
</description>
<link>https://blog.cloudflare.com/uptick-in-healthcare-organizations-experiencing-targeted-ddos-attacks/</link>
<guid isPermaLink="false">63db4ed797f204000a5e815a</guid>
<category>
<![CDATA[ DDoS ]]>
</category>
<category>
<![CDATA[ Healthcare ]]>
</category>
<category>
<![CDATA[ Ukraine ]]>
</category>
<dc:creator>
<![CDATA[ Cat Allen ]]>
</dc:creator>
<pubDate>Thu, 02 Feb 2023 06:02:16 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/02/DDoS-attacks-against-Healthcare-1.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/02/DDoS-attacks-against-Healthcare.png" class="kg-image" alt="Uptick in healthcare organizations experiencing targeted DDoS attacks"></figure><h3 id="healthcare-in-the-crosshairs">Healthcare in the crosshairs</h3><img src="http://blog.cloudflare.com/content/images/2023/02/DDoS-attacks-against-Healthcare-1.png" alt="Uptick in healthcare organizations experiencing targeted DDoS attacks"><p>Over the past few days, Cloudflare, as well as <a href="https://www.infosecurity-magazine.com/news/killnet-suspected-ddos-us-dutch/">other sources</a>, have observed healthcare organizations targeted by a pro-Russian hacktivist group claiming to be Killnet. There has been an increase in the amount of healthcare organizations coming to us to help get out from under these types of attacks. Multiple healthcare organizations behind Cloudflare have also been targeted by HTTP DDoS attacks and Cloudflare has helped them successfully mitigate these attacks. The United States Department of Health and Human Services issued an Analyst Note detailing the threat of Killnet-related cyberattacks to the healthcare industry. </p><p>A rise in political tensions and escalation of the conflict in Ukraine are all factors that play into the current cybersecurity threat landscape. Unlike traditional warfare, the Internet has enabled and empowered groups of individuals to carry out targeted attacks regardless of their location or involvement. Distributed-denial-of-Service (DDoS) attacks have the unfortunate advantage of not requiring an intrusion or a foothold to be launched and have, unfortunately, become more accessible than ever before. </p><p>The attacks observed by the Cloudflare global network do not show a clear indication that they are originating from a single botnet and the attack methods and sources seem to vary. This could indicate the involvement of multiple threat actors acting on behalf of Killnet, or it could indicate a more sophisticated, coordinated attack.</p><p>Cloudflare application services customers are protected against the attacks. Cloudflare systems have been automatically detecting and mitigating the attacks on behalf of our customers. Our team continues to monitor the situation closely and is prepared to deploy countermeasures, if needed.</p><p>As an extra precaution, customers in the Healthcare industry are advised to follow the mitigation recommendations in the “How to Prepare” section below.</p><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image.png" class="kg-image" alt="Uptick in healthcare organizations experiencing targeted DDoS attacks"></figure><figure class="kg-card kg-image-card kg-width-wide"><img src="http://blog.cloudflare.com/content/images/2023/02/image3.png" class="kg-image" alt="Uptick in healthcare organizations experiencing targeted DDoS attacks"></figure><h3 id="who-is-killnet">Who is Killnet?</h3><p>Killnet is a group of pro-Russian individuals that gather and communicate on a Telegram channel. The channel provides a space for pro-Russian sympathizers to volunteer their expertise by participating in cyberattacks against Western interests. Previously, in the fourth quarter of 2022, Killnet called to attack US airport websites.</p><h3 id="why-ddos-attacks">Why DDoS attacks?</h3><p>DDoS attacks, unlike ransomware, do not require an intrusion or foothold in the target network to be launched. Much like how physical addresses are publicly available via directories or for services like mail delivery, IP addresses and domain names are also publicly available. Unfortunately, this means that every domain name (layer 7) and every network that connects to the Internet (layers 3 &amp; 4) must proactively prepare to defend against DDoS attacks. DDoS attacks are not new threats, but they have become larger, more sophisticated, and more frequent in recent years.</p><h3 id="how-to-prepare">How to prepare</h3><p>While Cloudflare’s systems have been automatically detecting and mitigating these DDoS attacks, we recommend additional precautionary measures to improve your security posture:</p><ol><li>Ensure all other <a href="https://developers.cloudflare.com/ddos-protection/managed-rulesets/">DDoS Managed Rules</a> are set to default settings (High sensitivity level and mitigation actions) for optimal DDoS activation</li><li>Cloudflare Enterprise customers with Advanced DDoS should consider enabling <a href="https://developers.cloudflare.com/ddos-protection/managed-rulesets/adaptive-protection/">Adaptive DDoS Protection</a>, which mitigates traffic that deviates based on your traffic profiles</li><li>Deploy <a href="https://developers.cloudflare.com/firewall/cf-firewall-rules/">firewall rules</a> and <a href="https://developers.cloudflare.com/waf/rate-limiting-rules/">rate-limiting rules</a> to enforce a combined positive and negative security model. Reduce the traffic allowed to your website based on your known usage.</li><li>Ensure your origin is not exposed to the public Internet (i.e. only enable access to Cloudflare IP addresses)</li><li>Customers with access to Managed IP Lists should consider leveraging those lists in firewall rules</li><li>Enable <a href="https://developers.cloudflare.com/cache/">caching</a> as much as possible to reduce the strain on your origin servers, and when using Workers, avoid overwhelming your origin server with more subrequests than necessary</li><li>Enable <a href="https://developers.cloudflare.com/ddos-protection/reference/alerts/">DDoS alerting</a> to improve your response time</li></ol><p>Though attacks are launched by humans, they are carried out by bots. Defenders who do not leverage automated defenses are at a disadvantage. Cloudflare has helped, and will continue to help, our customers in the healthcare industry prepare for and respond to these attacks.</p><p><strong>Under attack? We can help. Visit </strong><a href="https://www.cloudflare.com/under-attack-hotline/"><strong>this webpage</strong></a><strong> or call us at +1 (888) 99 FLARE</strong></p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ CVE-2022-47929: traffic control noqueue no problem? ]]>
</title>
<description>
<![CDATA[ In the Linux kernel before 6.1.6, a NULL pointer dereference bug in the traffic control subsystem allows an unprivileged user to trigger a denial of service (system crash) via a crafted traffic control configuration that is set up with "tc qdisc" and "tc class" commands. ]]>
</description>
<link>https://blog.cloudflare.com/cve-2022-47929-traffic-control-noqueue-no-problem/</link>
<guid isPermaLink="false">63d7d10422d7b2000b3cca7b</guid>
<category>
<![CDATA[ Linux ]]>
</category>
<category>
<![CDATA[ Security ]]>
</category>
<category>
<![CDATA[ Vulnerabilities ]]>
</category>
<category>
<![CDATA[ CVE ]]>
</category>
<dc:creator>
<![CDATA[ Frederick Lawler ]]>
</dc:creator>
<pubDate>Tue, 31 Jan 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/01/image1-55.png" medium="image"/>
<content:encoded>
<![CDATA[ <figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/01/image1-56.png" class="kg-image" alt="CVE-2022-47929: traffic control noqueue no problem?"></figure><img src="http://blog.cloudflare.com/content/images/2023/01/image1-55.png" alt="CVE-2022-47929: traffic control noqueue no problem?"><p>USER namespaces power the functionality of our favorite tools such as docker and podman. <a href="http://blog.cloudflare.com/live-patch-security-vulnerabilities-with-ebpf-lsm/">We wrote about Linux namespaces back in June</a> and explained them like this:</p><blockquote>Most of the namespaces are uncontroversial, like the UTS namespace which allows the host system to hide its hostname and time. Others are complex but straightforward - NET and NS (mount) namespaces are known to be hard to wrap your head around. Finally, there is this very special, very curious USER namespace. USER namespace is special since it allows the - typically unprivileged owner to operate as "root" inside it. It's a foundation to having tools like Docker to not operate as true root, and things like rootless containers.</blockquote><p>Due to its nature, allowing unprivileged users access to USER namespace always carried a great security risk. With its help the unprivileged user can in fact run code that typically requires root. This code is often under-tested and buggy. Today we will look into one such case where USER namespaces are leveraged to exploit a kernel bug that can result in an unprivileged denial of service attack.</p><h3 id="enter-linux-traffic-control-queue-disciplines">Enter Linux Traffic Control queue disciplines</h3><p>In 2019, we were exploring leveraging <a href="https://man7.org/linux/man-pages/man8/tc.8.html#DESCRIPTION">Linux Traffic Control's</a> <a href="https://tldp.org/HOWTO/Traffic-Control-HOWTO/components.html#c-qdisc">queue discipline</a> (qdisc) to schedule packets for one of our services with the <a href="https://man7.org/linux/man-pages/man8/tc-htb.8.html">Hierarchy Token Bucket</a> (HTB) <a href="https://tldp.org/HOWTO/Traffic-Control-HOWTO/classful-qdiscs.html">classful qdisc</a> strategy. Linux Traffic Control is a user-configured system to schedule and filter network packets. Queue disciplines are the strategies in which packets are scheduled. In particular, we wanted to filter and schedule certain packets from an interface, and drop others into the <a href="https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt">noqueue</a> qdisc.</p><p>noqueue is a special case qdisc, such that packets are supposed to be dropped when scheduled into it. In practice, this is not the case. Linux handles noqueue such that packets are passed through and not dropped (for the most part). The <a href="https://linux-tc-notes.sourceforge.net/tc/doc/sch_noqueue.txt">documentation</a> states as much. It also states that “It is not possible to assign the noqueue queuing discipline to physical devices or classes.” So what happens when we assign noqueue to a class?</p><p>Let's write some shell commands to show the problem in action:</p><!--kg-card-begin: markdown--><pre><code class="language-shell">1. $ sudo -i 2. # dev=enp0s5 3. # tc qdisc replace dev $dev root handle 1: htb default 1 4. # tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit 5. # tc qdisc add dev $dev parent 1:1 handle 10: noqueue </code></pre> <!--kg-card-end: markdown--><ol><li>First we need to log in as root because that gives us <a href="https://man7.org/linux/man-pages/man7/capabilities.7.html#DESCRIPTION">CAP_NET_ADMIN</a> to be able to configure traffic control.</li><li>We then assign a network interface to a variable. These can be found with <code>ip a</code>. Virtual interfaces can be located by calling <code>ls /sys/devices/virtual/net</code>. These will match with the output from <code>ip a</code>.</li><li>Our interface is currently assigned to the <a href="https://man7.org/linux/man-pages/man8/tc-pfifo_fast.8.html">pfifo_fast</a> qdisc, so we replace it with the HTB classful qdisc and assign it the handle of <code>1:</code>. We can think of this as the root node in a tree. The “default 1” configures this such that unclassified traffic will be routed directly through this qdisc which falls back to pfifo_fast queuing. (more on this later)</li><li>Next we add a class to our root qdisc <code>1:</code>, assign it to the first leaf node 1 of root 1: <code>1:1</code>, and give it some reasonable configuration defaults.</li><li>Lastly, we add the noqueue qdisc to our first leaf node in the hierarchy: <code>1:1</code>. This effectively means traffic routed here will be scheduled to noqueue</li></ol><p>Assuming our setup executed without a hitch, we will receive something similar to this kernel panic:</p><!--kg-card-begin: markdown--><pre><code class="language-shell">BUG: kernel NULL pointer dereference, address: 0000000000000000 #PF: supervisor instruction fetch in kernel mode ... Call Trace: &lt;TASK&gt; htb_enqueue+0x1c8/0x370 dev_qdisc_enqueue+0x15/0x90 __dev_queue_xmit+0x798/0xd00 ... &lt;/TASK&gt; </code></pre> <!--kg-card-end: markdown--><p>We know that the root user is responsible for setting qdisc on interfaces, so if root can crash the kernel, so what? We just do not apply noqueue qdisc to a class id of a HTB qdisc:</p><!--kg-card-begin: markdown--><pre><code># dev=enp0s5 # tc qdisc replace dev $dev root handle 1: htb default 1 # tc class add dev $dev parent 1: classid 1:2 htb rate 10mbit // A // B is missing, so anything not filtered into 1:2 will be pfifio_fast </code></pre> <!--kg-card-end: markdown--><p>Here, we leveraged the default case of HTB where we assign a class id 1:2 to be rate-limited (A), and implicitly did not set a qdisc to another class such as id 1:1 (B). Packets queued to (A) will be filtered to <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_htb.c#L620">HTB_DIRECT</a> and packets queued to (B) will be filtered into pfifo_fast.</p><p>Because we were not familiar with this part of the codebase, we <a href="https://lore.kernel.org/all/CALrw=nEdA0asN4n7B3P2TyHKJ+UBPvoAiMrwkT42=fqp2-CPiw@mail.gmail.com/">notified</a> the mailing lists and created a ticket. The bug did not seem all that important to us at that time.</p><p>Fast-forward to 2022, we are <a href="https://lwn.net/Articles/903580/">pushing</a> USER namespace creation hardening. We extended the Linux LSM framework with a new LSM hook: <a href="https://lore.kernel.org/all/20220815162028.926858-1-fred@cloudflare.com/">userns_create</a> to leverage <a href="http://blog.cloudflare.com/live-patch-security-vulnerabilities-with-ebpf-lsm/">eBPF LSM</a> for our protections, and encourage others to do so as well. Recently while combing our ticket backlog, we rethought this bug. We asked ourselves, “can we leverage USER namespaces to trigger the bug?” and the short answer is yes!</p><h3 id="demonstrating-the-bug">Demonstrating the bug</h3><p>The exploit can be performed with any classful qdisc that assumes a <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/include/net/sch_generic.h#L73">struct Qdisc.enqueue</a> function to not be NULL (more on this later), but in this case, we are demonstrating just with HTB.</p><!--kg-card-begin: markdown--><pre><code class="language-shell">$ unshare -rU –net $ dev=lo $ tc qdisc replace dev $dev root handle 1: htb default 1 $ tc class add dev $dev parent 1: classid 1:1 htb rate 10mbit $ tc qdisc add dev $dev parent 1:1 handle 10: noqueue $ ping -I $dev -w 1 -c 1 1.1.1.1 </code></pre> <!--kg-card-end: markdown--><p>We use the “lo” interface to demonstrate that this bug is triggerable with a virtual interface. This is important for containers because they are fed virtual interfaces most of the time, and not the physical interface. Because of that, we can use a container to crash the host as an unprivileged user, and thus perform a denial of service attack.</p><h3 id="why-does-that-work">Why does that work?</h3><p>To understand the problem a bit better, we need to look back to the original <a href="https://lore.kernel.org/all/1440703299-21243-1-git-send-email-phil@nwl.cc/#t">patch series</a>, but specifically this <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=d66d6c3152e8d5a6db42a56bf7ae1c6cae87ba48">commit</a> that introduced the bug. Before this series, achieving noqueue on interfaces relied on a hack that would set a device qdisc to noqueue if the device had a <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_api.c#L1263">tx_queue_len = 0</a>. The commit d66d6c3152e8 (“net: sched: register noqueue qdisc”) circumvents this by explicitly allowing noqueue to be added with the <code>tc</code> command without needing to get around that limitation.</p><p>The way the kernel checks for whether we are in a noqueue case or not, is to simply check if a qdisc has a <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/core/dev.c#L4214">NULL enqueue()</a> function. Recall from earlier that noqueue does not necessarily drop packets in practice? After that check in the fail case, the following logic handles the noqueue functionality. In order to fail the check, the author had to <em>cheat</em> a reassignment from <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_generic.c#L628">noop_enqueue()</a> to <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_api.c#L142">NULL</a> by making <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_generic.c#L683">enqueue = NULL</a> in the init which is called <em>way after</em> <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_api.c#L131">register_qdisc()</a> during runtime.</p><p>Here is where classful qdiscs come into play. The check for an enqueue function is no longer NULL. In this call path, it is now set to HTB (in our example) and is thus allowed to enqueue the struct skb to a <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/core/dev.c#L3778">queue</a> by making a call to the function <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_htb.c#L612">htb_enqueue()</a>. Once in there, HTB performs a <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_htb.c#L216">lookup</a> to pull in a qdisc assigned to a leaf node, and eventually attempts to <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_htb.c#L635">queue</a> the struct skb to the chosen qdisc which ultimately reaches this function:</p><p><em>include/net/sch_generic.h</em></p><!--kg-card-begin: markdown--><pre><code class="language-c">static inline int qdisc_enqueue(struct sk_buff *skb, struct Qdisc *sch, struct sk_buff **to_free) { qdisc_calculate_pkt_len(skb, sch); return sch-&gt;enqueue(skb, sch, to_free); // sch-&gt;enqueue == NULL } </code></pre> <!--kg-card-end: markdown--><p>We can see that the enqueueing process is fairly agnostic from physical/virtual interfaces. The permissions and validation checks are done when adding a queue to an interface, which is why the classful qdics assume the queue to not be NULL. This knowledge leads us to a few solutions to consider.</p><h3 id="solutions">Solutions</h3><p>We had a few solutions ranging from what we thought was best to worst:</p><ol><li>Follow tc-noqueue documentation and do not allow noqueue to be assigned to a classful qdisc</li><li>Instead of checking for <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/core/dev.c#L4214">NULL</a>, check for <a href="https://elixir.bootlin.com/linux/v6.2-rc1/source/net/sched/sch_generic.c#L687">struct noqueue_qdisc_ops</a>, and reset noqueue to back to noop_enqueue</li><li>For each classful qdisc, check for NULL and fallback</li></ol><p>While we ultimately went for the first option: <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=96398560f26aa07e8f2969d73c8197e6a6d10407">"disallow noqueue for qdisc classes"</a>, the third option creates a lot of churn in the code, and does not solve the problem completely. Future qdiscs implementations could forget that important check as well as the maintainers. However, the reason for passing on the second option is a bit more interesting.</p><p>The reason we did not follow that approach is because we need to first answer these questions:</p><p>Why not allow noqueue for classful qdiscs?</p><p>This contradicts the documentation. The documentation does have some precedent for not being totally followed in practice, but we will need to update that to reflect the current state. This is fine to do, but does not address the behavior change problem other than remove the NULL dereference bug.</p><p>What behavior changes if we do allow noqueue for qdiscs?</p><p>This is harder to answer because we need to determine what that behavior should be. Currently, when noqueue is applied as the root qdisc for an interface, the path is to essentially allow packets to be processed. Claiming a fallback for classes is a different matter. They may each have their own fallback rules, and how do we know what is the right fallback? Sometimes in HTB the fallback is pass-through with HTB_DIRECT, sometimes it is pfifo_fast. What about the other classes? Perhaps instead we should fall back to the default noqueue behavior as it is for root qdiscs?</p><p>We felt that going down this route would only add confusion and additional complexity to queuing. We could also make an argument that such a change could be considered a feature addition and not necessarily a bug fix. Suffice it to say, adhering to the current documentation seems to be the more appealing approach to prevent the vulnerability now, while something else can be worked out later.</p><h3 id="takeaways">Takeaways</h3><p>First and foremost, apply this <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=96398560f26aa07e8f2969d73c8197e6a6d10407">patch</a> as soon as possible. And consider hardening USER namespaces on your systems by setting <code>sysctl -w </code><a href="https://sources.debian.org/patches/linux/3.16.56-1+deb8u1/debian/add-sysctl-to-disallow-unprivileged-CLONE_NEWUSER-by-default.patch/"><code>kernel.unprivileged_userns_clone</code></a><code>=0</code>, which only lets root create USER namespaces in Debian kernels, <code>sysctl -w </code><a href="https://docs.kernel.org/admin-guide/sysctl/user.html?highlight=max_user_namespaces"><code>user.max_user_namespaces</code></a><code>=[number]</code> for a process hierarchy, or consider backporting these two patches: <code><a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=7cd4c5c2101cb092db00f61f69d24380cf7a0ee8">security_create_user_ns()</a></code> and the <a href="https://git.kernel.org/pub/scm/linux/kernel/git/torvalds/linux.git/commit/?id=ed5d44d42c95e8a13bb54e614d2269c8740667f9">SELinux implementation</a>  (now in Linux 6.1.x) to allow you to protect your systems with either eBPF or SELinux. If you are sure you're not using USER namespaces and in extreme cases, you might consider turning the feature off with <code>CONFIG_USERNS=n</code>. This is just one example of many where namespaces are leveraged to perform an attack, and more are surely to crop up in varying levels of severity in the future.</p><p>Special thanks to Ignat Korchagin and Jakub Sitnicki for code reviews and helping demonstrate the bug in practice.</p> ]]>
</content:encoded>
</item>
<item>
<title>
<![CDATA[ Inside Geo Key Manager v2: re-imagining access control for distributed systems ]]>
</title>
<description>
<![CDATA[ Using the story of Geo Key Manager v2 as an example, let’s re-imagine access control for distributed systems using a variant of public-key cryptography, called attribute-based encryption. ]]>
</description>
<link>https://blog.cloudflare.com/inside-geo-key-manager-v2/</link>
<guid isPermaLink="false">63d2467e22d7b2000b3cc1fa</guid>
<category>
<![CDATA[ Cryptography ]]>
</category>
<category>
<![CDATA[ Attribute-Based Encryption ]]>
</category>
<category>
<![CDATA[ Geo Key Manager ]]>
</category>
<category>
<![CDATA[ Research ]]>
</category>
<dc:creator>
<![CDATA[ Tanya Verma ]]>
</dc:creator>
<pubDate>Fri, 27 Jan 2023 14:00:00 GMT</pubDate>
<media:content url="http://blog.cloudflare.com/content/images/2023/01/image1-48.png" medium="image"/>
<content:encoded>
<![CDATA[ <!--kg-card-begin: markdown--><img src="http://blog.cloudflare.com/content/images/2023/01/image1-48.png" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><p><small>This post is also available in <a href="http://blog.cloudflare.com/fr-fr/inside-geo-key-manager-v2-fr-fr/">Français</a>.</small></p> <!--kg-card-end: markdown--><figure class="kg-card kg-image-card"><img src="http://blog.cloudflare.com/content/images/2023/01/image1-49.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"></figure><p>In December 2022 we announced the closed beta of the new version of <a href="http://blog.cloudflare.com/configurable-and-scalable-geo-key-manager-closed-beta/">Geo Key Manager</a>. Geo Key Manager v2 (GeoV2) is the next step in our journey to provide customers with a secure and flexible way to control the distribution of their private keys by geographic location. Our original system, <a href="http://blog.cloudflare.com/introducing-cloudflare-geo-key-manager/">Geo Key Manager v1</a>, was launched as a research project in 2017, but as customer needs evolved and our scale increased, we realized that we needed to make significant improvements to provide a better user experience.</p><p>One of the principal challenges we faced with Geo Key Manager v1 (GeoV1) was the inflexibility of our access control policies. Customers required richer data localization, often spurred by regulatory concerns. Internally, events such as the conflict in Ukraine reinforced the need to be able to quickly restrict access to sensitive key material. Geo Key Manager v1’s underlying cryptography was a combination of identity-based broadcast encryption and identity-based revocation that simulated a subset of the functionality offered by Attribute-Based Encryption (ABE). Replacing this with an established ABE scheme addressed the inflexibility of our access control policies and provided a more secure foundation for our system.</p><p>Unlike our previous scheme, which limited future flexibility by freezing the set of participating data centers and policies at the outset, using ABE made the system easily adaptable for future needs. It allowed us to take advantage of performance gains from additional data centers added after instantiation and drastically simplified the process for handling changes to attributes and policies. Furthermore, GeoV1 struggled with some perplexing performance issues that contributed to high tail latency and a painfully manual key rotation process. GeoV2 is our answer to these challenges and limitations of GeoV1.</p><p>While this blog focuses on our solution for geographical key management, the lessons here can also be applied to other access control needs. Access control solutions are traditionally implemented using a highly-available central authority to police access to resources. As we will see, ABE allows us to avoid this single point of failure. As there are no large scale ABE-based access control systems we are aware of, we hope our discussion can help engineers consider using ABE as an alternative to access control with minimal reliance on a centralized authority. To facilitate this, we’ve included our implementation of ABE in <a href="https://pkg.go.dev/github.com/cloudflare/circl@v1.3.0/abe/cpabe/tkn20">CIRCL</a>, our open source cryptographic library.</p><h2 id="unsatisfactory-attempts-at-a-solution">Unsatisfactory attempts at a solution</h2><p>Before coming back to GeoV2, let’s take a little detour and examine the problem we’re trying to solve.</p><p>Consider this example: a large European bank wants to store their TLS private keys only within the EU. This bank is a customer of Cloudflare, which means we perform TLS handshakes on their behalf. The reason we need to terminate TLS for them is so that we can provide the best protection against DDoS attacks, improve performance by caching, support web application firewalls, etc.</p><!--kg-card-begin: markdown--><p>In order to terminate TLS, we need to have access to their TLS private keys<sup>1</sup>. The control plane, which handles API traffic, encrypts the customer’s uploaded private key with a master public key shared amongst all machines globally. It then puts the key into a globally distributed KV store, <a href="http://blog.cloudflare.com/introducing-quicksilver-configuration-distribution-at-internet-scale/">Quicksilver</a>. This means every machine in every data center around the world has a local copy of this customer’s TLS private key. Consequently, every machine in each data center has a copy of every customer’s private key.</p> <!--kg-card-end: markdown--><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Customer-uploading-their-TLS-certificate-and-private-key-to-be-stored-in-all-datacenters.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Customer uploading their TLS certificate and private key to be stored in all data centers</figcaption></figure><p>This bank however, wants its key to be stored only in EU data centers. In order to allow this to happen, we have three options.</p><p>The first option is to ensure that only EU data centers can receive this key and terminate the handshake. All other machines proxy TLS requests to an EU server for processing. This would require giving each machine only a subset of the entire keyset stored in Quicksilver, which challenges core design decisions Cloudflare has made over the years that assume the entire dataset is replicated on every machine.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Restricting-customer-keys-to-EU-datacenters.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Restricting customer keys to EU data centers</figcaption></figure><p>Another option is to store the keys in the core data center instead of Quicksilver. This would allow us to enforce the proper access control policy every time, ensuring that only certain machines can access certain keys. However, this would defeat the purpose of having a global network in the first place: to reduce latency and avoid a single point of failure at the core.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Storing-keys-in-core-datacenter-where-complicated-business-logic-runs-to-enforce-policies.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Storing keys in core data center where complicated business logic runs to enforce policies</figcaption></figure><p>A third option is to use public key cryptography. Instead of having a master key pair, every data center is issued its own key pair. The core encrypts the customer's private key with the keys of every data center allowed to use it. Only machines in the EU will be able to access the key in this example. Let’s assume there are 500 data centers, with 50 machines each. Of these 500 data centers, let’s say 200 are in the EU. Where 100 keys of 1kB consumed a total of 100 x 500 x 50 x 1 kB (globally), now they will consume 200 times that, and in the worst case, up to 500 times. This increases the space it takes to store the keys on each machine by a whole new factor - before, the storage space was purely a function of how many customer keys are registered; now, the storage space is still a function of the number of customer keys, but also multiplied by the number of data centers.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Assigning-unique-keys-to-each-data-center.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Assigning unique keys to each data center and wrapping customer key with EU data center keys</figcaption></figure><p>Unfortunately, all three of these options are undesirable in their own ways. They would either require changing fundamental assumptions we made about the architecture of Cloudflare, abandoning the advantages of using a highly distributed network, or quadratically increasing the storage this feature uses.</p><p>A deeper look at the third option reveals – why not create two key pairs instead of a unique one for each data center? One pair would be common among all EU data centers, and one for all non-EU data centers. This way, the core only needs to encrypt the customer’s key twice instead of for each EU data center. This is a good solution for the EU bank, but it doesn’t scale once we start adding additional policies. Consider the example: a data center in New York City could have a key for the policy “<code>country: US</code>”, another one for “<code>country: US or region: EU</code>”, another one for “<code>not country: RU</code>”, and so on… You can already see this getting rather unwieldy. And every time a new data center is provisioned, all policies must be re-evaluated and the appropriate keys assigned.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/A-key-for-a-each-policy-and-its-negation.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>A key for each policy and its negation</figcaption></figure><h2 id="geo-key-manager-v1-identity-based-encryption-and-broadcast-encryption">Geo Key Manager v1: identity-based encryption and broadcast encryption</h2><p>The invention of RSA in 1978 kicked off the era of modern public key cryptography, but anyone who has used GPG or is involved with certificate authorities can attest to the difficulty of managing public key infrastructure that connects keys to user identities. In 1984, Shamir asked if it was possible to create a public-key encryption system where the public key could be any string. His motivation for this question was to simplify email management. Instead of encrypting an email to Bob using Bob’s public key, Alice could encrypt it to Bob’s identity <a href="mailto:bob@institution.org"><code>bob@institution.org</code></a>. Finally, in 2001, <a href="https://crypto.stanford.edu/~dabo/papers/bfibe.pdf">Boneh and Franklin</a> figured out how to make it work.</p><p>Broadcast encryption was first proposed in 1993 by <a href="https://www.wisdom.weizmann.ac.il/~naor/PAPERS/broad.pdf">Fiat and Naor</a>. It lets you send the same encrypted message to everyone, but only people with the right key can decrypt it. Looking back to our third option, instead of wrapping the customer’s key with the key of every EU data center, we could use broadcast encryption to create a singular encryption of the customer’s key that only EU-based data centers could decrypt. This would solve the storage problem.</p><p>Geo Key Manager v1 used a combination of identity-based broadcast encryption and identity-based revocation to implement access control. Briefly, a set of identities is designated for each region and each data center location. Then, each machine is issued an identity-based private key for its region and location. With this in place, access to the customer’s key can be controlled using three sets: the set of regions to encrypt to, the set of locations inside the region to exclude, and the set of locations outside the region to include. For example, the customer’s key could be encrypted so that it is available in all regions except for a few specific locations, and also available in a few locations outside those regions. This blog post has all the <a href="http://blog.cloudflare.com/geo-key-manager-how-it-works/">nitty-gritty details</a> of this approach.</p><p>Unfortunately this scheme was insufficiently responsive to customer needs; the parameters used during initial cryptographic setup, such as the list of regions, data centers, and their attributes, were baked into the system and could not be easily changed. Tough luck excluding the UK from the EU region post Brexit, or supporting a new region based on a recent compliance standard that customers need. Using a predetermined static list of locations also made it difficult to quickly revoke machine access. Additionally, decryption keys could not be assigned to new data centers provisioned after setup, preventing them from speeding up requests. These limitations provided the impetus for integrating Attribute-Based Encryption (ABE) into Geo Key Manager.</p><h2 id="attribute-based-encryption">Attribute-Based Encryption</h2><p>In 2004, Amit Sahai and Brent Waters proposed a new cryptosystem based on access policies, known as attribute-based encryption (ABE). Essentially, a message is encrypted under an access policy rather than an identity. Users are issued a private key based on their attributes, and they can only decrypt the message if their attributes satisfy the policy. This allows for more flexible and fine-grained access control than traditional methods of encryption.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Group-4899-1.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Brief timeline of Public Key Encryption</figcaption></figure><p>The policy can be attached either to the key or to the ciphertext, leading to two variants of ABE: key-policy attribute-based encryption (KP-ABE) and ciphertext-policy attribute-based encryption (CP-ABE). There exist trade-offs between them, but they are functionally equivalent as they are duals of each other. Let’s focus on CP-ABE it aligns more closely with real-world access control. Imagine a hospital where a doctor has the attributes “<code>role: doctor</code>” and “<code>region: US</code>”, while a nurse has the attributes “<code>role: nurse</code>” and “<code>region: EU</code>”. A document encrypted under the policy “<code>role: doctor or region: EU</code>” can be decrypted by both the doctor and nurse. In other words, ABE is like a magical lock that only opens for people who have the right attributes.</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-amwm{font-weight:bold;text-align:center;vertical-align:top} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg" width="100%"> <thead> <tr> <th class="tg-amwm"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Policy</span></th> <th class="tg-amwm"><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Semantics</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">country: US or region: EU</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Decryption is possible either in the US or in the European Union</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">not (country: RU or country: US)</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Decryption is not possible in Russia and US</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">country: US and security: high</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Decryption is possible only in data centers within the US that have a high level of security (for some security definition established previously)</span></td> </tr> </tbody> </table><!--kg-card-end: html--><p>There are many different ABE schemes out there, with varying properties. The scheme we choose must satisfy a few requirements:</p><ol><li><strong>Negation</strong> We want to be able to support boolean formulas consisting of <strong>AND</strong>, <strong>OR</strong> and <strong>NOT</strong>, aka non-monotonic boolean formulas. While practically every scheme handles <strong>AND</strong> and <strong>OR</strong>, <strong>NOT</strong> is rarer to find. Negation makes blocklisting certain countries or machines easier.</li><li><strong>Repeated Attributes</strong> Consider the policy “<code>organization: executive or (organization: weapons and clearance: top-secret)</code>”. The attribute “<code>organization</code>” has been repeated twice in the policy. Schemes with support for repetition add significant expressibility and flexibility when composing policies.</li><li><strong>Security against Chosen Ciphertext Attacks</strong> Most schemes are presented in a form that is only secure if the attacker doesn’t choose the messages to decrypt (<a href="https://en.wikipedia.org/wiki/Chosen-plaintext_attack">CPA</a>). There are <a href="https://www.cs.umd.edu/~jkatz/papers/id-cca-mac.pdf">standard ways</a> to convert such a scheme into one that is secure even if the attacker manipulates ciphertexts (<a href="https://en.wikipedia.org/wiki/Ciphertext_indistinguishability#Indistinguishability_under_chosen_ciphertext_attack/adaptive_chosen_ciphertext_attack_(IND-CCA1,_IND-CCA2)">CCA</a>), but it isn’t automatic. We apply the well-known <a href="https://www.iacr.org/archive/pkc2011/65710074/65710074.pdf">Boneh-Katz transform</a> to our chosen scheme to make it secure against this class of attacks. We will present a proof of security for the end to end scheme in our forthcoming paper.</li></ol><p>Negation in particular deserves further comment. For an attribute to be satisfied when negated, the name must stay the same, but the value must differ. It’s like the data center is saying, “I have a country, but it’s definitely not Japan”, instead of “I don’t have a country”. This might seem counterintuitive, but it enables decryption without needing to examine every attribute value. It also makes it safe to roll out attributes incrementally. Based on these criteria, we ended up choosing the scheme by <a href="https://eprint.iacr.org/2019/966">Tomida et al (2021)</a>.</p><p>Implementing a complex cryptographic scheme such as this can be quite challenging. The discrete log assumption that underlies traditional public key cryptography is not sufficient to meet the security requirements of ABE. ABE schemes must secure both ciphertexts and the attribute-based secret keys, whereas traditional public key cryptography only imposes security constraints on the ciphertexts, while the secret key is merely an integer. To achieve this, most ABE schemes are constructed using a mathematical operation known as bilinear pairings.</p><p>The speed at which we can perform pairing operations determines the baseline performance of our implementation. Their efficiency is particularly desirable during decryption, where they are used to combine the attribute-based secret key with the ciphertext in order to recover the plaintext. To this end, we rely on our highly optimized pairing implementations in our open source library of cryptographic suites, CIRCL, which we discuss at length in a <a href="http://blog.cloudflare.com/circl-pairings-update/">previous blog</a>. Additionally, the various keys, attributes and the ciphertext that embeds the access structure are expressed as matrices and vectors. We wrote linear algebra routines to handle matrix operations such as multiplication, transpose, inverse that are necessary to manipulate the structures as needed. We also added serialization, extensive testing and benchmarking. Finally, we implemented our conversion to a <a href="https://en.wikipedia.org/wiki/Adaptive_chosen-ciphertext_attack">CCA2 secure</a> scheme.</p><p>In addition to the core cryptography, we had to decide how to express and represent policies. Ultimately we decided on using strings for our API. While perhaps less convenient for programs than structures would be, users of our scheme would have to implement a parser anyway. Having us do it for them seemed like a way to have a more stable interface. This means the frontend of our policy language was composed of boolean expressions as strings, such as “<code>country: JP or (not region: EU)</code>”, while the backend is a <em>monotonic</em> boolean circuit consisting of wires and gates. Monotonic boolean circuits only include AND and OR gates. In order to handle NOT gates, we assigned positive or negative values to the wires. Every NOT gate can be placed directly on a wire because of <a href="https://en.wikipedia.org/wiki/De_Morgan%27s_laws">De Morgan’s Law</a>, which allows the conversion of a formula like “<code>not (X and Y)” into “not X or not Y</code>”, and similarly for disjunction.</p><p>The following is a demonstration of the API. The central authority runs Setup to generate the master public key and master secret key. The master public key can be used by anyone to encrypt a message over an access policy. The master secret key, held by the central authority, is used to generate secret keys for users based on their attributes. Attributes themselves can be supplied out-of-band. In our case, we rely on the machine provisioning database to provide and validate attributes. These attribute-based secret keys are securely distributed to users, such as over TLS, and are used to decrypt ciphertexts. The API also includes helper functions to check decryption capabilities and extract policies from ciphertexts for improved usability.</p><!--kg-card-begin: markdown--><pre><code>publicKey, masterSecretKey := cpabe.Setup() policy := cpabe.Policy{} policy.FromString(&quot;country: US or region: EU&quot;) ciphertext := publicKey.Encrypt(policy, []byte(&quot;secret message&quot;)) attrsParisDC := cpabe.Attributes{} attrsParisDC.FromMap(map[string]string{&quot;country&quot;: &quot;FR&quot;, &quot;region&quot;: &quot;EU&quot;} secretKeyParisDC := masterSecretKey.KeyGen(attrsParisDC) plaintext := secretKeyParisDC.Decrypt(ciphertext) assertEquals(plaintext, &quot;secret message&quot;) </code></pre> <!--kg-card-end: markdown--><p>We now come back to our original example. This time, the central authority holds the master secret key. Each machine in every data center presents its set of attributes to the central authority, which, after some validation, generates a unique attribute-based secret key for that particular machine. Key issuance happens when a machine is first brought up, if keys must be rotated, or if an attribute has changed, but never in the critical path of a TLS handshake. This solution is also collusion resistant, which means two machines without the appropriate attributes cannot combine their keys to decrypt a secret that they individually could not decrypt. For example, a machine with the attribute  “<code>country: US</code>” and another with “<code>security: high</code>”. These machines cannot collude together to decrypt a resource with the policy “<code>country: US and security: high</code>”.</p><p>Crucially, this solution can seamlessly scale and respond to changes to machines. If a new machine is added, the central authority can simply issue it a secret key since the participants of the scheme don’t have to be predetermined at setup, unlike our previous identity-broadcast scheme.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Key-Distribution.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Key Distribution</figcaption></figure><p>When a customer uploads their TLS certificate, they can specify a policy, and the central authority will encrypt their private key with the master public key under the specified policy. The encrypted customer key then gets written to Quicksilver, to be distributed to all data centers. In practice, there is a layer of indirection here that we will discuss in a later section.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Encryption-using-Master-Public-Key.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Encryption using Master Public Key</figcaption></figure><p>When a user visits the customer’s website, the TLS termination service at the data center that first receives the request, fetches the customer’s encrypted private key from Quicksilver. If the service's attributes do not satisfy the policy, decryption fails and the request is proxied to the closest data center that satisfies the policy. Whichever data center can successfully decrypt the key performs the signature to complete the TLS handshake.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Decryption-using-Attribute-based-Secret-Key.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Decryption using Attribute-based Secret Key (Simplified)</figcaption></figure><p>The following table summarizes the pros and cons of the various solutions we discussed:</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg" width="100%"> <thead> <tr> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Solution</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Flexible policies</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Fault Tolerant</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Efficient Space</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Low Latency</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Collusion-resistant</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Changes to machines</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Different copies of Quicksilver in data centers</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Complicated Business Logic in Core</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Encrypt customer keys with each data center’s unique keypair</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Encrypt customer keys with a policy-based keypair, where each data center has multiple policy-based keypairs</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Identity-Based Broadcast Encryption + Identity-Based Negative Broadcast Encryption</span><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">(Geo Key Manager v1)</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Attribute-Based Encryption</span><span style="font-weight:700;font-style:normal;text-decoration:none;color:#000;background-color:transparent">(Geo Key Manager v2)</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">✅</span></td> </tr> </tbody> </table><!--kg-card-end: html--><h3 id="performance-characteristics">Performance characteristics</h3><p>We characterize our scheme’s performance on measures inspired by <a href="https://bench.cr.yp.to/results-encrypt.html">ECRYPT</a>. We set the <strong>attribute size to 50</strong>, which is significantly higher than necessary for most applications, but serves as a worst case scenario for benchmarking purposes. We conduct our measurements on a laptop with Intel Core i7-10610U CPU @ 1.80GHz and compare the results against RSA with 2048-bit security, X25519 and our previous scheme.</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg" width="100%"> <thead> <tr> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Scheme</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Secret key(bytes)</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Public key(bytes)</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Overhead of encrypting 23 bytes</span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">(ciphertext length - message length)</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Overhead of encrypting 10k bytes</span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">(ciphertext length - message length)</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">RSA-2048</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">1190 (PKCS#1)</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">256</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">233</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">3568</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">X25519</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">32</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">32</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">48</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">48</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">GeoV1 scheme</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">4838</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">4742</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">169</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">169</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">GeoV2 ABE scheme</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">33416</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">3282</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">19419</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">19419</span></td> </tr> </tbody> </table><!--kg-card-end: html--><p>Different attribute based encryption schemes optimize for different performance profiles. Some may have fast key generation, while others may prioritize fast decryption. In our case, we only care about fast decryption because it is the only part of the process that lies in the critical path of a request. Everything else happens out-of-band where the extra overhead is acceptable.</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg" width="100%"> <thead> <tr> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Scheme</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generating keypair</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Encrypting 23 bytes</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Decrypting 23 bytes</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">RSA-2048</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">117 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">0.043 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">1.26 ms</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">X25519</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">0.045 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">0.093 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">0.046 ms</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">GeoV1 scheme</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">75 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">10.7 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">13.9 ms</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">GeoV2 ABE scheme</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">1796 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">704 ms</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">62.4 ms</span></td> </tr> </tbody> </table><!--kg-card-end: html--><h3 id="a-brief-note-on-attribute-based-access-control-abac-">A Brief Note on Attribute-Based Access Control (ABAC)</h3><p>We have used Attribute-Based Encryption to implement what is commonly known as <a href="https://csrc.nist.gov/Projects/Attribute-Based-Access-Control">Attribute-Based Access Control (ABAC)</a>.</p><p>ABAC is an extension of the more familiar <a href="https://csrc.nist.gov/Projects/Role-Based-Access-Control">Role-Based Access Control (RBAC)</a>. To understand why ABAC is relevant, let’s briefly discuss its origins. In 1970, the United States Department of Defense introduced Discretionary Access Control (DAC). DAC is how Unix file systems are implemented. But DAC isn’t enough if you want to restrict resharing, because the owner of the resource can grant other users permission to access it in ways that the central administrator does not agree with. To address this, the Department of Defense introduced Mandatory Access Control (MAC). DRM is a good example of MAC. Even though you have the file, you don’t have a right to share it to others.</p><p>RBAC is an implementation of certain aspects of MAC. ABAC is an extension of RBAC that was defined by NIST in 2017 to address the increasing characteristics of users that are not restricted to their roles, such as time of day, user agent, and so on.</p><p>However, RBAC/ABAC is simply a specification. While they are traditionally implemented using a central authority to police access to some resource, it doesn’t have to be so. Attribute-based encryption is an excellent mechanism to implement ABAC in distributed systems.</p><h2 id="key-rotation">Key rotation</h2><p>While it may be tempting to attribute all failures to DNS, changing keys is another strong contender in this race. Suffering through the rather manual and error-prone key rotation process of Geo Key Manager v1 taught us to make robust and simple key rotation without impact on availability, an explicit design goal for Geo Key Manager v2.</p><p>To facilitate key rotation and improve performance, we introduce a layer of indirection to the customer key wrapping (encryption) process. When a customer uploads their TLS private key, instead of encrypting with the Master Public Key, we generate a X25519 keypair, called the <em>policy key</em>. The central authority then adds the public part of this newly minted policy keypair and its associated policy label to a database. It then encrypts the private half of the policy keypair with the Master Public Key, over the associated access policy. The customer’s private key is encrypted with the public policy key, and saved into Quicksilver.</p><p>When a user accesses the customer’s website, the TLS termination service at the data center that receives the request fetches the encrypted policy key associated with the customer’s access policy. If the machine’s attributes don’t satisfy the policy, decryption fails and the request is forwarded to the closest satisfying data center. If decryption succeeds, the policy key is used to decrypt the customer’s private key and complete the handshake.</p><!--kg-card-begin: html--><style type="text/css"> .tg {border-collapse:collapse;border-spacing:0;} .tg td{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; overflow:hidden;padding:10px 5px;word-break:normal;} .tg th{border-color:black;border-style:solid;border-width:1px;font-family:Arial, sans-serif;font-size:14px; font-weight:normal;overflow:hidden;padding:10px 5px;word-break:normal;} .tg .tg-0lax{text-align:left;vertical-align:top} </style> <table class="tg" width="100%"> <thead> <tr> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Key</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Purpose</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">CA in core</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Core</span></th> <th class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Network</span></th> </tr> </thead> <tbody> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Master Public Key</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Encrypts private policy keys over an access policy</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generate</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read</span></td> <td class="tg-0lax"></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Master Secret Key</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generates secret keys for machines based on their attributes</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generate,Read</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Machine Secret Key / Attribute-Based Secret Key</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Decrypts private policy keys stored in global KV store, Quicksilver</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generate</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Customer TLS Private Key</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Performs digital signature necessary to complete TLS handshake to the customer’s website</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read (transiently on upload)</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read</span></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Public Policy Key</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Encrypts customers’ TLS private keys</span></td> <td class="tg-0lax"></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generate,</span><br><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read</span></td> <td class="tg-0lax"></td> </tr> <tr> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Private Policy Key</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Decrypts customer’s TLS private keys</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read (transiently during key rotation)</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Generate</span></td> <td class="tg-0lax"><span style="font-weight:400;font-style:normal;text-decoration:none;color:#000;background-color:transparent">Read</span></td> </tr> </tbody> </table><!--kg-card-end: html--><p>However, policy keys are not generated for every customer’s certificate upload. As shown in the figure below, if a customer requests a policy that already exists in the system and thus has an associated policy key, the policy key will get re-used. Since most customers use the same few policies, such as restricting to one country, or restricting to the EU, the number of policy keys is orders of magnitude smaller compared to the number of customer keys.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Policy-Keys.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Policy Keys</figcaption></figure><p>This sharing of policy keys is tremendously useful for key rotation. When master keys are rotated (and consequently the machine secret keys), only the handful of policy keys used to control access to the customers’ keys need to be re-encrypted, rather than every customer’s key encryption. This reduces compute and bandwidth requirements. Additionally, caching policy keys at the TLS termination service improves performance by reducing the need for frequent decryptions in the critical path.</p><p>This is similar to hybrid encryption, where public key cryptography is used to establish a shared symmetric key, which then gets used to encrypt data. The difference here is that the policy keys are not symmetric, but rather X25519 keypairs, which is an asymmetric scheme based on elliptic curves. While not as fast as symmetric schemes like AES, traditional elliptic curve cryptography is significantly faster than attribute-based encryption. The advantage here is that the central service doesn’t need access to secret key material to encrypt customer keys.</p><p>The other component of robust key rotation involves maintaining multiple key versions.The latest key generation is used for encryption, but the latest and previous versions can be used for decryption. We use a system of states to manage key transitions and safe deletion of older keys. We also have extensive monitoring in place to alert us if any machines are not using the appropriate key generations.</p><h2 id="the-tail-at-scale">The Tail At Scale</h2><p>Geo Key Manager suffered from high tail latency, which occasionally impacted availability. Jeff Dean’s paper, <a href="https://research.google/pubs/pub40801/">The Tail at Scale</a>, is an enlightening read on how even elevated p99 latency at Cloudflare scale can be damaging. Despite revamping the server and client components of our service, the p99 latency didn’t budge. These revamps, such as switching from worker pools to one goroutine per request, did simplify the service, as they removed thousands of lines of code. Distributed tracing was able to pin down the delays: they took place between the client sending a request and the server receiving it. But we could not dig in further. We even wrote a blog last year describing our <a href="http://blog.cloudflare.com/scaling-geo-key-manager/">debugging endeavors</a>, but without a concrete solution.</p><p>Finally, we realized that there is a level of indirection between the client and the server. Our data centers around the world are very different sizes. To avoid swamping smaller data centers with connections, larger data centers would task individual, intermediary machines with proxying requests to other data centers using the Go net/rpc library.</p><p>Once we included the forwarding function on the intermediary server in the trace, the problem became clear. There was a long delay between issuing the request and processing it. Yet the code was merely a call to a built-in library function. Why was it delaying the request?</p><p>Ultimately we found that there was a lock held while the request was serialized. The net/rpc package does not support streams, but our packet-oriented custom application protocol, which we wrote before the advent of gRPC, does support streaming. To bridge this gap, we executed a request and waited for the response in the serialization function. While an expedient way to get the code written, it created a performance bottleneck as only one request could be forwarded at a time.</p><p>Our solution was to use channels for coordination, letting multiple requests execute while we waited for the responses to arrive. When we rolled it out we saw dramatic decreases in tail latency.</p><figure class="kg-card kg-image-card kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/Untitled-4.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>The results of fixing RPC failures in remote colo in Australia</figcaption></figure><p>Unfortunately we cannot make the speed of light any faster (yet). Customers who want their keys kept only in the US while their website users are in the land down under will have to endure some delays as we make the trans-pacific voyage. But thanks to session tickets, those delays only affect new connections.</p><!--kg-card-begin: html--><div style="position: relative; padding-top: 49.86830553116769%;"><iframe src="https://customer-eq7kiuol0tk9chox.cloudflarestream.com/a2ff6e606d424150264223bc7635ca25/iframe?preload=true&loop=true&autoplay=true&poster=https%3A%2F%2Fcustomer-eq7kiuol0tk9chox.cloudflarestream.com%2Fa2ff6e606d424150264223bc7635ca25%2Fthumbnails%2Fthumbnail.jpg%3Ftime%3D%26height%3D600" style="border: none; position: absolute; top: 0; left: 0; height: 100%; width: 100%;" allow="accelerometer; gyroscope; autoplay; encrypted-media; picture-in-picture;" allowfullscreen="true"></iframe></div><!--kg-card-end: html--><p>Uptime was also significantly improved. Data centers provisioned after cryptographic initiation could now participate in the system, which also implies that data centers that did not satisfy a certain policy had a broader range of satisfying neighbors to which they could forward the signing request to. This increased redundancy in the system, and particularly benefited data centers in regions without the best internet connectivity. The graph below represents successful probes spanning every machine globally over a two-day period. For GeoV1, we see websites with policies for US and EU regions falling to under 98% at one point, while for GeoV2, uptime rarely drops below 4 9s of availability.</p><figure class="kg-card kg-image-card kg-width-wide kg-card-hascaption"><img src="http://blog.cloudflare.com/content/images/2023/01/ss.png" class="kg-image" alt="Inside Geo Key Manager v2: re-imagining access control for distributed systems"><figcaption>Uptime by Key Profile across US and EU for GeoV1 and GeoV2, and IN for GeoV2</figcaption></figure><h2 id="conclusion">Conclusion</h2><p>Congratulations dear reader for making it this far. Just like you, applied cryptography has come a long way, but only limited slivers manage to penetrate the barrier between research and real-world adoption. Bridging this gap can help enable novel capabilities for protecting sensitive data. Attribute-based encryption itself has become much more efficient and featureful over the past few years. We hope that this post encourages you to consider ABE for your own access control needs, particularly if you deal with distributed systems and don’t want to depend on a highly available central authority. We have open-sourced our implementation of CP-ABE in <a href="https://github.com/cloudflare/circl/tree/main/abe/cpabe/tkn20">CIRCL</a>, and plan on publishing a paper with additional details.</p><p>We look forward to the numerous product improvements to Geo Key Manager made possible by this new cryptographic foundation. We plan to use this ABE-based mechanism for storing not just private keys, but also other types of data. We are working on making it more user-friendly and generalizable for internal services to use.</p><h2 id="acknowledgements">Acknowledgements</h2><p>We’d like to thank Watson Ladd for his contributions to this project during his tenure at Cloudflare.</p><!--kg-card-begin: markdown--><p><small>......<br> <sup>1</sup>While true for most customers, we do offer <a href="https://www.cloudflare.com/ssl/keyless-ssl/">Keyless SSL</a> that allows customers who can run their own keyservers, the ability to store their private keys on-prem</small></p> <!--kg-card-end: markdown--> ]]>
</content:encoded>
</item>
</channel>
</rss>
